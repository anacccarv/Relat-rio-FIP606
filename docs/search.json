[
  {
    "objectID": "Introdução.html",
    "href": "Introdução.html",
    "title": "Introdução",
    "section": "",
    "text": "R é uma linguagem de programação e ambiente de software livre amplamente utilizado para análise estatística, visualização de dados e ciência de dados. Criado por Ross Ihaka e Robert Gentleman na década de 1990, R teve sua primeira versão estável lançada em 2000 e, desde então, tem crescido em popularidade devido a suas poderosas capacidades e à forte comunidade de usuários e desenvolvedores.\nEmbora seja perfeitamente possível usar apenas a instalação básica do R, muitas pessoas preferem utilizar um ambiente de desenvolvimento integrado (IDE) para uma experiência mais eficiente e amigável. Um dos IDEs mais populares para R é o RStudio.\nRStudio é um complemento do R que oferece uma interface mais intuitiva e funcionalidades avançadas para facilitar seu trabalho com R.\nPara fazer o download dos programas clique aqui."
  },
  {
    "objectID": "Introdução.html#passos-para-começar-um-projeto-organizado",
    "href": "Introdução.html#passos-para-começar-um-projeto-organizado",
    "title": "Introdução",
    "section": "Passos para Começar um Projeto Organizado",
    "text": "Passos para Começar um Projeto Organizado\n\nCriar um Projeto no RStudio\n\nInicie o RStudio e vá para File &gt; New Project.\nSiga as instruções para criar um novo projeto. Isso ajudará a manter todos os arquivos relacionados ao seu projeto em um único diretório.\n\nCriar Arquivos Quarto Markdown\n\nUse Quarto Markdown para combinar conteúdo e código executável em um documento finalizado.\nNo RStudio, vá para File &gt; New File &gt; Quarto Document para criar um novo arquivo .qmd.\n\n\nUtilizar o Quarto Markdown permite a criação de documentos dinâmicos que integram texto e código, facilitando a análise reprodutível e a comunicação dos resultados."
  },
  {
    "objectID": "Introdução.html#para-instalar-pacotes-do-cran",
    "href": "Introdução.html#para-instalar-pacotes-do-cran",
    "title": "Introdução",
    "section": "Para instalar pacotes do CRAN:",
    "text": "Para instalar pacotes do CRAN:\nPara instalar um pacote do CRAN você pode usar a função install.packages().\n\n#Exemplo:\n#install.packages(\"nome do pacote de interesse\")\n\nÉ uma boa prática atualizar periodicamente os pacotes instalados para acessar novas funcionalidades e correções de bugs. Para atualizar pacotes do CRAN, você pode usar a função update.packages()."
  },
  {
    "objectID": "Introdução.html#para-instalar-pacotes-do-github",
    "href": "Introdução.html#para-instalar-pacotes-do-github",
    "title": "Introdução",
    "section": "Para instalar pacotes do GitHub:",
    "text": "Para instalar pacotes do GitHub:\nHá várias maneiras de instalar pacotes hospedados no GitHub, mas uma das mais eficientes é utilizar a função install_github() do pacote remotes. Antes de usar esta função, é necessário saber o nome de usuário do GitHub do proprietário do repositório e o nome do próprio repositório.\n\n#Exemplo:\nremotes::install_github(\"emdelponte/r4pde\")"
  },
  {
    "objectID": "Introdução.html#carregamento-de-pacotes",
    "href": "Introdução.html#carregamento-de-pacotes",
    "title": "Introdução",
    "section": "Carregamento de pacotes:",
    "text": "Carregamento de pacotes:\nDepois de instalar um pacote em seu computador, ele não está imediatamente disponível para uso. Para utilizar um pacote, você precisa carregá-lo utilizando a função library().\n\n#Exemplo:\nlibrary(tidyverse)\n\nA função library() também carregará quaisquer pacotes adicionais necessários e poderá imprimir informações adicionais do pacote.\nDica: colocar todos pacotes necessários para a análise no topo dos scripts em um chunk específico para torná-los mais acessíveis e fáceis de encontrar.\nAs vezes, pode ser útil usar uma função sem primeiro usar a função library(). Por exemplo, se for utilizar apenas uma ou duas funções em seu script e não quiser carregar o pacote completo, poderá acessar a função diretamente, basta especificar o nome do pacote seguido de :: e o nome da função.\n\n#Exemplo:\n#tidyverse::select()"
  },
  {
    "objectID": "Aula9.html",
    "href": "Aula9.html",
    "title": "Análise de Modelo Misto, Correlação e Regressão Linear",
    "section": "",
    "text": "Parcelas subdividas: dentro de cada bloco tem os hibridos aleatoriamente. Naquele bloco, subdivido, aleatorizou o método dentro dos blocos – ou seja, o método foi aleatorizado entre os hibridos em cada bloco. “Hibrido dentro do bloco e método dentro do híbrido”.\nPode utilizar um modelo misto (mistura de um fator de efeito fixo e um fator de efeito aleatório)."
  },
  {
    "objectID": "Aula9.html#index-modelo-para-subdividido",
    "href": "Aula9.html#index-modelo-para-subdividido",
    "title": "Análise de Modelo Misto, Correlação e Regressão Linear",
    "section": "INDEX: Modelo para subdividido:",
    "text": "INDEX: Modelo para subdividido:\n\nmilho &lt;- milho |&gt; \n  mutate(block = as.factor(block))\n\nmix2 &lt;- lmer(sqrt(index) ~hybrid*method  + block + (1|block/hybrid),\n                                  data = milho)\n\nAnova(mix2)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: sqrt(index)\n                Chisq Df Pr(&gt;Chisq)   \nhybrid        15.3159  5   0.009095 **\nmethod         3.8886  1   0.048615 * \nblock          0.0718  3   0.994997   \nhybrid:method 13.3812  5   0.020057 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n(1|block/hybrid) = é para indicar para a função que é o fator de efeito aleatório.\nResultado: deu interação significativa entre o hibrido e o metodo.\n\nTestar as premissas\n\ncheck_normality(mix2)\n\nOK: residuals appear as normally distributed (p = 0.440).\n\ncheck_heteroscedasticity(mix2)\n\nOK: Error variance appears to be homoscedastic (p = 0.971).\n\nplot(simulateResiduals(mix2))\n\n\n\n\n\n\n\nqqnorm(residuals(mix2))\nqqline(residuals(mix2))\n\n\n\n\n\n\n\nhist(residuals(mix2))\n\n\n\n\n\n\n\n#mesmo o Dharma dando problema, com o qqlinde e qqnorm os pontos estão próximos da linha, indicando normalidade, por isso, vamos prosseguir assumindo que as premissas foram atendidas.\n\n\n\nTeste de comparação de médias\n\nmedias_milho &lt;- emmeans(mix2,\n                        ~ hybrid | method,\n                        type = \"response\")\n\nmedias_milho2 &lt;- emmeans(mix2,\n                         ~ method | hybrid,\n                         type = \"response\")\n\ncld(medias_milho, Letters = LETTERS)\n\nmethod = pin:\n hybrid   response   SE   df lower.CL upper.CL .group\n BG7049H      19.4 10.7 6084     4.10     46.0  A    \n 30K64        20.3 10.9 6084     4.51     47.4  A    \n 30F53 YH     24.5 12.0 6084     6.61     53.7  AB   \n 30F53 HX     25.0 12.1 6084     6.84     54.4  AB   \n 30S31YH      31.7 13.7 6084    10.57     64.2  AB   \n 30S31H       37.1 14.8 6084    13.79     71.8   B   \n\nmethod = silk:\n hybrid   response   SE   df lower.CL upper.CL .group\n BG7049H      19.1 10.6 6084     3.96     45.6  A    \n 30K64        21.3 11.2 6084     5.00     48.9  A    \n 30F53 HX     24.4 12.0 6084     6.56     53.6  A    \n 30F53 YH     26.0 12.4 6084     7.42     56.0  A    \n 30S31H       26.3 12.5 6084     7.57     56.4  A    \n 30S31YH      26.4 12.5 6084     7.62     56.5  A    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\ncld(medias_milho2, Letters = LETTERS)\n\nhybrid = 30F53 HX:\n method response   SE   df lower.CL upper.CL .group\n silk       24.4 12.0 6084     6.56     53.6  A    \n pin        25.0 12.1 6084     6.84     54.4  A    \n\nhybrid = 30F53 YH:\n method response   SE   df lower.CL upper.CL .group\n pin        24.5 12.0 6084     6.61     53.7  A    \n silk       26.0 12.4 6084     7.42     56.0  A    \n\nhybrid = 30K64:\n method response   SE   df lower.CL upper.CL .group\n pin        20.3 10.9 6084     4.51     47.4  A    \n silk       21.3 11.2 6084     5.00     48.9  A    \n\nhybrid = 30S31H:\n method response   SE   df lower.CL upper.CL .group\n silk       26.3 12.5 6084     7.57     56.4  A    \n pin        37.1 14.8 6084    13.79     71.8   B   \n\nhybrid = 30S31YH:\n method response   SE   df lower.CL upper.CL .group\n silk       26.4 12.5 6084     7.62     56.5  A    \n pin        31.7 13.7 6084    10.57     64.2  A    \n\nhybrid = BG7049H:\n method response   SE   df lower.CL upper.CL .group\n silk       19.1 10.6 6084     3.96     45.6  A    \n pin        19.4 10.7 6084     4.10     46.0  A    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same."
  },
  {
    "objectID": "Aula9.html#yield-modelo-para-subdividido",
    "href": "Aula9.html#yield-modelo-para-subdividido",
    "title": "Análise de Modelo Misto, Correlação e Regressão Linear",
    "section": "YIELD: Modelo para subdividido:",
    "text": "YIELD: Modelo para subdividido:\n\nmilho &lt;- milho |&gt; \n  mutate(block = as.factor(block))\n\nmix3 &lt;- lmer(sqrt(yield) ~hybrid*method  + block + (1|block/hybrid),\n                                  data = milho)\n\nAnova(mix3)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: sqrt(yield)\n                Chisq Df Pr(&gt;Chisq)    \nhybrid        25.5591  5  0.0001086 ***\nmethod         0.0520  1  0.8196750    \nblock          2.3606  3  0.5010021    \nhybrid:method 24.4985  5  0.0001741 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n(1|block/hybrid) = é para indicar para a função que é o fator de efeito aleatório.\nResultado: deu interação significativa entre o hibrido e o metodo.\n\nTestar as premissas\n\ncheck_normality(mix3)\n\nOK: residuals appear as normally distributed (p = 0.214).\n\ncheck_heteroscedasticity(mix3)\n\nOK: Error variance appears to be homoscedastic (p = 0.686).\n\nplot(simulateResiduals(mix3))\n\n\n\n\n\n\n\nqqnorm(residuals(mix3))\nqqline(residuals(mix3))\n\n\n\n\n\n\n\nhist(residuals(mix3))\n\n\n\n\n\n\n\n#mesmo o Dharma dando problema, com o qqlinde e qqnorm os pontos estão próximos da linha, indicando normalidade, por isso, vamos prosseguir assumindo que as premissas foram atendidas.\n\n\n\nTeste de comparação de médias\n\nmedias_milho3 &lt;- emmeans(mix3,\n                        ~ hybrid | method,\n                        type = \"response\")\n\nmedias_milho4 &lt;- emmeans(mix3,\n                         ~ method | hybrid,\n                         type = \"response\")\n\ncld(medias_milho3, Letters = LETTERS)\n\nmethod = pin:\n hybrid   response  SE   df lower.CL upper.CL .group\n 30S31YH      7829 732 26.1     6398     9405  A    \n 30S31H       8081 743 26.1     6626     9681  AB   \n 30F53 YH     9314 798 26.1     7746    11027  ABC  \n 30F53 HX    11130 872 26.1     9410    12995   BC  \n 30K64       11666 893 26.1     9903    13574    C  \n BG7049H     11914 903 26.1    10131    13841    C  \n\nmethod = silk:\n hybrid   response  SE   df lower.CL upper.CL .group\n 30S31YH      8257 751 26.1     6785     9873  A    \n 30F53 YH     9079 788 26.1     7532    10770  A    \n 30S31H       9135 790 26.1     7583    10832  A    \n 30F53 HX     9932 824 26.1     8311    11698  AB   \n 30K64       10331 840 26.1     8676    12131  AB   \n BG7049H     12822 936 26.1    10970    14818   B   \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\ncld(medias_milho4, Letters = LETTERS)\n\nhybrid = 30F53 HX:\n method response  SE   df lower.CL upper.CL .group\n silk       9932 824 26.1     8311    11698  A    \n pin       11130 872 26.1     9410    12995   B   \n\nhybrid = 30F53 YH:\n method response  SE   df lower.CL upper.CL .group\n silk       9079 788 26.1     7532    10770  A    \n pin        9314 798 26.1     7746    11027  A    \n\nhybrid = 30K64:\n method response  SE   df lower.CL upper.CL .group\n silk      10331 840 26.1     8676    12131  A    \n pin       11666 893 26.1     9903    13574   B   \n\nhybrid = 30S31H:\n method response  SE   df lower.CL upper.CL .group\n pin        8081 743 26.1     6626     9681  A    \n silk       9135 790 26.1     7583    10832   B   \n\nhybrid = 30S31YH:\n method response  SE   df lower.CL upper.CL .group\n pin        7829 732 26.1     6398     9405  A    \n silk       8257 751 26.1     6785     9873  A    \n\nhybrid = BG7049H:\n method response  SE   df lower.CL upper.CL .group\n pin       11914 903 26.1    10131    13841  A    \n silk      12822 936 26.1    10970    14818  A    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same."
  },
  {
    "objectID": "Aula9.html#regressão-linear-simples-por-experimento",
    "href": "Aula9.html#regressão-linear-simples-por-experimento",
    "title": "Análise de Modelo Misto, Correlação e Regressão Linear",
    "section": "Regressão linear simples por experimento",
    "text": "Regressão linear simples por experimento\n\nVisualização para exp1\n\nexp1 &lt;- estande |&gt; \n  dplyr::filter(exp == 1)\n\nexp1 |&gt; \nggplot(aes(trat, nplants))+\n  geom_point()+\n  ylim(0,100)+\n  geom_smooth(se = FALSE)\n\n\n\n\n\n\n\n\nSe não colocar o method em geom_smooth ele dá a linha suavizada. O se é para tirar o fundo cinza de tras da linha (erro)\n\n\nModelo linear\n\nlm1 &lt;- lm(nplants ~trat,\n          data = exp1)\nsummary(lm1)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.500  -6.532   1.758   8.573  27.226 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  52.5000     4.2044  12.487 1.84e-11 ***\ntrat         -0.2419     0.1859  -1.301    0.207    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 15 on 22 degrees of freedom\nMultiple R-squared:  0.07148,   Adjusted R-squared:  0.02928 \nF-statistic: 1.694 on 1 and 22 DF,  p-value: 0.2066\n\n\nQUal a hipótese nula: que o coeficiente de regressão é igual a 0. Ou seja, não tem efeito. Para cada percentual de inoculo (unidade de x) reduz 0,24 de y (precisa de 4% para reduzir uma planta) Dessa forma, como valor p foi maior que 0,05 (0,207), não rejeita H0, então não tem efeito.\n\n\nVisualização para exp2\n\nexp2 &lt;- estande |&gt; \n  dplyr::filter(exp == 2)\n\nexp2 |&gt; \nggplot(aes(trat, nplants))+\n  geom_point()+\n  ylim(0,100)+\n  geom_smooth(method = lm,\n    se = FALSE)\n\n\n\n\n\n\n\n\nSe não colocar o method em geom_smooth ele dá a linha suavizada. O se é para tirar o fundo cinza de tras da linha (erro)\n\n\nModelo linear\n\nlm2 &lt;- lm(nplants ~trat,\n          data = exp2)\nsummary(lm2)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-25.7816  -7.7150   0.5653   8.1929  19.2184 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  60.9857     3.6304  16.798 4.93e-14 ***\ntrat         -0.7007     0.1605  -4.365 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.95 on 22 degrees of freedom\nMultiple R-squared:  0.4641,    Adjusted R-squared:  0.4398 \nF-statistic: 19.05 on 1 and 22 DF,  p-value: 0.0002473\n\n\nPara cada percentual de inoculo (unidade de x) reduz 0,70 de y (quase uma planta)\nTem efeito significativo: p-valor &lt; 0,05\nAdjusted R-squared: é uma medida estatística utilizada em regressão linear para avaliar o ajuste do modelo aos dados. Ou seja, quanto maior o R2, maior a relação de y ser em função do x. Quanto maior variabilidade nos pontos (dispersão), o R2 diminui e o p-valor aumenta. Vai explicar menos, quanto mais disperso são os dados.\n\nFazendo transformação dos dados: fica mais linear a linha\n\nexp2 |&gt; \nggplot(aes(log(trat), nplants))+\n  geom_point()+\n  ylim(0,100)+\n  geom_smooth(se = FALSE)\n\n\n\n\n\n\n\n\n\n\nFazendo GLM\n\nglm2 &lt;- glm(nplants ~trat, family = \"gaussian\",\n            data = exp2)\n\nsummary(glm2)\n\n\nCall:\nglm(formula = nplants ~ trat, family = \"gaussian\", data = exp2)\n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  60.9857     3.6304  16.798 4.93e-14 ***\ntrat         -0.7007     0.1605  -4.365 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 167.7464)\n\n    Null deviance: 6886.6  on 23  degrees of freedom\nResidual deviance: 3690.4  on 22  degrees of freedom\nAIC: 194.96\n\nNumber of Fisher Scoring iterations: 2\n\nAIC(glm2)\n\n[1] 194.9597\n\nglm2b &lt;- glm(nplants ~trat, family = \"poisson\",\n             data = exp2)\n\nsummary(glm2b)\n\n\nCall:\nglm(formula = nplants ~ trat, family = \"poisson\", data = exp2)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  4.134189   0.037583 110.003  &lt; 2e-16 ***\ntrat        -0.016270   0.002059  -7.901 2.76e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 139.783  on 23  degrees of freedom\nResidual deviance:  69.578  on 22  degrees of freedom\nAIC: 210.24\n\nNumber of Fisher Scoring iterations: 4\n\nAIC(glm2b)\n\n[1] 210.2353\n\n\n\n\n\nVisualização para exp3\n\nexp3 &lt;- estande |&gt; \n  dplyr::filter(exp == 3)\n\nexp3 |&gt; \nggplot(aes(trat, nplants))+\n  geom_point()+\n  ylim(0,100)+\n  geom_smooth(se = FALSE)\n\n\n\n\n\n\n\nglm3 &lt;- glm(nplants ~trat, family = \"poisson\",\n             data = exp3)\n\nsummary(glm3)\n\n\nCall:\nglm(formula = nplants ~ trat, family = \"poisson\", data = exp3)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  4.571590   0.029539 154.762  &lt; 2e-16 ***\ntrat        -0.009965   0.001488  -6.697 2.13e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 77.906  on 23  degrees of freedom\nResidual deviance: 29.952  on 22  degrees of freedom\nAIC: 183.93\n\nNumber of Fisher Scoring iterations: 4\n\nAIC(glm3)\n\n[1] 183.9324\n\n\n\n\nAnálise global (sem ser para cada experimentos = todos os experimentos juntos)\n\nglm3 &lt;- glmer(nplants ~trat + (trat | exp), family = \"gaussian\",\n              data = estande)\nsummary(glm3)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: nplants ~ trat + (trat | exp)\n   Data: estande\n\nREML criterion at convergence: 580.8\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.0988 -0.6091  0.1722  0.6360  1.9963 \n\nRandom effects:\n Groups   Name        Variance  Std.Dev. Corr \n exp      (Intercept) 510.68405 22.5983       \n          trat          0.05516  0.2349  -0.82\n Residual             167.91303 12.9581       \nNumber of obs: 72, groups:  exp, 3\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)  69.7452    13.2146   5.278\ntrat         -0.5687     0.1643  -3.462\n\nCorrelation of Fixed Effects:\n     (Intr)\ntrat -0.731\noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.00274249 (tol = 0.002, component 1)\n\nAIC(glm3)\n\n[1] 592.8402\n\nglm3b &lt;- glmer(nplants ~trat + (trat|exp), family = poisson(link = \"log\"),\n                                                            data = estande)\nsummary(glm3b)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: poisson  ( log )\nFormula: nplants ~ trat + (trat | exp)\n   Data: estande\n\n     AIC      BIC   logLik deviance df.resid \n   660.7    672.1   -325.4    650.7       67 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.6247 -0.8083  0.1042  0.9601  3.6511 \n\nRandom effects:\n Groups Name        Variance  Std.Dev. Corr \n exp    (Intercept) 6.425e-02 0.253478      \n        trat        1.602e-05 0.004003 -0.17\nNumber of obs: 72, groups:  exp, 3\n\nFixed effects:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  4.223397   0.147793  28.577  &lt; 2e-16 ***\ntrat        -0.010434   0.002538  -4.111 3.93e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n     (Intr)\ntrat -0.192\n\nAIC(glm3b)\n\n[1] 660.7282\n\n\nAIC menor diz que o modelo está melhor ajustado."
  },
  {
    "objectID": "Aula9.html#importação-dos-dados-e-visualização",
    "href": "Aula9.html#importação-dos-dados-e-visualização",
    "title": "Análise de Modelo Misto, Correlação e Regressão Linear",
    "section": "Importação dos dados e visualização",
    "text": "Importação dos dados e visualização\nQue correlação tem entre a análise dos grupos (diferentes programas que fizeram a análise das imagens)? Definimos como padrão o Assess.\nCorrelação: associação entre duas variáveis. A força da associação é em função da dispersão dos dados, quanto mais diperso, mais fraca é a associação. Quanto mais próximo, menos disperso, são os dados, a associação é mais forte.\nObtém o r (COEFICIENTE DE CORRELAÇÃO) = força de associação entre x e y. Correlação: entre variáveis respostas diferentes.\nCoeficiente de Pearson: -1 &gt; 0 &gt; 1 (correlação negativa e positiva).\nPode obter a significação da correlação através do p-valor.\nCorrelação não quer dizer causalidade: não tem relação de causa e efeito. Exemplo: aumentou o consumo de sorvete e aumentou a temperatura do mar - uma coisa não tem causa e efeito com a outra.\nRegressão: R² (quanto da variação de y é explicado pelo x) = COEFICIENTE DE DETERMINAÇÃO. R² é sempre menor que o r. O R² é sempre menor que r.\n\nimg &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=373270992\")\n\np1 &lt;- img |&gt; \n  ggplot(aes(Assess, ImageJ))+\n  geom_point()+\n  geom_smooth(method = \"lm\")\n\np2 &lt;- img |&gt; \n  ggplot(aes(Assess, LeafDoctor))+\n  geom_point()+\n  geom_smooth(method = \"lm\")\n\nimg |&gt; \n  pivot_longer(3:5, names_to = \"method\",\n               values_to = \"value\") |&gt; \n  ggplot(aes(method, value))+\n  geom_boxplot()\n\n\n\n\n\n\n\np1 + p2\n\n\n\n\n\n\n\n\n\nimg2 &lt;- img |&gt; \n  dplyr::select(Assess, LeafDoctor, ImageJ)\n\nlibrary(AgroR)\ncorgraph(img2)\n\n        Var1       Var2       cor            p\n2 LeafDoctor     Assess 0.9666367 5.972544e-42\n3     ImageJ     Assess 0.9776918 8.143613e-48\n6     ImageJ LeafDoctor 0.9797478 3.144091e-49\n\n\n\n\n\n\n\n\ncor.test(img$Assess, img$LeafDoctor)\n\n\n    Pearson's product-moment correlation\n\ndata:  img$Assess and img$LeafDoctor\nt = 31.119, df = 68, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.9466882 0.9792005\nsample estimates:\n      cor \n0.9666367 \n\ncor(img$Assess, img$LeafDoctor)\n\n[1] 0.9666367\n\nlibrary(corrplot)\ncor_img2 &lt;- cor(img2)\ncorrplot(cor_img2, method = 'number', type = \"lower\")\n\n\n\n\n\n\n\ncor_img2 &lt;- cor(img2)\ncorrplot(cor_img2, method = 'number', type = \"upper\")\n\n\n\n\n\n\n\n\ncor.test dá mais informações do que a função cor. Quanto maior o r, menor o p-valor. P-valor: hipótese alternativa é que a a ccorrelação é igual a 0 (não tem correlação significativa). p-value = &lt; 2.2e-16 indica que a correlação é muito forte (p-valor altamente significativo) o r = 0,98 indica eplevada correlação entre os resultados.\n\ncampo &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=866852711\")\n\ncampo2 &lt;- campo |&gt; \n  dplyr::select(DFC, FER, PROD)\n\ncorgraph(campo2)\n\n  Var1 Var2        cor            p\n2  FER  DFC  0.9316978 9.864101e-15\n3 PROD  DFC -0.6928161 1.110652e-05\n6 PROD  FER -0.6258321 1.277444e-04\n\n\n\n\n\n\n\n\ncor.test(campo$PROD, campo$DFC)\n\n\n    Pearson's product-moment correlation\n\ndata:  campo$PROD and campo$DFC\nt = -5.2623, df = 30, p-value = 1.111e-05\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.8388581 -0.4537361\nsample estimates:\n       cor \n-0.6928161 \n\ncor.test(campo$PROD, campo$FER)\n\n\n    Pearson's product-moment correlation\n\ndata:  campo$PROD and campo$FER\nt = -4.3949, df = 30, p-value = 0.0001277\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.7999565 -0.3544981\nsample estimates:\n       cor \n-0.6258321 \n\n\n\ncampo |&gt;\n  ggplot(aes(DFC, PROD))+\n  geom_point()"
  },
  {
    "objectID": "Aula9.html#importação-dos-dados-e-visualização-dos-dados",
    "href": "Aula9.html#importação-dos-dados-e-visualização-dos-dados",
    "title": "Análise de Modelo Misto, Correlação e Regressão Linear",
    "section": "Importação dos dados e visualização dos dados",
    "text": "Importação dos dados e visualização dos dados\n\npyra &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=465348652\")\n\npyra2 &lt;- pyra |&gt;\n  group_by(code, state, dose) |&gt; \n  summarise(mean_germination = mean(germination))\n\npyra2|&gt; \n  ggplot(aes(dose, mean_germination))+\n  geom_point()+\n  facet_wrap(~code)\n\n\n\n\n\n\n\n\n\nIsolado 186\n\nlibrary(drc)\n\nisolado186 &lt;- pyra2 |&gt; \n   filter(code == \"186\")\n\ndrc1 &lt;- drm(mean_germination ~ dose, data = isolado186,\n            fct = W1.3())\n\nAIC(drc1)\n\n[1] 20.97861\n\nplot(drc1) #para visualizar se o ajuste está bom\n\n\n\n\n\n\n\nED(drc1, 50, interval = \"delta\")\n\n\nEstimated effective doses\n\n       Estimate Std. Error    Lower    Upper\ne:1:50 0.612064   0.015429 0.562963 0.661165\n\nsummary(drc1)\n\n\nModel fitted: Weibull (type 1) with lower limit at 0 (3 parms)\n\nParameter estimates:\n\n               Estimate Std. Error t-value   p-value    \nb:(Intercept)  2.832159   0.213496  13.266 0.0009257 ***\nd:(Intercept) 48.767893   0.716131  68.099 6.978e-06 ***\ne:(Intercept)  0.696626   0.018156  38.368 3.895e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error:\n\n 1.009228 (3 degrees of freedom)\n\n\n\n\nIsolado 165\n\nisolado165 &lt;- pyra2 |&gt; \n  filter(code == \"165\")\n\ndrc2 &lt;- drm(mean_germination ~ dose, data = isolado165,\n            fct = LL.3())\n\nAIC(drc2)\n\n[1] 31.55522\n\nplot(drc2) #para visualizar se o ajuste está bom\n\n\n\n\n\n\n\nED(drc1, 50, interval = \"delta\")\n\n\nEstimated effective doses\n\n       Estimate Std. Error    Lower    Upper\ne:1:50 0.612064   0.015429 0.562963 0.661165\n\n\n\n\nInterpretação:\nAIC: O critério de informação de Akaike (AIC) ajuda a avaliar a qualidade do ajuste do modelo; valores menores indicam melhor ajuste.\nplot(drc1): O gráfico permite visualizar o ajuste do modelo aos dados.\nED(drc1, 50, interval = “delta”): Calcula a dose que causa 50% do efeito máximo esperado (ED50) com um intervalo de confiança delta.\nsummary(drc1): Fornece um resumo detalhado do modelo ajustado, incluindo estimativas dos parâmetros e suas significâncias."
  },
  {
    "objectID": "Aula9.html#ec50",
    "href": "Aula9.html#ec50",
    "title": "Análise de Modelo Misto, Correlação e Regressão Linear",
    "section": "EC50",
    "text": "EC50\n\nlibrary(ec50estimator)\ndf_ec50 &lt;- estimate_EC50(mean_germination ~ dose,\n                         data = pyra2,\n                         isolate_col = \"code\",\n                         interval = \"delta\",\n                         fct = drc::LL.3())\n\ndf_ec50 |&gt; \n  ggplot(aes(reorder(ID, Estimate), Estimate))+\n  geom_point()+\n  geom_errorbar(aes(ymin = Lower, ymax = Upper), width = 0.1)+\n  coord_flip()\n\n\n\n\n\n\n\nprint(df_ec50)\n\n      ID strata   Estimate  Std..Error        Lower     Upper\n1    152        0.44435629 0.077789240  0.196796213 0.6919164\n2    153        0.20379664 0.042373512  0.068945217 0.3386481\n3    164        0.50775844 0.047248266  0.357393370 0.6581235\n4    165        0.55839613 0.114195113  0.194976315 0.9218159\n5    169        0.14722311 0.009555688  0.116812646 0.1776336\n6    170        0.37503889 0.043207328  0.237533889 0.5125439\n7    186        0.57975744 0.013332268  0.537328208 0.6221867\n8    187        0.21563338 0.036639446  0.099030315 0.3322365\n9    188        0.15297172 0.004284691  0.139335920 0.1666075\n10   189        0.53106193 0.023130936  0.457448972 0.6046749\n11 FGT05        0.04483862 0.019290890 -0.016553601 0.1062308\n12 FGT06        0.54497946 0.034834602  0.434120211 0.6558387\n13 FGT07        0.88770053 0.079917704  0.633366725 1.1420343\n14 FGT28        0.22608141 0.033600742  0.119148854 0.3330140\n15 FGT29        0.23601652 0.034933881  0.124841318 0.3471917\n16 FGT33        0.10481627 0.013065221  0.063236910 0.1463956\n17 FGT34        0.14773114 0.047003373 -0.001854568 0.2973169\n18 FGT35        0.20315392 0.038984604  0.079087515 0.3272203\n19 FGT42        0.45000559 0.059685890  0.260058448 0.6399527\n20 FGT43        0.49589549 0.060850771  0.302241178 0.6895498\n\n\n\nExplicação dos Parâmetros:\nmean_germination ~ dose: A fórmula que especifica a variável resposta (mean_germination) e a variável preditora (dose).\ndata = pyra2: O data frame que contém os dados.\nisolate_col = “code”: A coluna que identifica os diferentes isolados.\ninterval = “delta”: O método para calcular os intervalos de confiança.\nfct = drc::LL.3(): A função de ajuste logística de três parâmetros do pacote drc.\n\n\nAtenção\nQuanto maior a EC50, menor a sensibilidade. Ou seja, requer uma quantidade maior de produto, para ter o efeito de redução de 50% A EC50 (concentração efetiva 50) é a concentração de um agente (exemplo, fungicida) que é necessária para obter 50% do efeito máximo desejado. Portanto, a interpretação da EC50 é:\n\nMaior EC50: Indica menor sensibilidade do organismo ao agente. Isso significa que é necessária uma concentração maior do agente para alcançar o efeito desejado.\nMenor EC50: Indica maior sensibilidade do organismo ao agente. Isso significa que uma concentração menor do agente é suficiente para alcançar o efeito desejado\n\nEssa relação é crucial para entender a eficácia e a dosagem necessária de determinado produto."
  },
  {
    "objectID": "Aula6.html",
    "href": "Aula6.html",
    "title": "Teste T e ANOVA",
    "section": "",
    "text": "library(gsheet)\nlibrary(tidyverse)\nlibrary(report)\nlibrary(emmeans)\nlibrary(estimability)\nlibrary(see)\n\n\n\n\nNesta aula, consideramos o alfa = 0,05.\n\n\n\nmg &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=983033137\")\n\n\n\n\nmg |&gt; \n  ggplot(aes(trat, comp))+\n  geom_boxplot()\n\n\n\n\n\n\n\n\nHipótese científica: a suplementação de Mg reduz o tamanho da lesão. Hipótese estatística: H0 = as médias não diferem entre os tratamentos.\nVisualmente: Parece que tem um efeito da suplementação de magnésio reduzindo a redução da lesão. Indica que o Mg tem um efeito de indução de resistência na planta.\n*A diferença entre as medianas dá o tamanho desse efeito.\nPara dois grupos independentes, com normalidade garantida, usa-se normalmente o teste T. É independente porque são dois grupos medidos individualmente (10 plantas para trat control e 10 plantas para Mg2). * Se tivesse avaliações em diferentes tempos na mesma planta, seria dependente, pois a resposta seria dependente da planta.\nO box indica normalidade, de acordo com a simetria e dá uma ideia de variancia, por isso, para conjuntos com n &gt; ou = 8, o boxplot pode ser bom para viasualizar e fazer a estatística inferencial.\n\n\n\nFunção que roda o teste T: t.test\nPara o t.test precisa que os dados estejam no formato largo (a função pede os dados (tratamentos) em colunas separadas).\nTambém precisa verificar: homogeneidade de variâncias e normalidade (Shapiro-wilk test).\n\nmg2 &lt;- mg |&gt; \n  pivot_wider(names_from = trat,\n              values_from = comp)\n\nteste1 &lt;- t.test(mg2$control, mg2$Mg2)\n\nAssummindo que o test T está ok (normalidade e variâncias homogêneas), como o p-valor foi muito menor que 0,05, pode-se rejeitar a hipótese nula (H0). Ou seja, existe um efeito de indução de resistência.\nSe o intervalo de confiança não inclui o 0, dá diferença.\n\n\n\nPode ser feito visualmente, mas existe um teste que avalia a normalidade: shapiro.test No shapiro test a H0 = normalidade. Se p-value for maior do que 0,05, não rejeita H0, ou seja, assume normalidade. Se o p-valor for menor que 0,05, rejeita H0, então assume não normalidade.\nComo para os dois tratamentos foi maior 0,05, assume normalidade para os tratamentos.\n\nshapiro.test(mg2$control)\n\n\n    Shapiro-Wilk normality test\n\ndata:  mg2$control\nW = 0.93886, p-value = 0.5404\n\nhist(mg2$control)\n\n\n\n\n\n\n\nshapiro.test(mg2$Mg2)\n\n\n    Shapiro-Wilk normality test\n\ndata:  mg2$Mg2\nW = 0.97269, p-value = 0.9146\n\nhist(mg2$Mg2)\n\n\n\n\n\n\n\n\n\nnormalmente variáveis numéricas contínuas tendem a apresentar normalidade.\n\nOutra forma de verificar a normalidade:\n\nqqnorm(mg2$control)\nqqline(mg2$control)\n\n\n\n\n\n\n\n\n\n\n\nH0 = as variâncias são homogêneas\nComo valor p é maior que 0,05, assume que são homogeneas\n\nvar.test(mg2$control, mg2$Mg2)\n\n\n    F test to compare two variances\n\ndata:  mg2$control and mg2$Mg2\nF = 0.67654, num df = 9, denom df = 9, p-value = 0.5698\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.1680428 2.7237436\nsample estimates:\nratio of variances \n         0.6765394 \n\n\nComo as variancias e a normalidade estão okay, pode usar o teste T normalmente (tipico caso de análise paramétrica).\nCaso a variancia fosse heterogênea, poderia utilizar o teste T, porém deve informar que as variancias são heterogeneas:\n\nt.test(mg2$control, mg2$Mg2,\n       var.equal = FALSE)\n\n\n    Welch Two Sample t-test\n\ndata:  mg2$control and mg2$Mg2\nt = 8.1549, df = 17.354, p-value = 2.423e-07\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 3.825607 6.490393\nsample estimates:\nmean of x mean of y \n   15.678    10.520 \n\n\n\n\n\nO report cria um “textinnho” sobre o teste T que pode ser utilizado para justificar a estatística.\n\nreport(teste1)\n\nEffect sizes were labelled following Cohen's (1988) recommendations.\n\nThe Welch Two Sample t-test testing the difference between mg2$control and\nmg2$Mg2 (mean of x = 15.68, mean of y = 10.52) suggests that the effect is\npositive, statistically significant, and large (difference = 5.16, 95% CI\n[3.83, 6.49], t(17.35) = 8.15, p &lt; .001; Cohen's d = 3.65, 95% CI [2.14, 5.12])\n\n\n\n\n\n\nDependencia: mesmo avaliador em tempos diferentes\n\nescala &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1729131173\")\n\nComo são dois grupos (avaliação com escala e sem escala), pode usar o Teste T novamente, todavia deve indicar o argumento de que é pareado.\n\n\n\nescala |&gt; \n  ggplot(aes(assessment, acuracia))+\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n\n\nescala2 &lt;- escala |&gt; \n  select(assessment, rater, acuracia) |&gt; \n  pivot_wider(names_from = assessment,\n              values_from = acuracia)\n\nt.test(escala2$Aided1, escala2$Unaided,\n       var.equal = FALSE,\n       paired = TRUE)\n\n\n    Paired t-test\n\ndata:  escala2$Aided1 and escala2$Unaided\nt = 4.4214, df = 9, p-value = 0.001668\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 0.1147647 0.3552353\nsample estimates:\nmean difference \n          0.235 \n\n\np-value &lt; 0,05, por isso, rejeita H0: ou seja há um efeito do uso da escala diagramática aumentando a acurácia dos avaliadores. Como o intervalo de confiança não inclui 0 (varia de 0,113 até 0,252), indica que há diferença significativa.\n\n\n\n\nshapiro.test(escala2$Unaided)\n\n\n    Shapiro-Wilk normality test\n\ndata:  escala2$Unaided\nW = 0.7748, p-value = 0.007155\n\nhist(escala2$Unaided)\n\n\n\n\n\n\n\nshapiro.test(escala2$Aided1)\n\n\n    Shapiro-Wilk normality test\n\ndata:  escala2$Aided1\nW = 0.92852, p-value = 0.4335\n\nhist(escala2$Aided1)\n\n\n\n\n\n\n\n\nH0 = apresenta normalidade Normalidade okay (p-valor &gt; 0,05, ou seja, aceita H0)\n\n\n\n\nvar.test(escala2$Unaided, escala2$Aided1)\n\n\n    F test to compare two variances\n\ndata:  escala2$Unaided and escala2$Aided1\nF = 20.978, num df = 9, denom df = 9, p-value = 0.000106\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n  5.210754 84.459185\nsample estimates:\nratio of variances \n          20.97847 \n\n\nH0 = variâncias são homogêneas Variâncias são heterogêneas (p-value &lt; 0,05, rejeita H0)\n\n\n\n\nHouve uma modificação nos dados (Escala) para que fiquem não paramétricos.\n\n\n\nescala &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1729131173\")\n\nescala |&gt; \n  ggplot(aes(assessment, acuracia))+\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n\n\nescala2 &lt;- escala |&gt; \n  select(assessment, rater, acuracia) |&gt; \n  pivot_wider(names_from = assessment,\n              values_from = acuracia)\n\n\nshapiro.test(escala2$Unaided)\n\n\n    Shapiro-Wilk normality test\n\ndata:  escala2$Unaided\nW = 0.7748, p-value = 0.007155\n\nhist(escala2$Unaided)\n\n\n\n\n\n\n\nshapiro.test(escala2$Aided1)\n\n\n    Shapiro-Wilk normality test\n\ndata:  escala2$Aided1\nW = 0.92852, p-value = 0.4335\n\nhist(escala2$Aided1)\n\n\n\n\n\n\n\n\nComo o p-valor é menor que 0,05, rejeita H0, dessa forma, não apresenta normalidade. A partir daí utilizaremos outro teste, equivalente ao Teste T, mas que usa-se para dados não paramétricos.\n\n\n\nNão precisa verificar as variâncias.\n\nwilcox.test(escala2$Aided1,\n            escala2$Unaided,\n            paired = TRUE)\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  escala2$Aided1 and escala2$Unaided\nV = 55, p-value = 0.005889\nalternative hypothesis: true location shift is not equal to 0\n\n\nComo o p-valor é menor que 0,05, rejeita H0, dessa forma as médias são diferentes. Ou seja, há um efeito do uso da escala diagramática aumentando a acurácia dos avaliadores.\nSe os dados não atenderem as pressimas para análise paramétrica, pode-se usar um teste não paramétrico, ou, fazer a transformação dos dados, para que esses valores transformados possam atender as premissas. Porém, ao se usar os dados transformados, não está usando os dados originais (não está errado, é apenas uma metodologia diferente).\nt.test -&gt; pareado (paired = “TRUE”) -&gt; não-pareado (paired = “FALSE” - não precisa porque já assume isso)\n   -&gt; variâncias homogêneas (var.equal = TRUE - não precisa porque já assume isso)\n   -&gt; variâncias heterogêneas (var.equal = FALSE)\n   \nwilcox.test -&gt; pareado (paired = TRUE) não-pareado (paired = FALSE) = Mann-Whitney test\n\n\n\n\nANOVA: Hipótese alternativa é que pelo menos uma média é diferente das outras. Mas não diz qual média é diferente das outras, para isso, usa o teste de comparação de médias. H0 = as médias não diferem.\ntcm = taxa de crescimento micelial\n\nmicelial &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=959387827\")\n\n\n\n\nmicelial |&gt; \n  ggplot(aes(especie, tcm))+\n  geom_jitter(width = 0.01)+\n  stat_summary(\n    geom = \"point\",\n    fun.y = \"mean\",\n    size = 3,\n    color = \"red\"\n  )\n\n\n\n\n\n\n\n\nVisualmente: parece que a dispersão dos dados é muito grande, dessa forma não parece haver muita diferença entre os grupos.\nTeste F: é a razão da variância entre os grupos sobre a variância dentro dos grupos.\n\n\n\n\nm1 &lt;- lm(tcm ~especie, data = micelial)\n\nanova(m1)\n\nAnalysis of Variance Table\n\nResponse: tcm\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nespecie    4 1.46958 0.36739  19.629 2.028e-07 ***\nResiduals 25 0.46792 0.01872                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(m1)\n\n\nCall:\nlm(formula = tcm ~ especie, data = micelial)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.23667 -0.09667  0.01583  0.08833  0.28333 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.57167    0.05585  28.140  &lt; 2e-16 ***\nespecieFaus -0.33500    0.07899  -4.241 0.000266 ***\nespecieFcor -0.25000    0.07899  -3.165 0.004047 ** \nespecieFgra -0.66000    0.07899  -8.356 1.05e-08 ***\nespecieFmer -0.14500    0.07899  -1.836 0.078317 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1368 on 25 degrees of freedom\nMultiple R-squared:  0.7585,    Adjusted R-squared:  0.7199 \nF-statistic: 19.63 on 4 and 25 DF,  p-value: 2.028e-07\n\n\nDF = grau de liberdade Sum Sq = é a soma dos quadrados Mean SQ = média da soma dos quadrados (variância) F value (valor F) = variância da espécie/média de residuals Quanto &gt; o F, &lt; o p-valor\nComo p-valor &gt; 0,05 (0,055), não descartamos H0, ou seja, não a diferença entre as médias. Ou seja, não há diferença entre o crescimento micelial das espécies.\nPara retirar o intercepto e dar os valores médios direto\n\nm1 &lt;- lm(tcm ~especie -1, data = micelial)\n\nanova(m1)\n\nAnalysis of Variance Table\n\nResponse: tcm\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nespecie    5 51.677 10.3354   552.2 &lt; 2.2e-16 ***\nResiduals 25  0.468  0.0187                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(m1)\n\n\nCall:\nlm(formula = tcm ~ especie - 1, data = micelial)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.23667 -0.09667  0.01583  0.08833  0.28333 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \nespecieFasi  1.57167    0.05585   28.14  &lt; 2e-16 ***\nespecieFaus  1.23667    0.05585   22.14  &lt; 2e-16 ***\nespecieFcor  1.32167    0.05585   23.66  &lt; 2e-16 ***\nespecieFgra  0.91167    0.05585   16.32 7.66e-15 ***\nespecieFmer  1.42667    0.05585   25.54  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1368 on 25 degrees of freedom\nMultiple R-squared:  0.991, Adjusted R-squared:  0.9892 \nF-statistic: 552.2 on 5 and 25 DF,  p-value: &lt; 2.2e-16\n\n\nPara ter variabilidade, modificamos os dados, para ter efeito de espécie.\n\nmicelial &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=959387827\")\n\nmicelial |&gt; \n  ggplot(aes(especie, tcm))+\n  geom_jitter(width = 0.01)+\n  stat_summary(\n    geom = \"point\",\n    fun.y = \"mean\",\n    size = 3,\n    color = \"red\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nm1 &lt;- lm(tcm ~especie, data = micelial)\n\nanova(m1)\n\nAnalysis of Variance Table\n\nResponse: tcm\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nespecie    4 1.46958 0.36739  19.629 2.028e-07 ***\nResiduals 25 0.46792 0.01872                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(m1) #&lt;- visualiza a diferença entre os grupos\n\n\nCall:\nlm(formula = tcm ~ especie, data = micelial)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.23667 -0.09667  0.01583  0.08833  0.28333 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.57167    0.05585  28.140  &lt; 2e-16 ***\nespecieFaus -0.33500    0.07899  -4.241 0.000266 ***\nespecieFcor -0.25000    0.07899  -3.165 0.004047 ** \nespecieFgra -0.66000    0.07899  -8.356 1.05e-08 ***\nespecieFmer -0.14500    0.07899  -1.836 0.078317 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1368 on 25 degrees of freedom\nMultiple R-squared:  0.7585,    Adjusted R-squared:  0.7199 \nF-statistic: 19.63 on 4 and 25 DF,  p-value: 2.028e-07\n\n\nComo valor-p &lt; 0,05 (2.028e-07), rejeitamos H0, dessa forma, pelo menos uma espécie difere das outras.\n\no summary compara a média de todos com asiaticus (intercepto) e não de todos contra todos.\n\n\n\n\n\n\n\nmedias1 &lt;- emmeans(m1, ~especie)\n\nlibrary(multcomp)\nlibrary(multcompView) #para colocar as letrinhas\ncld(medias1)\n\n especie emmean     SE df lower.CL upper.CL .group\n Fgra     0.912 0.0559 25    0.797     1.03  1    \n Faus     1.237 0.0559 25    1.122     1.35   2   \n Fcor     1.322 0.0559 25    1.207     1.44   2   \n Fmer     1.427 0.0559 25    1.312     1.54   23  \n Fasi     1.572 0.0559 25    1.457     1.69    3  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 5 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\n\n\n#Para verificar normalidade:\nhist(m1$residuals)\n\n\n\n\n\n\n\nshapiro.test(m1$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  m1$residuals\nW = 0.9821, p-value = 0.8782\n\n#Para verificar as variâncias:\nbartlett.test(tcm ~especie, data = micelial)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  tcm by especie\nBartlett's K-squared = 4.4367, df = 4, p-value = 0.3501\n\nlibrary(DHARMa)\nplot(simulateResiduals(m1))\n\n\n\n\n\n\n\nlibrary(performance)\ncheck_normality(m1)\n\nOK: residuals appear as normally distributed (p = 0.878).\n\ncheck_heteroscedasticity(m1) #(variâncias homogêneas = homoscedastic)\n\nOK: Error variance appears to be homoscedastic (p = 0.880).\n\ncheck_model(m1)"
  },
  {
    "objectID": "Aula6.html#bibliotecas",
    "href": "Aula6.html#bibliotecas",
    "title": "Teste T e ANOVA",
    "section": "",
    "text": "library(gsheet)\nlibrary(tidyverse)\nlibrary(report)\nlibrary(emmeans)\nlibrary(estimability)\nlibrary(see)"
  },
  {
    "objectID": "Aula6.html#inferencial",
    "href": "Aula6.html#inferencial",
    "title": "Teste T e ANOVA",
    "section": "",
    "text": "Nesta aula, consideramos o alfa = 0,05.\n\n\n\nmg &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=983033137\")\n\n\n\n\nmg |&gt; \n  ggplot(aes(trat, comp))+\n  geom_boxplot()\n\n\n\n\n\n\n\n\nHipótese científica: a suplementação de Mg reduz o tamanho da lesão. Hipótese estatística: H0 = as médias não diferem entre os tratamentos.\nVisualmente: Parece que tem um efeito da suplementação de magnésio reduzindo a redução da lesão. Indica que o Mg tem um efeito de indução de resistência na planta.\n*A diferença entre as medianas dá o tamanho desse efeito.\nPara dois grupos independentes, com normalidade garantida, usa-se normalmente o teste T. É independente porque são dois grupos medidos individualmente (10 plantas para trat control e 10 plantas para Mg2). * Se tivesse avaliações em diferentes tempos na mesma planta, seria dependente, pois a resposta seria dependente da planta.\nO box indica normalidade, de acordo com a simetria e dá uma ideia de variancia, por isso, para conjuntos com n &gt; ou = 8, o boxplot pode ser bom para viasualizar e fazer a estatística inferencial.\n\n\n\nFunção que roda o teste T: t.test\nPara o t.test precisa que os dados estejam no formato largo (a função pede os dados (tratamentos) em colunas separadas).\nTambém precisa verificar: homogeneidade de variâncias e normalidade (Shapiro-wilk test).\n\nmg2 &lt;- mg |&gt; \n  pivot_wider(names_from = trat,\n              values_from = comp)\n\nteste1 &lt;- t.test(mg2$control, mg2$Mg2)\n\nAssummindo que o test T está ok (normalidade e variâncias homogêneas), como o p-valor foi muito menor que 0,05, pode-se rejeitar a hipótese nula (H0). Ou seja, existe um efeito de indução de resistência.\nSe o intervalo de confiança não inclui o 0, dá diferença.\n\n\n\nPode ser feito visualmente, mas existe um teste que avalia a normalidade: shapiro.test No shapiro test a H0 = normalidade. Se p-value for maior do que 0,05, não rejeita H0, ou seja, assume normalidade. Se o p-valor for menor que 0,05, rejeita H0, então assume não normalidade.\nComo para os dois tratamentos foi maior 0,05, assume normalidade para os tratamentos.\n\nshapiro.test(mg2$control)\n\n\n    Shapiro-Wilk normality test\n\ndata:  mg2$control\nW = 0.93886, p-value = 0.5404\n\nhist(mg2$control)\n\n\n\n\n\n\n\nshapiro.test(mg2$Mg2)\n\n\n    Shapiro-Wilk normality test\n\ndata:  mg2$Mg2\nW = 0.97269, p-value = 0.9146\n\nhist(mg2$Mg2)\n\n\n\n\n\n\n\n\n\nnormalmente variáveis numéricas contínuas tendem a apresentar normalidade.\n\nOutra forma de verificar a normalidade:\n\nqqnorm(mg2$control)\nqqline(mg2$control)\n\n\n\n\n\n\n\n\n\n\n\nH0 = as variâncias são homogêneas\nComo valor p é maior que 0,05, assume que são homogeneas\n\nvar.test(mg2$control, mg2$Mg2)\n\n\n    F test to compare two variances\n\ndata:  mg2$control and mg2$Mg2\nF = 0.67654, num df = 9, denom df = 9, p-value = 0.5698\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.1680428 2.7237436\nsample estimates:\nratio of variances \n         0.6765394 \n\n\nComo as variancias e a normalidade estão okay, pode usar o teste T normalmente (tipico caso de análise paramétrica).\nCaso a variancia fosse heterogênea, poderia utilizar o teste T, porém deve informar que as variancias são heterogeneas:\n\nt.test(mg2$control, mg2$Mg2,\n       var.equal = FALSE)\n\n\n    Welch Two Sample t-test\n\ndata:  mg2$control and mg2$Mg2\nt = 8.1549, df = 17.354, p-value = 2.423e-07\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 3.825607 6.490393\nsample estimates:\nmean of x mean of y \n   15.678    10.520 \n\n\n\n\n\nO report cria um “textinnho” sobre o teste T que pode ser utilizado para justificar a estatística.\n\nreport(teste1)\n\nEffect sizes were labelled following Cohen's (1988) recommendations.\n\nThe Welch Two Sample t-test testing the difference between mg2$control and\nmg2$Mg2 (mean of x = 15.68, mean of y = 10.52) suggests that the effect is\npositive, statistically significant, and large (difference = 5.16, 95% CI\n[3.83, 6.49], t(17.35) = 8.15, p &lt; .001; Cohen's d = 3.65, 95% CI [2.14, 5.12])\n\n\n\n\n\n\nDependencia: mesmo avaliador em tempos diferentes\n\nescala &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1729131173\")\n\nComo são dois grupos (avaliação com escala e sem escala), pode usar o Teste T novamente, todavia deve indicar o argumento de que é pareado.\n\n\n\nescala |&gt; \n  ggplot(aes(assessment, acuracia))+\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n\n\nescala2 &lt;- escala |&gt; \n  select(assessment, rater, acuracia) |&gt; \n  pivot_wider(names_from = assessment,\n              values_from = acuracia)\n\nt.test(escala2$Aided1, escala2$Unaided,\n       var.equal = FALSE,\n       paired = TRUE)\n\n\n    Paired t-test\n\ndata:  escala2$Aided1 and escala2$Unaided\nt = 4.4214, df = 9, p-value = 0.001668\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 0.1147647 0.3552353\nsample estimates:\nmean difference \n          0.235 \n\n\np-value &lt; 0,05, por isso, rejeita H0: ou seja há um efeito do uso da escala diagramática aumentando a acurácia dos avaliadores. Como o intervalo de confiança não inclui 0 (varia de 0,113 até 0,252), indica que há diferença significativa.\n\n\n\n\nshapiro.test(escala2$Unaided)\n\n\n    Shapiro-Wilk normality test\n\ndata:  escala2$Unaided\nW = 0.7748, p-value = 0.007155\n\nhist(escala2$Unaided)\n\n\n\n\n\n\n\nshapiro.test(escala2$Aided1)\n\n\n    Shapiro-Wilk normality test\n\ndata:  escala2$Aided1\nW = 0.92852, p-value = 0.4335\n\nhist(escala2$Aided1)\n\n\n\n\n\n\n\n\nH0 = apresenta normalidade Normalidade okay (p-valor &gt; 0,05, ou seja, aceita H0)\n\n\n\n\nvar.test(escala2$Unaided, escala2$Aided1)\n\n\n    F test to compare two variances\n\ndata:  escala2$Unaided and escala2$Aided1\nF = 20.978, num df = 9, denom df = 9, p-value = 0.000106\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n  5.210754 84.459185\nsample estimates:\nratio of variances \n          20.97847 \n\n\nH0 = variâncias são homogêneas Variâncias são heterogêneas (p-value &lt; 0,05, rejeita H0)\n\n\n\n\nHouve uma modificação nos dados (Escala) para que fiquem não paramétricos.\n\n\n\nescala &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1729131173\")\n\nescala |&gt; \n  ggplot(aes(assessment, acuracia))+\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n\n\nescala2 &lt;- escala |&gt; \n  select(assessment, rater, acuracia) |&gt; \n  pivot_wider(names_from = assessment,\n              values_from = acuracia)\n\n\nshapiro.test(escala2$Unaided)\n\n\n    Shapiro-Wilk normality test\n\ndata:  escala2$Unaided\nW = 0.7748, p-value = 0.007155\n\nhist(escala2$Unaided)\n\n\n\n\n\n\n\nshapiro.test(escala2$Aided1)\n\n\n    Shapiro-Wilk normality test\n\ndata:  escala2$Aided1\nW = 0.92852, p-value = 0.4335\n\nhist(escala2$Aided1)\n\n\n\n\n\n\n\n\nComo o p-valor é menor que 0,05, rejeita H0, dessa forma, não apresenta normalidade. A partir daí utilizaremos outro teste, equivalente ao Teste T, mas que usa-se para dados não paramétricos.\n\n\n\nNão precisa verificar as variâncias.\n\nwilcox.test(escala2$Aided1,\n            escala2$Unaided,\n            paired = TRUE)\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  escala2$Aided1 and escala2$Unaided\nV = 55, p-value = 0.005889\nalternative hypothesis: true location shift is not equal to 0\n\n\nComo o p-valor é menor que 0,05, rejeita H0, dessa forma as médias são diferentes. Ou seja, há um efeito do uso da escala diagramática aumentando a acurácia dos avaliadores.\nSe os dados não atenderem as pressimas para análise paramétrica, pode-se usar um teste não paramétrico, ou, fazer a transformação dos dados, para que esses valores transformados possam atender as premissas. Porém, ao se usar os dados transformados, não está usando os dados originais (não está errado, é apenas uma metodologia diferente).\nt.test -&gt; pareado (paired = “TRUE”) -&gt; não-pareado (paired = “FALSE” - não precisa porque já assume isso)\n   -&gt; variâncias homogêneas (var.equal = TRUE - não precisa porque já assume isso)\n   -&gt; variâncias heterogêneas (var.equal = FALSE)\n   \nwilcox.test -&gt; pareado (paired = TRUE) não-pareado (paired = FALSE) = Mann-Whitney test\n\n\n\n\nANOVA: Hipótese alternativa é que pelo menos uma média é diferente das outras. Mas não diz qual média é diferente das outras, para isso, usa o teste de comparação de médias. H0 = as médias não diferem.\ntcm = taxa de crescimento micelial\n\nmicelial &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=959387827\")\n\n\n\n\nmicelial |&gt; \n  ggplot(aes(especie, tcm))+\n  geom_jitter(width = 0.01)+\n  stat_summary(\n    geom = \"point\",\n    fun.y = \"mean\",\n    size = 3,\n    color = \"red\"\n  )\n\n\n\n\n\n\n\n\nVisualmente: parece que a dispersão dos dados é muito grande, dessa forma não parece haver muita diferença entre os grupos.\nTeste F: é a razão da variância entre os grupos sobre a variância dentro dos grupos.\n\n\n\n\nm1 &lt;- lm(tcm ~especie, data = micelial)\n\nanova(m1)\n\nAnalysis of Variance Table\n\nResponse: tcm\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nespecie    4 1.46958 0.36739  19.629 2.028e-07 ***\nResiduals 25 0.46792 0.01872                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(m1)\n\n\nCall:\nlm(formula = tcm ~ especie, data = micelial)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.23667 -0.09667  0.01583  0.08833  0.28333 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.57167    0.05585  28.140  &lt; 2e-16 ***\nespecieFaus -0.33500    0.07899  -4.241 0.000266 ***\nespecieFcor -0.25000    0.07899  -3.165 0.004047 ** \nespecieFgra -0.66000    0.07899  -8.356 1.05e-08 ***\nespecieFmer -0.14500    0.07899  -1.836 0.078317 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1368 on 25 degrees of freedom\nMultiple R-squared:  0.7585,    Adjusted R-squared:  0.7199 \nF-statistic: 19.63 on 4 and 25 DF,  p-value: 2.028e-07\n\n\nDF = grau de liberdade Sum Sq = é a soma dos quadrados Mean SQ = média da soma dos quadrados (variância) F value (valor F) = variância da espécie/média de residuals Quanto &gt; o F, &lt; o p-valor\nComo p-valor &gt; 0,05 (0,055), não descartamos H0, ou seja, não a diferença entre as médias. Ou seja, não há diferença entre o crescimento micelial das espécies.\nPara retirar o intercepto e dar os valores médios direto\n\nm1 &lt;- lm(tcm ~especie -1, data = micelial)\n\nanova(m1)\n\nAnalysis of Variance Table\n\nResponse: tcm\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nespecie    5 51.677 10.3354   552.2 &lt; 2.2e-16 ***\nResiduals 25  0.468  0.0187                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(m1)\n\n\nCall:\nlm(formula = tcm ~ especie - 1, data = micelial)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.23667 -0.09667  0.01583  0.08833  0.28333 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \nespecieFasi  1.57167    0.05585   28.14  &lt; 2e-16 ***\nespecieFaus  1.23667    0.05585   22.14  &lt; 2e-16 ***\nespecieFcor  1.32167    0.05585   23.66  &lt; 2e-16 ***\nespecieFgra  0.91167    0.05585   16.32 7.66e-15 ***\nespecieFmer  1.42667    0.05585   25.54  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1368 on 25 degrees of freedom\nMultiple R-squared:  0.991, Adjusted R-squared:  0.9892 \nF-statistic: 552.2 on 5 and 25 DF,  p-value: &lt; 2.2e-16\n\n\nPara ter variabilidade, modificamos os dados, para ter efeito de espécie.\n\nmicelial &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=959387827\")\n\nmicelial |&gt; \n  ggplot(aes(especie, tcm))+\n  geom_jitter(width = 0.01)+\n  stat_summary(\n    geom = \"point\",\n    fun.y = \"mean\",\n    size = 3,\n    color = \"red\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nm1 &lt;- lm(tcm ~especie, data = micelial)\n\nanova(m1)\n\nAnalysis of Variance Table\n\nResponse: tcm\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nespecie    4 1.46958 0.36739  19.629 2.028e-07 ***\nResiduals 25 0.46792 0.01872                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(m1) #&lt;- visualiza a diferença entre os grupos\n\n\nCall:\nlm(formula = tcm ~ especie, data = micelial)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.23667 -0.09667  0.01583  0.08833  0.28333 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.57167    0.05585  28.140  &lt; 2e-16 ***\nespecieFaus -0.33500    0.07899  -4.241 0.000266 ***\nespecieFcor -0.25000    0.07899  -3.165 0.004047 ** \nespecieFgra -0.66000    0.07899  -8.356 1.05e-08 ***\nespecieFmer -0.14500    0.07899  -1.836 0.078317 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1368 on 25 degrees of freedom\nMultiple R-squared:  0.7585,    Adjusted R-squared:  0.7199 \nF-statistic: 19.63 on 4 and 25 DF,  p-value: 2.028e-07\n\n\nComo valor-p &lt; 0,05 (2.028e-07), rejeitamos H0, dessa forma, pelo menos uma espécie difere das outras.\n\no summary compara a média de todos com asiaticus (intercepto) e não de todos contra todos."
  },
  {
    "objectID": "Aula6.html#para-verificar-a-diferença-entre-as-médias",
    "href": "Aula6.html#para-verificar-a-diferença-entre-as-médias",
    "title": "Teste T e ANOVA",
    "section": "",
    "text": "medias1 &lt;- emmeans(m1, ~especie)\n\nlibrary(multcomp)\nlibrary(multcompView) #para colocar as letrinhas\ncld(medias1)\n\n especie emmean     SE df lower.CL upper.CL .group\n Fgra     0.912 0.0559 25    0.797     1.03  1    \n Faus     1.237 0.0559 25    1.122     1.35   2   \n Fcor     1.322 0.0559 25    1.207     1.44   2   \n Fmer     1.427 0.0559 25    1.312     1.54   23  \n Fasi     1.572 0.0559 25    1.457     1.69    3  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 5 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\n\n\n#Para verificar normalidade:\nhist(m1$residuals)\n\n\n\n\n\n\n\nshapiro.test(m1$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  m1$residuals\nW = 0.9821, p-value = 0.8782\n\n#Para verificar as variâncias:\nbartlett.test(tcm ~especie, data = micelial)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  tcm by especie\nBartlett's K-squared = 4.4367, df = 4, p-value = 0.3501\n\nlibrary(DHARMa)\nplot(simulateResiduals(m1))\n\n\n\n\n\n\n\nlibrary(performance)\ncheck_normality(m1)\n\nOK: residuals appear as normally distributed (p = 0.878).\n\ncheck_heteroscedasticity(m1) #(variâncias homogêneas = homoscedastic)\n\nOK: Error variance appears to be homoscedastic (p = 0.880).\n\ncheck_model(m1)"
  },
  {
    "objectID": "Aula6.html#importação-dos-dados",
    "href": "Aula6.html#importação-dos-dados",
    "title": "Teste T e ANOVA",
    "section": "Importação dos dados",
    "text": "Importação dos dados\n\ninseticida &lt;- InsectSprays\n\ninseticida |&gt; \n  count(spray)\n\n  spray  n\n1     A 12\n2     B 12\n3     C 12\n4     D 12\n5     E 12\n6     F 12\n\n\n12 repetições para cada spray. tem um fator só (inseticida = spray) -&gt; vai ser Anova unifatorial (um fator só com seis níveis).\n\nVisualização\nVer se tem normalidade dos resíduos e homogeneidade entre as variâncias.\n\ninseticida |&gt; \n  ggplot(aes(spray, count))+\n  geom_boxplot()\n\n\n\n\n\n\n\n\nF é o que tem maior variância, o que tem menor é o C e D (tem outlier), parece que (visualmente) as variâncias não são homogêneas.\n1º Ajusta ANOVA 2º trabalha com resíduos da ANOVA (aplica os testes)\nlm = função que ajusta anova\n\nm1 &lt;- lm(count ~ spray,\n         data = inseticida)\n\nsummary(m1)\n\n\nCall:\nlm(formula = count ~ spray, data = inseticida)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-8.333 -1.958 -0.500  1.667  9.333 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  14.5000     1.1322  12.807  &lt; 2e-16 ***\nsprayB        0.8333     1.6011   0.520    0.604    \nsprayC      -12.4167     1.6011  -7.755 7.27e-11 ***\nsprayD       -9.5833     1.6011  -5.985 9.82e-08 ***\nsprayE      -11.0000     1.6011  -6.870 2.75e-09 ***\nsprayF        2.1667     1.6011   1.353    0.181    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.922 on 66 degrees of freedom\nMultiple R-squared:  0.7244,    Adjusted R-squared:  0.7036 \nF-statistic:  34.7 on 5 and 66 DF,  p-value: &lt; 2.2e-16\n\nanova(m1)\n\nAnalysis of Variance Table\n\nResponse: count\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nspray      5 2668.8  533.77  34.702 &lt; 2.2e-16 ***\nResiduals 66 1015.2   15.38                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nhist(m1$residuals)\n\n\n\n\n\n\n\nshapiro.test(m1$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  m1$residuals\nW = 0.96006, p-value = 0.02226\n\nqqnorm(m1$residuals)\nqqline(m1$residuals)\n\n\n\n\n\n\n\nbartlett.test(count ~ spray,\n             data = inseticida)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  count by spray\nBartlett's K-squared = 25.96, df = 5, p-value = 9.085e-05\n\n\nOs resíduos parecem ter normalidade visualizando pelo histograma. AO fazer o shapiro.test, vê-se que não tem normalidade, pq o p-valor &lt; 0,05, então rejeita H0 (H0 = normalidade).\nMais grave: variâncias não serem homogêneas, do que normalidade.\n\nlibrary(performance)\ncheck_normality(m1)\n\nWarning: Non-normality of residuals detected (p = 0.022).\n\ncheck_heteroscedasticity(m1)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p &lt; .001).\n\nlibrary(DHARMa)\nplot(simulateResiduals(m1))\n\n\n\n\n\n\n\n\nCom performance e DHARma, foi possível ver que não tem normalidade e que as variâncias são heterogêneas. O DHARma faz o outro test (KS test) – saída das variâncias com texto em vermelho indica que as variâncias são heterogêneas.\nTranformações mais comuns: log de x (quando tem 0, adiciona a constante + 0,5) raiz quadrada de x arc seno de x\n\n\nAlternativa 1: fazer a transformação dos dados\nNormalmente, quando tem contagem (numérica discreta), raiz quadrada resolve.\nFunção sqrt faz a raiz quadrada.\n\ninseticida &lt;- inseticida |&gt; \n  mutate(count2 = sqrt(count))\n\ninseticida |&gt; \n  ggplot(aes(spray, count2))+\n  geom_boxplot()\n\n\n\n\n\n\n\n\nAgora, variancias parecem mais iguais, dessa forma, visualmente parece que a raiz quadrada está homogeneizando as variâncias.\n\nm2 &lt;- lm(count2 ~ spray,\n         data = inseticida)\n\nsummary(m2)\n\n\nCall:\nlm(formula = count2 ~ spray, data = inseticida)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.24486 -0.39970 -0.01902  0.42661  1.40089 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   3.7607     0.1814  20.733  &lt; 2e-16 ***\nsprayB        0.1160     0.2565   0.452    0.653    \nsprayC       -2.5158     0.2565  -9.807 1.64e-14 ***\nsprayD       -1.5963     0.2565  -6.223 3.80e-08 ***\nsprayE       -1.9512     0.2565  -7.606 1.34e-10 ***\nsprayF        0.2579     0.2565   1.006    0.318    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6283 on 66 degrees of freedom\nMultiple R-squared:  0.7724,    Adjusted R-squared:  0.7552 \nF-statistic:  44.8 on 5 and 66 DF,  p-value: &lt; 2.2e-16\n\nanova(m2)\n\nAnalysis of Variance Table\n\nResponse: count2\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nspray      5 88.438 17.6876  44.799 &lt; 2.2e-16 ***\nResiduals 66 26.058  0.3948                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nhist(m2$residuals)\n\n\n\n\n\n\n\nshapiro.test(m2$residuals)  # tem normalidade\n\n\n    Shapiro-Wilk normality test\n\ndata:  m2$residuals\nW = 0.98721, p-value = 0.6814\n\nqqnorm(m2$residuals)\nqqline(m2$residuals)\n\n\n\n\n\n\n\nbartlett.test(count2 ~spray,\n             data = inseticida)  # tem homgeneidade das variâncias\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  count2 by spray\nBartlett's K-squared = 3.7525, df = 5, p-value = 0.5856\n\n\nCom a transformação alcançou a normalidade e homogeneidade de variancias. Em anova(m2) pode ver que pelo menos um grupo difere dos demais (p-valor &lt; 0,05)\n\nlibrary(performance)\ncheck_normality(m2)\n\nOK: residuals appear as normally distributed (p = 0.681).\n\ncheck_heteroscedasticity(m2)\n\nOK: Error variance appears to be homoscedastic (p = 0.854).\n\nlibrary(DHARMa)\nplot(simulateResiduals(m2)) #melhorou ainda mais a normmalidade e variância deu ñ significativo\n\n\n\n\n\n\n\n\nQuando for avaliar, utilizar os diferentes testes para garantir confiabilidade. ANOVa é um teste mais robusto à falta de normalidade do que à heterocedasticidade.\n\n# Para m1 (dados não transformados)\nlibrary(emmeans)\nm1_medias &lt;- emmeans(m1, ~ spray,)\nplot(m1_medias)\n\n\n\n\n\n\n\nlibrary(multcomp)\ncld(m1_medias)\n\n spray emmean   SE df lower.CL upper.CL .group\n C       2.08 1.13 66   -0.177     4.34  1    \n E       3.50 1.13 66    1.240     5.76  1    \n D       4.92 1.13 66    2.656     7.18  1    \n A      14.50 1.13 66   12.240    16.76   2   \n B      15.33 1.13 66   13.073    17.59   2   \n F      16.67 1.13 66   14.406    18.93   2   \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n# Para m2 (dados transformados)\nlibrary(emmeans)\nm2_medias &lt;- emmeans(m2, ~ spray,)\nplot(m2_medias)\n\n\n\n\n\n\n\nlibrary(multcomp)\ncld(m2_medias)\n\n spray emmean    SE df lower.CL upper.CL .group\n C       1.24 0.181 66    0.883     1.61  1    \n E       1.81 0.181 66    1.447     2.17  12   \n D       2.16 0.181 66    1.802     2.53   2   \n A       3.76 0.181 66    3.399     4.12    3  \n B       3.88 0.181 66    3.514     4.24    3  \n F       4.02 0.181 66    3.656     4.38    3  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\npwpm(m2_medias)\n\n       A      B      C      D      E      F\nA [3.76] 0.9975 &lt;.0001 &lt;.0001 &lt;.0001 0.9145\nB -0.116 [3.88] &lt;.0001 &lt;.0001 &lt;.0001 0.9936\nC  2.516  2.632 [1.24] 0.0081 0.2513 &lt;.0001\nD  1.596  1.712 -0.919 [2.16] 0.7366 &lt;.0001\nE  1.951  2.067 -0.565  0.355 [1.81] &lt;.0001\nF -0.258 -0.142 -2.774 -1.854 -2.209 [4.02]\n\nRow and column labels: spray\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\npwpp(m2_medias)\n\n\n\n\n\n\n\npairs(m2_medias)\n\n contrast estimate    SE df t.ratio p.value\n A - B      -0.116 0.257 66  -0.452  0.9975\n A - C       2.516 0.257 66   9.807  &lt;.0001\n A - D       1.596 0.257 66   6.223  &lt;.0001\n A - E       1.951 0.257 66   7.606  &lt;.0001\n A - F      -0.258 0.257 66  -1.006  0.9145\n B - C       2.632 0.257 66  10.259  &lt;.0001\n B - D       1.712 0.257 66   6.675  &lt;.0001\n B - E       2.067 0.257 66   8.058  &lt;.0001\n B - F      -0.142 0.257 66  -0.554  0.9936\n C - D      -0.919 0.257 66  -3.584  0.0081\n C - E      -0.565 0.257 66  -2.201  0.2513\n C - F      -2.774 0.257 66 -10.813  &lt;.0001\n D - E       0.355 0.257 66   1.383  0.7366\n D - F      -1.854 0.257 66  -7.229  &lt;.0001\n E - F      -2.209 0.257 66  -8.612  &lt;.0001\n\nP value adjustment: tukey method for comparing a family of 6 estimates \n\n# quando usa os dados não transformados tá cometendo o erro do tipo 2, não estava mostrando a diferença quando existia (mostrou só 2 grupos e quando com dados transformados dividiu em 3)\n\nUtilizando o pwpm mostrou a comparação entre cada um dos grupos (comparação par a par). Quando o valor (é igual ao p-valor) é &lt; 0,05, diz que são de grupos diferentes (rejeita H0), enquanto valor &gt; 0,05, pertencem ao mesmo grupo (não rejeita H0).\n\nTestando outras formas de transformação\nBox-Cox: y(lambda) = (x^lambda -1)/lambda lambda é o valor de x onde o y é máximo Sempre que o lambda = 0,5 é igual a raiz quadrado\n\nlibrary(MASS)\nb &lt;- boxcox(lm(inseticida$count+0.1 ~1))\n\n\n\n\n\n\n\nlambda &lt;- b$x[which.max(b$y)]\n\n# O lambda (0,42) é o que usaremos na fórmula para transformar os dados --&gt; variável transformada\n\n#Usando o lambda (0,42) na fórmula: y(lambda) = (x^lambda -1)/lambda\ninseticida$count3 &lt;- (inseticida$count ^ lambda - 1) / lambda\n\nm5 &lt;- lm(count3 ~ spray,\n         data = inseticida)\n\nsummary(m5)\n\n\nCall:\nlm(formula = count3 ~ spray, data = inseticida)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.74114 -0.65893 -0.01922  0.78560  2.64047 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   4.8835     0.3232  15.109  &lt; 2e-16 ***\nsprayB        0.1910     0.4571   0.418    0.677    \nsprayC       -4.4995     0.4571  -9.843 1.42e-14 ***\nsprayD       -2.7157     0.4571  -5.941 1.17e-07 ***\nsprayE       -3.3605     0.4571  -7.352 3.82e-10 ***\nsprayF        0.4162     0.4571   0.911    0.366    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.12 on 66 degrees of freedom\nMultiple R-squared:  0.7659,    Adjusted R-squared:  0.7482 \nF-statistic: 43.19 on 5 and 66 DF,  p-value: &lt; 2.2e-16\n\nanova(m5)\n\nAnalysis of Variance Table\n\nResponse: count3\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nspray      5 270.737  54.147  43.191 &lt; 2.2e-16 ***\nResiduals 66  82.742   1.254                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nhist(m5$residuals)\n\n\n\n\n\n\n\nshapiro.test(m5$residuals)  \n\n\n    Shapiro-Wilk normality test\n\ndata:  m5$residuals\nW = 0.98873, p-value = 0.7723\n\nqqnorm(m5$residuals)\nqqline(m5$residuals)\n\n\n\n\n\n\n\nbartlett.test(count3 ~spray,\n             data = inseticida)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  count3 by spray\nBartlett's K-squared = 5.7412, df = 5, p-value = 0.3322\n\n# é uma forma de estabilizar variância também\n\n\n\n\nAlternativa 2: teste não paramétrico\nUsa saída original (sem transformar). Faz um rankeamento.\n\nlibrary(agricolae)\n\nkruskal.test(count ~spray,\n             data = inseticida) #kruskal.test é do R base\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  count by spray\nKruskal-Wallis chi-squared = 54.691, df = 5, p-value = 1.511e-10\n\n# usando o agricolae\nm3 &lt;- kruskal(inseticida$count,\n        inseticida$spray,\n        group = TRUE)\n\nH0 = médias são iguais Como Kruskal-wallis, rejeita H0, então as médias são diferentes\nO não-paramétrico deu os mesmos resultados dos valores transformados.\nmodelo linear generalizado = glm. É o modelo menos criticado (entre os transformado e não-paramétrico). Utiliza a distribuição apropriado.\n\n\nAlternativa 3: GLMs\nDistribuição de dados contagem (numérica discreta): poisson se ajusta também a essa distribuição (de 0 para cima)\n\n# glm com a familia gaussiana reduz a lm\nm4 &lt;- glm(count ~ spray,\n          family = gaussian,\n          data = inseticida)\n\n# utilizando com a família poisson\nm4 &lt;- glm(count ~ spray,\n          family = poisson,\n          data = inseticida)\nsummary(m4)\n\n\nCall:\nglm(formula = count ~ spray, family = poisson, data = inseticida)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  2.67415    0.07581  35.274  &lt; 2e-16 ***\nsprayB       0.05588    0.10574   0.528    0.597    \nsprayC      -1.94018    0.21389  -9.071  &lt; 2e-16 ***\nsprayD      -1.08152    0.15065  -7.179 7.03e-13 ***\nsprayE      -1.42139    0.17192  -8.268  &lt; 2e-16 ***\nsprayF       0.13926    0.10367   1.343    0.179    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 409.041  on 71  degrees of freedom\nResidual deviance:  98.329  on 66  degrees of freedom\nAIC: 376.59\n\nNumber of Fisher Scoring iterations: 5\n\nanova(m4)\n\nAnalysis of Deviance Table\n\nModel: poisson, link: log\n\nResponse: count\n\nTerms added sequentially (first to last)\n\n      Df Deviance Resid. Df Resid. Dev  Pr(&gt;Chi)    \nNULL                     71     409.04              \nspray  5   310.71        66      98.33 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(car)\nAnova(m4)\n\nAnalysis of Deviance Table (Type II tests)\n\nResponse: count\n      LR Chisq Df Pr(&gt;Chisq)    \nspray   310.71  5  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nplot(simulateResiduals(m4))\n\n\n\n\n\n\n\nm4_medias &lt;- emmeans(m4, ~spray,\n                     type = \"response\")\n\ncld(m4_medias)\n\n spray  rate    SE  df asymp.LCL asymp.UCL .group\n C      2.08 0.417 Inf      1.41      3.08  1    \n E      3.50 0.540 Inf      2.59      4.74  12   \n D      4.92 0.640 Inf      3.81      6.35   2   \n A     14.50 1.099 Inf     12.50     16.82    3  \n B     15.33 1.130 Inf     13.27     17.72    3  \n F     16.67 1.179 Inf     14.51     19.14    3  \n\nConfidence level used: 0.95 \nIntervals are back-transformed from the log scale \nP value adjustment: tukey method for comparing a family of 6 estimates \nTests are performed on the log scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nAnova: tem um que é diferente dos outros (p-valor &lt;0,05). Os grupos com o GLM foram iguais às outras alternativas (dados transformados e não-paramétrico)"
  },
  {
    "objectID": "Aula6.html#anova-2-fatores-modelo-fatorial-two-way-anova",
    "href": "Aula6.html#anova-2-fatores-modelo-fatorial-two-way-anova",
    "title": "Teste T e ANOVA",
    "section": "Anova 2 fatores = Modelo fatorial (two-way anova)",
    "text": "Anova 2 fatores = Modelo fatorial (two-way anova)\n\nImporta os dados\n\ntheme_set(theme_bw())\nli &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=2023059672\")\n\n#visualização dos dados\n\nli |&gt; \n  ggplot(aes(factor(dose), severity, color = factor(dose)))+\n  geom_jitter(width = 0.05)+\n  facet_wrap(~~treat)\n\n\n\n\n\n\n\nli |&gt; \n  ggplot(aes(factor(treat), severity, color = factor(dose)))+\n  geom_jitter(width = 0.05)\n\n\n\n\n\n\n\n\n\n\nAnova\n\nmf &lt;- lm(severity ~treat*factor(dose),\n         data = li)\n\nanova(mf)\n\nAnalysis of Variance Table\n\nResponse: severity\n                   Df   Sum Sq  Mean Sq F value    Pr(&gt;F)    \ntreat               1 0.113232 0.113232  30.358 4.754e-05 ***\nfactor(dose)        1 0.073683 0.073683  19.755 0.0004077 ***\ntreat:factor(dose)  1 0.072739 0.072739  19.502 0.0004326 ***\nResiduals          16 0.059678 0.003730                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\ntreat:dose = interação Interação significativa: tem que estimar as médias de um dentro do outro (combinação dos fatores). São quatro valores médios (LI-0,5, LI-2,0, TEB-0,5 e TEB-2,0 = 4 médias). Letras maiusculas comparam as colunas e as minusculas comparam as linhas\n      0,5             2,0\nLI Média Aa Média Ab TEB Média Ba Média Aa\n\nTestar as premissas\n\nplot(simulateResiduals(mf))\n\n\n\n\n\n\n\n\nDharma: não teve problema na normalidade dos residuals, nem na heterocedasticidade\n\ncheck_heteroscedasticity(mf)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p &lt; .001).\n\ncheck_homogeneity(mf)\n\nWarning: Variances differ between groups (Bartlett Test, p = 0.001).\n\n\nUtilizando o performance, os resultados foram o contrário do DHArma, mas o Dharma é mais confiável, então vamos prosseguir.\n\n\nCOMPARAR AS COLUNAS\n\nmf_medias &lt;- emmeans(mf, ~ treat | dose)\ncld(mf_medias)  #para mostrar os grupos\n\ndose = 0.5:\n treat        emmean     SE df lower.CL upper.CL .group\n Tebuconazole 0.0210 0.0273 16 -0.03690   0.0789  1    \n Ionic liquid 0.2921 0.0273 16  0.23420   0.3500   2   \n\ndose = 2.0:\n treat        emmean     SE df lower.CL upper.CL .group\n Tebuconazole 0.0202 0.0273 16 -0.03768   0.0781  1    \n Ionic liquid 0.0501 0.0273 16 -0.00781   0.1080  1    \n\nConfidence level used: 0.95 \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n         DOSES\nTREAT 0,5 | 2,0 LI | 0,29 A | 0,05 A TEB | 0,02 B | 0,02 A\n####COMPARAR AS LINHAS\n\nmf_medias &lt;- emmeans(mf, ~ dose | treat)\ncld(mf_medias)\n\ntreat = Ionic liquid:\n dose emmean     SE df lower.CL upper.CL .group\n  2.0 0.0501 0.0273 16 -0.00781   0.1080  1    \n  0.5 0.2921 0.0273 16  0.23420   0.3500   2   \n\ntreat = Tebuconazole:\n dose emmean     SE df lower.CL upper.CL .group\n  2.0 0.0202 0.0273 16 -0.03768   0.0781  1    \n  0.5 0.0210 0.0273 16 -0.03690   0.0789  1    \n\nConfidence level used: 0.95 \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n         DOSES\nTREAT| 0,5 | 2,0 LI | 0,29 Aa | 0,05 Ab TEB | 0,02 Ba | 0,02 Aa"
  },
  {
    "objectID": "Aula4.html",
    "href": "Aula4.html",
    "title": "Gráficos com ggplot - Parte 2",
    "section": "",
    "text": "library(datapasta)\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(ggthemes)\nlibrary(gsheet)"
  },
  {
    "objectID": "Aula4.html#mudando-o-formato-da-tabela",
    "href": "Aula4.html#mudando-o-formato-da-tabela",
    "title": "Gráficos com ggplot - Parte 2",
    "section": "Mudando o formato da tabela",
    "text": "Mudando o formato da tabela\nPara permitir a visualização dos dados através do ggplot é importante que os dados estejam no formato correto. A função pivot_longer permite passar uma tabela que está no formato largo para o formato longo. De igual modo, a função pivot_wider permite transformar a tabela do formato longo para formato largo.\n\npepper1 &lt;- pepper |&gt; \n  pivot_longer(2:4,\n               names_to = \"epidemic\",\n               values_to = \"inc\")"
  },
  {
    "objectID": "Aula4.html#visualização-dos-dados",
    "href": "Aula4.html#visualização-dos-dados",
    "title": "Gráficos com ggplot - Parte 2",
    "section": "Visualização dos dados",
    "text": "Visualização dos dados\nAgora com os dados transformados é possível visualizar no ggplot.\nVamos utilizar a função annotate para colocar informações no gráfico (etiquetas, equações…).\nComo já temos os nº das linhas dentro do próprio gráfico não precisa da legenda, por isso legend.position = \"none\", para tirar a legenda.\n\npepper1 |&gt; \n  ggplot(aes(t, inc, color = epidemic))+\n  geom_point()+\n  geom_line()+\n  annotate(geom = \"text\", x = 12.5, y = 0.80, label = 1)+\n  annotate(geom = \"text\", x = 26, y = 0.80, label = 2)+\n  annotate(geom = \"text\", x = 41, y = 0.50, label = 3)+\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "Aula4.html#importação-dos-dados-1",
    "href": "Aula4.html#importação-dos-dados-1",
    "title": "Gráficos com ggplot - Parte 2",
    "section": "Importação dos dados",
    "text": "Importação dos dados\n\ncr &lt;- read_csv(\"https://raw.githubusercontent.com/emdelponte/paper-coffee-rust-Ethiopia/master/data/survey_clean.csv\")"
  },
  {
    "objectID": "Aula4.html#esquematizando-a-tabela",
    "href": "Aula4.html#esquematizando-a-tabela",
    "title": "Gráficos com ggplot - Parte 2",
    "section": "Esquematizando a tabela",
    "text": "Esquematizando a tabela\nVai fazer uma contagem de uma váriavel categórica (quantas ocorrências tem) através da função count. Função interessante para fazer um sumário de variáveis categóricas de forma rápida.\nTambém podemos usar a função tabyl do pacote janitor para fazer a contagem - cruzando as variaveis (ex: zone e region) temos a tabela de contigência.\nAs tabelas de contingência de frequências relativas mostram que porcentagem dos dados se encaixa em cada categoria.\n\ncr |&gt; \n  count(region, zone)\n\n# A tibble: 9 × 3\n  region zone             n\n  &lt;chr&gt;  &lt;chr&gt;        &lt;int&gt;\n1 Oromia Bale            30\n2 Oromia Ilu AbaBora     45\n3 Oromia Jimma           45\n4 Oromia West Wellega    45\n5 SNNPR  Bench Maji      45\n6 SNNPR  Gedio           45\n7 SNNPR  Keffa           45\n8 SNNPR  Sheka           45\n9 SNNPR  Sidama          60\n\ncr |&gt; \n  tabyl(zone, region)\n\n         zone Oromia SNNPR\n         Bale     30     0\n   Bench Maji      0    45\n        Gedio      0    45\n  Ilu AbaBora     45     0\n        Jimma     45     0\n        Keffa      0    45\n        Sheka      0    45\n       Sidama      0    60\n West Wellega     45     0\n\ncr |&gt; \n  tabyl(cultivar, region)\n\n cultivar Oromia SNNPR\n Improved     23    60\n    Local     50    66\n  Mixture     92   114\n\ncr |&gt; \n  tabyl(cultivar, farm_management) #formato largo\n\n cultivar Intensive Minimal Moderate Unmanaged\n Improved        83       0        0         0\n    Local         0      10        4       102\n  Mixture        82      59       65         0\n\n  #formato longo, estes que usaremos para fazer gráficos com o ggplot:\n\ncr2 &lt;- cr |&gt; \n  count(farm_management, cultivar)"
  },
  {
    "objectID": "Aula4.html#visualização-dos-dados-com-ggplot",
    "href": "Aula4.html#visualização-dos-dados-com-ggplot",
    "title": "Gráficos com ggplot - Parte 2",
    "section": "Visualização dos dados com ggplot",
    "text": "Visualização dos dados com ggplot\n\ncr2 |&gt; \n    ggplot(aes(cultivar, n, fill = farm_management, label = n))+\n  geom_col(position = \"dodge2\")+\n  scale_fill_canva()+\n  theme_bw()+\n  theme(strip.text.x = element_blank(),\n      legend.position = \"top\")+\n    geom_text(position = position_dodge(width = 0.9))+\n  facet_wrap(~cultivar, scale = \"free_x\")\n\n\n\n\n\n\n\n\n\nmg &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1aID5Dh6PlBVCKzU1j7k-WA6zuWQWE2NhtWEgdJtt5iA/edit?usp=sharing\")\n\n# Com as barras podemos ver o valor médio\nmg |&gt; \n  group_by(trat) |&gt;\n  summarise(mean_comp = mean(comp)) |&gt; \n  ggplot(aes(trat, mean_comp))+\n  geom_col(fill = \"steelblue\", width = 0.5)\n\n\n\n\n\n\n\n#Com o jitter podemos ver a dispersão dos dados já que cada ponto é referente a uma observação.  \nmg |&gt; \n  ggplot(aes(trat, comp))+\n  geom_jitter(width = 0.1)\n\n\n\n\n\n\n\nmg |&gt; \n  group_by(trat) |&gt;\n  summarise(mean_comp = mean(comp),\n            sd_comp = sd(comp)) |&gt; \n  ggplot(aes(trat, mean_comp))+\n  #geom_col(fill = \"steelblue\", width = 0.5)+\n  geom_point(size = 3)+\n  ylim(4, 20)+\n  geom_errorbar(aes(ymin = mean_comp - sd_comp,\n                    ymax = mean_comp + sd_comp),\n                width = 0.05)+\n  annotate(geom = \"text\",\n           x = 1, y = 17.5,\n           label = \"*\")\n\n\n\n\n\n\n\n# quando é grafico de contagem de elementos tem que começar do 0. Nesse caso o y começou do 5 pq é para dar noçao melhor dos valores. Se for com o geom_col tem que começar do 0."
  },
  {
    "objectID": "Aula2.html",
    "href": "Aula2.html",
    "title": "Aula2",
    "section": "",
    "text": "Bibliotecas\nBibliotecas que foram utilizadas durante a aula.\n\nlibrary(ec50estimator)\nlibrary(readxl)\nlibrary(tidyverse)\nlibrary(gsheet)\nlibrary(googlesheets4)\nlibrary(ggplot2)\nlibrary(ggthemes)\n\n\n\nCarregamento do conjunto de dados multi_isolate da biblioteca ec50estimator\nPrimeiro, precisa carregar o pacote ec50estimator\n\ndf1 &lt;- multi_isolate\n\n\n\nOutras formas de carregar um conjunto de dados\nOutras formas de carregar um conjunto de dados utilizando diferentes funções do pacote readxl, que permite importar para o R dados presentes em arquivos de diferentes formatos. Também utilizamos o pacote gsheet, com a função gsheet2tbl, que permite importar planilhas direto do Google Sheet.\n\ndf21 &lt;- read_excel(\"dados-diversos.xlsx\", 2)\n\ndf2 &lt;- read_excel(\"dados-diversos.xlsx\")\n\ndf3 &lt;- read_csv(\"dados-diversos.csv\")\n\ndf4 &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1aID5Dh6PlBVCKzU1j7k-WA6zuWQWE2NhtWEgdJtt5iA/edit#gid=921203844\")\n\n# df5 &lt;- read_sheet(\"https://docs.google.com/spreadsheets/d/1aID5Dh6PlBVCKzU1j7k-WA6zuWQWE2NhtWEgdJtt5iA/edit?usp=sharing\") #pacote mais complexo e com mais funções, para apenas inserir novos df utilizar o gsheet, que é mais simples.\n\n\n\nVisualização dos dados\nVisualização dos dados utilizando o pacote ggplot.\n\ng1 &lt;-df4 |&gt; \n  ggplot(aes(trat, comp))+\n  geom_boxplot(outlier.colour = NA,\n               fill = \"steelblue\")+\n  geom_jitter(width = 0.05,\n              color = \"black\",\n              shape = 1,\n              size = 3)+\n  labs(x = \"Tratamento\",\n       y = \"Comprimento\",\n       title = \"Meu Primeiro ggplot\",\n       caption = \"Fonte: Dados diversos\")+\n  theme_clean()+\n  scale_y_continuous(limits = c(0,20),\n                     n.breaks = 10)\n\ng1\n\n\n\n\n\n\n\nggsave(\"meu1gg.png\", bg = \"white\")"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Sou Ana Carolyne, mestranda no Programa de Pós-Graduação em Fitopatologia da Universidade Federal de Viçosa, formada em Agronomia pela Universidade Federal Rural do Rio de Janeiro. Atualmente, atuo no Laboratório de Epidemiologia.\nOlá, seja bem vindo ao meu website!! Meu nome é Ana Carolyne, atualmente sou mestranda no Programa de Pós-Graduação em Fitopatologia na Universidade Federal de Viçosa e atuo no Laboratório de Epidemiologia. Concluí minha graduação em Agronomia na Universidade Federal Rural do Rio de Janeiro. Estou ansiosa para continuar explorando novas oportunidades de aprendizado e crescimento, enquanro trabalho para fazer uma diferença positiva no campo da Fitopatologia.\n\n\nEste website é dedicado à disciplina FIP 606 - Análise e Visualização de Dados em Fitopatologia, oferecida pela Universidade Federal de Viçosa e ministrada pelo professor Emerson Medeiros Del Ponte.\nNeste site, você encontrará todo o material das aulas, com códigos comentados e organizados nas aulas da disciplina. O objetivo é facilitar o acesso ao conhecimento e fomentar o interesse pela análise de dados fitopatológicos usando RStudio.\nConvido você a explorar os conteúdos disponíveis e a aproveitar ao máximo os recursos oferecidos. Se tiver qualquer dúvida ou sugestão, sinta-se à vontade para entrar em contato. Boa aprendizagem!"
  },
  {
    "objectID": "about.html#sobre-esse-site",
    "href": "about.html#sobre-esse-site",
    "title": "About",
    "section": "",
    "text": "Este website é dedicado à disciplina FIP 606 - Análise e Visualização de Dados em Fitopatologia, oferecida pela Universidade Federal de Viçosa e ministrada pelo professor Emerson Medeiros Del Ponte.\nNeste site, você encontrará todo o material das aulas, com códigos comentados e organizados nas aulas da disciplina. O objetivo é facilitar o acesso ao conhecimento e fomentar o interesse pela análise de dados fitopatológicos usando RStudio.\nConvido você a explorar os conteúdos disponíveis e a aproveitar ao máximo os recursos oferecidos. Se tiver qualquer dúvida ou sugestão, sinta-se à vontade para entrar em contato. Boa aprendizagem!"
  },
  {
    "objectID": "Aula1.html",
    "href": "Aula1.html",
    "title": "Algumas funções do R",
    "section": "",
    "text": "Na primeira aula da disciplina, utilizamos o RStudio para testar e aprender alguns pacotes e funções do R."
  },
  {
    "objectID": "Aula1.html#pacote-agricolae",
    "href": "Aula1.html#pacote-agricolae",
    "title": "Algumas funções do R",
    "section": "Pacote agricolae",
    "text": "Pacote agricolae\n\nlibrary(agricolae)\n\ndates &lt;- c(14, 21, 28) #days\n\n# example a: evaluation - vector\nevaluation &lt;- c(40, 80, 90)\naudpc(evaluation, dates)\n\nevaluation \n      1015"
  },
  {
    "objectID": "Aula1.html#pacote-epifitter",
    "href": "Aula1.html#pacote-epifitter",
    "title": "Algumas funções do R",
    "section": "Pacote epifitter",
    "text": "Pacote epifitter\n\nlibrary(epifitter)\n\npressure\n\n   temperature pressure\n1            0   0.0002\n2           20   0.0012\n3           40   0.0060\n4           60   0.0300\n5           80   0.0900\n6          100   0.2700\n7          120   0.7500\n8          140   1.8500\n9          160   4.2000\n10         180   8.8000\n11         200  17.3000\n12         220  32.1000\n13         240  57.0000\n14         260  96.0000\n15         280 157.0000\n16         300 247.0000\n17         320 376.0000\n18         340 558.0000\n19         360 806.0000\n\nsummary(pressure)\n\n  temperature     pressure       \n Min.   :  0   Min.   :  0.0002  \n 1st Qu.: 90   1st Qu.:  0.1800  \n Median :180   Median :  8.8000  \n Mean   :180   Mean   :124.3367  \n 3rd Qu.:270   3rd Qu.:126.5000  \n Max.   :360   Max.   :806.0000  \n\nplot(pressure)\n\n\n\n\n\n\n\nstr(pressure) #str : mostra a estrutura do df\n\n'data.frame':   19 obs. of  2 variables:\n $ temperature: num  0 20 40 60 80 100 120 140 160 180 ...\n $ pressure   : num  0.0002 0.0012 0.006 0.03 0.09 0.27 0.75 1.85 4.2 8.8 ..."
  },
  {
    "objectID": "Aula3.html",
    "href": "Aula3.html",
    "title": "Gráficos com ggplot",
    "section": "",
    "text": "Pacotes que foram utilizados na aula do dia 20/03/2024\n\nlibrary(tidyverse)\nlibrary(ggthemes)\nlibrary(patchwork)"
  },
  {
    "objectID": "Aula3.html#visualização-dos-dados",
    "href": "Aula3.html#visualização-dos-dados",
    "title": "Gráficos com ggplot",
    "section": "Visualização dos dados",
    "text": "Visualização dos dados\nVamos utilizar a biblioteca ggplot2 para visualizar os dados do conjunto.\nComo está distribuída a incidência da ferrugem do café nas 405 fazendas?\n\ncr |&gt; \n  ggplot(aes(inc))+\n  geom_histogram()\n\n\n\n\n\n\n\n\nVimos que não é uma distribuição normal, é multimodal (mais de um pico de maior inc)\n\nsummary(cr$inc)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   9.50   19.43   32.50   34.89   48.20   86.71 \n\n\nA inc da ferrugem variou de 9,50% a 86,71%, com média de 32,50% e mediana de 32,50%.\n\ncr |&gt; \n  ggplot(aes(x = farm, y = inc))+\n  geom_boxplot()"
  },
  {
    "objectID": "Aula3.html#sumarização-e-visualização-dos-dados",
    "href": "Aula3.html#sumarização-e-visualização-dos-dados",
    "title": "Gráficos com ggplot",
    "section": "Sumarização e visualização dos dados",
    "text": "Sumarização e visualização dos dados\n\ncr |&gt; \n  ggplot(aes(inc))+\n  geom_histogram()+\n  facet_wrap(~region)\n\n\n\n\n\n\n\ncr |&gt; \n  ggplot(aes(inc))+\n  geom_boxplot()+\n  facet_wrap(~region)\n\n\n\n\n\n\n\n\nPelo boxplot é possível ver que a mediana mais alta, quando os dados são divididos de acordo com a região, que a incidência é mais alta em Oromia.\nPara saber a média, mediana e desvio padrão de inc das duas regiões:\n\ncr |&gt; \n  group_by(region) |&gt; \n  summarise(inc_mean = mean(inc),\n            inc_sd = sd(inc),\n            inc_median = median(inc))\n\n# A tibble: 2 × 4\n  region inc_mean inc_sd inc_median\n  &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n1 Oromia     37.0   14.6       39.5\n2 SNNPR      33.4   18.9       29.6\n\n\nMesma coisa para cultivar:\n\ncr |&gt; \n  group_by(cultivar) |&gt; \n  summarise(inc_mean = mean(inc),\n            inc_sd = sd(inc),\n            inc_median = median(inc))\n\n# A tibble: 3 × 4\n  cultivar inc_mean inc_sd inc_median\n  &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n1 Improved     16.4   5.66       15.2\n2 Local        53.4  14.3        50.9\n3 Mixture      31.9  11.2        31.6\n\n\nQuero saber o que é mais interessante? Usar severidade ou inc? Existe alguma relação entre elas?\n\ncr |&gt; \n  ggplot(aes(inc, sev2))+\n  geom_point( )\n\n\n\n\n\n\n\n\nÉ possível ver que há um aumento da severidade conforme a incidência aumenta. A partir disso, é possível criar um modelo para predizer/estimar a severidade de acordo com a incidência, já que foi verificado essa relação entre essas duas variáveis.\n\ncr |&gt; \n  ggplot(aes(sev2))+\n  geom_histogram()+\n  facet_wrap(~region)\n\n\n\n\n\n\n\n\nDe acordo com a severidade, a distribuição também é assimétrica - indica que a mediana e a média são mais distantes.\n\ncr |&gt; \n  #group_by(cultivar) |&gt; \n  summarise(sev_mean = mean(sev2),\n            sev_sd = sd(sev2),\n            sev_median = median(sev2))\n\n# A tibble: 1 × 3\n  sev_mean sev_sd sev_median\n     &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n1     9.09   9.22       5.95\n\n\nA média está mais alta do que a mediana (a média está sendo influenciada pelos outliers - aqueles valores com a severidade mais alta).\nQuando se tem uma situação mais simétrica (mais próximo da normalidade), a média e a\nmediana estão mais próximas.\n\ncr |&gt; \n  group_by(cultivar) |&gt; \n  summarise(sev_mean = mean(sev2),\n            sev_sd = sd(sev2),\n            sev_median = median(sev2))\n\n# A tibble: 3 × 4\n  cultivar sev_mean sev_sd sev_median\n  &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n1 Improved     2.16   1.82       1.64\n2 Local       18.7   11.1       17.2 \n3 Mixture      6.47   4.35       5.43\n\n\nTem tendência de maior homogeniedade dentro de cada grupo (medianas e médias mais próximos para cada cultivar).\n\ncr |&gt; \n  ggplot(aes(sev2))+\n  geom_histogram()+\n  facet_wrap(~cultivar)\n\n\n\n\n\n\n\n\n\ncr |&gt; \n  ggplot(aes(sev2))+\n  geom_histogram()+\n  facet_wrap(~region)\n\n\n\n\n\n\n\n\n\ncr |&gt; \n  ggplot(aes(sev2, fill = region))+\n  scale_fill_colorblind()+\n  geom_histogram(color = \"white\")+\n  facet_wrap(region ~ cultivar, ncol = 3)+\n  theme_clean(base_size = 14)+\n  theme(legend.position = \"bottom\")+\n  labs(y = \"Frequency\",\n       x = \"Severity (%)\",\n       fill = \"Region\")\n\n\n\n\n\n\n\nggsave(\"plot2.png\", bg = \"white\")\n\nÉ possível ver que, de maneira geral, a severidade para as cultivares se mantém similar independente da região."
  },
  {
    "objectID": "Aula3.html#visualização-dos-subconjuntos",
    "href": "Aula3.html#visualização-dos-subconjuntos",
    "title": "Gráficos com ggplot",
    "section": "Visualização dos subconjuntos",
    "text": "Visualização dos subconjuntos\nGráficos ggplot para cada subconjunto\n\np1 &lt;- cr_oromia |&gt; \n  ggplot(aes(cultivar, sev2, fill = cultivar))+\n  geom_boxplot()+\n  labs(#title = \"Oromia\",\n       y = \"Severity (%)\",\n       x = \"Cultivar\",\n       fill = \"Cultivar\")\n\n\np2 &lt;- cr_pr |&gt; \n  ggplot(aes(cultivar, sev2, fill = cultivar))+\n  geom_boxplot()+\n  labs(#title = \"SNNPR\",\n       y = \"Severity (%)\",\n       x = \"Cultivar\",\n       fill = \"Cultivar\")\n\n(p1 + p2)+ # coloca um gráfico ao lado do outro; o + pode ser substituído por |\n#p1 / p2 # coloca um gráfico em baixo do outro\nplot_layout(guides = 'collect')+ # para deixar apenas 1 legenda dos gráficos (já que é a mesma) \n  plot_annotation(tag_levels = \"A\")\n\n\n\n\n\n\n\nggsave(\"patch1.png\")\n\nPara fazer o mesmo gráfico, mas invertendo os eixos, de maneira mais rápida, sem precisar recriar todo o ggplot, utilizar a função coord_flip().\n\np1 &lt;- cr_oromia |&gt; \n  ggplot(aes(cultivar, sev2, fill = cultivar))+\n  geom_boxplot()+\n  scale_fill_few()+\n  theme_few()+\n  labs(#title = \"Oromia\",\n    x = \"\",   \n    y = \"Severity (%)\",\n       fill = \"Cultivar\")+\n  coord_flip()\n\n\np2 &lt;- cr_pr |&gt; \n  ggplot(aes(cultivar, sev2, fill = cultivar))+\n  geom_boxplot()+\n  scale_fill_few()+\n  theme_few()+\n  labs(#title = \"SNNPR\",\n    x = \"\",  \n    y = \"Severity (%)\",\n       fill = \"Cultivar\")+\n  coord_flip()\n\np3 &lt;- cr_oromia |&gt; \n  ggplot(aes(x = sev2))+\n  geom_histogram()"
  },
  {
    "objectID": "Aula3.html#utilizando-o-patchwork",
    "href": "Aula3.html#utilizando-o-patchwork",
    "title": "Gráficos com ggplot",
    "section": "Utilizando o patchwork",
    "text": "Utilizando o patchwork\nO pacote patchwork foi utilizado para fazer essa junção de mais de um gráfico em apenas uma imagem.\n\n#(p1 + p2)+ # coloca um gráfico ao lado do outro; o '+' pode ser substituído por '|'\n(p1 / p2)+ # coloca um gráfico em baixo do outro\nplot_layout(guides = 'collect',\n            axes = 'collect') +\n  plot_annotation(tag_levels = \"A\")+\n  plot_annotation(title = \"Coffee rust in Ethiopia\",\n                  caption = \"Source: Del Ponte (2022)\")\n\n\n\n\n\n\n\nggsave(\"patch2.png\", width = 6, height = 4)\n\nPara inserir um gráfico dentro de outro gráfico usar a função insect_element():\n\np1 + inset_element(p3, left = 0.6, bottom = 0.6, right = 1, top = 1)"
  },
  {
    "objectID": "Aula5.html",
    "href": "Aula5.html",
    "title": "Análise Descritiva",
    "section": "",
    "text": "Aluna: Ana Carolyne Costa de Carvalho (115522)"
  },
  {
    "objectID": "Aula5.html#visualização-dos-dados",
    "href": "Aula5.html#visualização-dos-dados",
    "title": "Análise Descritiva",
    "section": "Visualização dos dados",
    "text": "Visualização dos dados\n\nSumarização dos dados\nAtravés da função summary do R base é possível obter uma sumarização geral dos dados, onde sabemos a média geral e outras informações das notas dos alunos para as duas provas realizadas.\n\ndados |&gt; \n  summary()\n\n     prova         pontos           nota       \n Min.   :1.0   Min.   : 6.00   Min.   : 42.90  \n 1st Qu.:1.0   1st Qu.:10.00   1st Qu.: 68.75  \n Median :1.5   Median :12.50   Median : 85.70  \n Mean   :1.5   Mean   :11.91   Mean   : 79.40  \n 3rd Qu.:2.0   3rd Qu.:14.00   3rd Qu.:100.00  \n Max.   :2.0   Max.   :16.00   Max.   :100.00  \n\n\nUtilizando o group_by e summarise, ambas funções do pacote dplyr, é possível calcular as informações de média, mediana e desvio padrão para cada prova, de forma que conseguimos visualizar em qual das avaliações obtivemos um melhor resultado.\n\ndados |&gt; \n  group_by(prova) |&gt; \n  summarise(mean_nota = mean(nota),\n            sd_nota = sd(nota),\n            median_nota = median(nota),\n            somatorio_nota = sum(nota))\n\n# A tibble: 2 × 5\n  prova mean_nota sd_nota median_nota somatorio_nota\n  &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;       &lt;dbl&gt;          &lt;dbl&gt;\n1     1      79.5    19.0        85.7          1750 \n2     2      79.3    19.7        84.4          1744.\n\n\nCom isso, foi possível verificar que as duas avaliações apresentaram médias muito próximas, indicando uma constância no desempenho dos alunos.\n\n\nGráficos\nPara facilitar a visualização dos dados, foram elaborados alguns gráficos. Os gráficos foram confeccionados utilizando a função ggplot do pacote ggplot2.\n\nHistograma\n\ndados |&gt; \n  ggplot(aes(nota))+\n  geom_histogram(fill = \"steelblue\",\n                 color = \"white\",\n                 bins = 13)+\n    facet_wrap(~prova)+\n    geom_vline(xintercept = 70, linetype = \"dashed\", color = \"black\")+\n  xlim(0, 100)+\n  ylim(0,6)+\nlabs(y = \"Frequência\",\n       x = \"Notas\")+\n  theme_bw()\n\n\n\n\n\n\n\n\nNeste gráfico é possível visualizar a frequência de notas. Além disso, a linha chamuscada indica o local onde a nota é igual a 70.00, ou seja, após esta linha, estão as notas com valor maior ou igual à nota necessária para aprovação na disciplina.\n\nQuantos alunos possuem nota maior ou igual à 70.00?\nPara saber essa informação iremos utilizar a função filter, group_by e count do pacote dplyr.\n\ndados |&gt; \n  filter(nota &gt; 70.00) |&gt; \n  group_by(prova) |&gt; \n  count()\n\n# A tibble: 2 × 2\n# Groups:   prova [2]\n  prova     n\n  &lt;dbl&gt; &lt;int&gt;\n1     1    16\n2     2    13\n\n\nCom esses dados, é possível ver que obtivemos 16 e 13 notas maiores que 70.00 na primeira e segunda prova, respectivamente. Em ambas as provas, mais da metade da turma (n = 22).\n\n\n\nBoxplot\n\ndados |&gt; \n  ggplot(aes(factor(prova), nota, color = prova))+\n  geom_boxplot()+\n  geom_jitter(width = 0.05, point_type = 2)+\n  labs(y = \"Notas\",\n       x = \"Provas\")+\n  theme_bw()+\n    theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nNeste boxplot é possível visualizar que as duas provas se mantiveram com padrões similares quanto as notas. Em ambos os casos, é possível ver que a maior parte das notas foram maiores que 65, embora ainda seja possível ver uma dispersão dos dados.\n\n\nHistograma para cada prova\n\np1 &lt;- dados|&gt; \n    filter(prova == 1) |&gt; \n  ggplot(aes(nota))+\n  theme_bw()+\n  geom_histogram(bins = 5,\n                 fill = \"darkred\",\n               color = \"white\")+\n  labs(title = \"Prova 1\",\n    y = \"Frequency\",\n       x = \"Notas\")+\n  geom_vline(xintercept = 79.54545, linetype = \"dashed\")+\n      annotate(geom = \"text\", x = 73.5, y = 6.5, label = \"Mean\")+\n    theme(plot.title = element_text(hjust=0.5))+\n  ylim(0, 10)\n\np1\n\n\n\n\n\n\n\np2 &lt;- dados |&gt; \n  filter(prova == 2) |&gt; \n  ggplot(aes(nota))+\n  theme_bw()+\n  geom_histogram(bins = 5,\n                 fill = \"steelblue\",\n               color = \"white\")+\n labs( title = \"Prova 2\",\n       y = \"Frequency\",\n       x = \"Notas\")+\n  geom_vline(xintercept = 79.26136, linetype = \"dashed\")+\n    annotate(geom = \"text\", x = 73.5, y = 6.5, label = \"Mean\")+\n  theme(plot.title = element_text(hjust=0.5))+\n    ylim(0, 10)\n\n\np2\n\n\n\n\n\n\n\np1+p2\n\n\n\n\n\n\n\n\nNeste gráfico é possível visualizar a frequência das notas para cada prova, separadamente. A linha tachada indica o valor médio.\n\n\nGráfico de pontos\n\ndados |&gt; \n  group_by(prova) |&gt;\n  summarise(mean_nota = mean(nota),\n            sd_nota = sd(nota)) |&gt;  \n  ggplot(aes(factor(prova), mean_nota, color = prova))+\n  geom_point(size = 3)+\n  geom_errorbar(aes(ymin = mean_nota - sd_nota,\n                    ymax = mean_nota + sd_nota),\n                width = 0.05)+\n      theme_bw()+\n  theme(legend.position = \"none\")  +\n  ylim(0,100)+\n  labs(       y = \"Nota média\",\n       x = \"Provas\")\n\n\n\n\n\n\n\n\nNeste gráfico, os pontos indicam o valor médio das notas para cada prova e as barras representam os intervalos de confianças.\n\n\n\nConclusão\nCom estes dados foi possível calcular e visualizar a frequência, a média, o desvio padrão, além de outros descritores, possibilitando fornecer insights sobre a dispersão dos dados em relação à média. Pode-se concluir que o desempenho dos alunos nas duas provas foi muito semelhante e que, apesar da variabilidade nas notas individuais, o desempenho médio dos alunos foi superior ao valor de corte estabelecido para a disciplina (70.00) Este resultado sugere uma performance satisfatória, indicando uma compreensão adequada do conteúdo da disciplina."
  },
  {
    "objectID": "Aula8.html",
    "href": "Aula8.html",
    "title": "ANOVA",
    "section": "",
    "text": "library(tidyverse)\nlibrary(gsheet)\nlibrary(patchwork)"
  },
  {
    "objectID": "Aula8.html#anova-dfc",
    "href": "Aula8.html#anova-dfc",
    "title": "ANOVA",
    "section": "Anova DFC",
    "text": "Anova DFC\n\naov_dfc &lt;- lm(DFC ~ TRAT + BLOCO,\n              data = soja)\n\nanova(aov_dfc)\n\nAnalysis of Variance Table\n\nResponse: DFC\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nTRAT       7 149.299 21.3284 51.5490 8.218e-12 ***\nBLOCO      3   0.461  0.1537  0.3716    0.7743    \nResiduals 21   8.689  0.4138                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nEfeito de tratamento foi significativo, de blocos não foi. Vai comparar as médias entre os tratamentos. Mesmo assim, tem que deixar os blocos, porque o delineamento do experimento foi em blocos casualizados. Antes de partir para as comparações múltiplas, tem que verificar as variâncias e homogeneidade.\nChecar normalidade e variancias:\n\nlibrary(performance)\ncheck_normality(aov_dfc)\n\nOK: residuals appear as normally distributed (p = 0.978).\n\ncheck_heteroscedasticity(aov_dfc)\n\nOK: Error variance appears to be homoscedastic (p = 0.532).\n\n\nTodos os pacotes a seguir permitem a comparar as médias dos tratamentos:\n\nlibrary(performance)\ncheck_normality(aov_dfc)\n\nOK: residuals appear as normally distributed (p = 0.978).\n\ncheck_heteroscedasticity(aov_dfc)\n\nOK: Error variance appears to be homoscedastic (p = 0.532).\n\nlibrary(emmeans)\nmedias_dfc &lt;- emmeans(aov_dfc, ~ TRAT)\nmedias_dfc\n\n TRAT emmean    SE df lower.CL upper.CL\n 1     10.88 0.322 21    10.21    11.54\n 2      6.42 0.322 21     5.76     7.09\n 3      6.05 0.322 21     5.38     6.72\n 4      4.75 0.322 21     4.08     5.42\n 5      4.20 0.322 21     3.53     4.87\n 6      4.00 0.322 21     3.33     4.67\n 7      4.08 0.322 21     3.41     4.74\n 8      4.58 0.322 21     3.91     5.24\n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \n\npwpm(medias_dfc)\n\n        1       2       3       4       5       6       7       8\n1 [10.87]  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001\n2   4.450 [ 6.42]  0.9896  0.0249  0.0017  0.0006  0.0009  0.0107\n3   4.825   0.375 [ 6.05]  0.1329  0.0107  0.0040  0.0058  0.0628\n4   6.125   1.675   1.300 [ 4.75]  0.9202  0.7173  0.8072  0.9999\n5   6.675   2.225   1.850   0.550 [ 4.20]  0.9998  1.0000  0.9896\n6   6.875   2.425   2.050   0.750   0.200 [ 4.00]  1.0000  0.9020\n7   6.800   2.350   1.975   0.675   0.125  -0.075 [ 4.07]  0.9499\n8   6.300   1.850   1.475   0.175  -0.375  -0.575  -0.500 [ 4.57]\n\nRow and column labels: TRAT\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\nlibrary(multcomp)\ncld(medias_dfc, Letters = LETTERS)\n\n TRAT emmean    SE df lower.CL upper.CL .group\n 6      4.00 0.322 21     3.33     4.67  A    \n 7      4.08 0.322 21     3.41     4.74  A    \n 5      4.20 0.322 21     3.53     4.87  A    \n 8      4.58 0.322 21     3.91     5.24  AB   \n 4      4.75 0.322 21     4.08     5.42  AB   \n 3      6.05 0.322 21     5.38     6.72   BC  \n 2      6.42 0.322 21     5.76     7.09    C  \n 1     10.88 0.322 21    10.21    11.54     D \n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 8 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same."
  },
  {
    "objectID": "Aula8.html#anova-fer",
    "href": "Aula8.html#anova-fer",
    "title": "ANOVA",
    "section": "Anova FER",
    "text": "Anova FER\n\naov_fer &lt;- lm(FER ~ TRAT + BLOCO,\n              data = soja)\n\nanova(aov_fer)\n\nAnalysis of Variance Table\n\nResponse: FER\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nTRAT       7 978.87 139.838 55.1717 4.218e-12 ***\nBLOCO      3   3.84   1.279  0.5045    0.6834    \nResiduals 21  53.23   2.535                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nEfeito de tratamento foi significativo, de blocos não foi. Vai comparar as médias entre os tratamentos. Mesmo assim, tem que deixar os blocos, porque o delineamento do experimento foi em blocos casualizados. Antes de partir para as comparações múltiplas, tem que verificar as variâncias e homogeneidade.\nChecar normalidade e variancias:\n\ncheck_normality(aov_fer)\n\nWarning: Non-normality of residuals detected (p = 0.008).\n\ncheck_heteroscedasticity(aov_fer)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p &lt; .001).\n\nlibrary(DHARMa)\nplot(simulateResiduals(aov_fer)) #melhorou ainda mais a normmalidade e não atendeu a heterocedasticidade\n\n\n\n\n\n\n\n\nNão foi verificado homogeneidade e foi verificado heterocedasticidade entre as variâncias, então não pode continuar com a ANOVA.\n\n#Transformação dos dados por log\naov_fer2 &lt;- lm(log(FER) ~ TRAT + BLOCO,\n              data = soja)\n\nanova(aov_fer2)\n\nAnalysis of Variance Table\n\nResponse: log(FER)\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nTRAT       7 11.5210 1.64585 42.9665 4.838e-11 ***\nBLOCO      3  0.2064 0.06880  1.7961    0.1788    \nResiduals 21  0.8044 0.03831                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ncheck_normality(aov_fer2)\n\nOK: residuals appear as normally distributed (p = 0.255).\n\ncheck_heteroscedasticity(aov_fer2)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p = 0.035).\n\n\nComo o heterocedasticidade de 0,035, vamos considerar que não foi uma violação tão grave (num alfa de 0,05) e vamos seguir com a transformação\nTodos os pacotes a seguir permitem a comparar as médias dos tratamentos:\n\nlibrary(emmeans)\nmedias_fer &lt;- emmeans(aov_fer, ~ TRAT)\nmedias_fer\n\n TRAT emmean    SE df lower.CL upper.CL\n 1     20.25 0.796 21    18.59    21.91\n 2      5.88 0.796 21     4.22     7.53\n 3      4.00 0.796 21     2.34     5.66\n 4      3.12 0.796 21     1.47     4.78\n 5      3.25 0.796 21     1.59     4.91\n 6      3.00 0.796 21     1.34     4.66\n 7      3.38 0.796 21     1.72     5.03\n 8      3.50 0.796 21     1.84     5.16\n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \n\npwpm(medias_fer)\n\n        1       2       3       4       5       6       7       8\n1 [20.25]  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001\n2  14.375 [ 5.87]  0.7076  0.2722  0.3229  0.2273  0.3792  0.4404\n3  16.250   1.875 [ 4.00]  0.9926  0.9971  0.9840  0.9991  0.9998\n4  17.125   2.750   0.875 [ 3.12]  1.0000  1.0000  1.0000  1.0000\n5  17.000   2.625   0.750  -0.125 [ 3.25]  1.0000  1.0000  1.0000\n6  17.250   2.875   1.000   0.125   0.250 [ 3.00]  1.0000  0.9998\n7  16.875   2.500   0.625  -0.250  -0.125  -0.375 [ 3.37]  1.0000\n8  16.750   2.375   0.500  -0.375  -0.250  -0.500  -0.125 [ 3.50]\n\nRow and column labels: TRAT\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\nlibrary(multcomp)\ncld(medias_fer, Letters = LETTERS)\n\n TRAT emmean    SE df lower.CL upper.CL .group\n 6      3.00 0.796 21     1.34     4.66  A    \n 4      3.12 0.796 21     1.47     4.78  A    \n 5      3.25 0.796 21     1.59     4.91  A    \n 7      3.38 0.796 21     1.72     5.03  A    \n 8      3.50 0.796 21     1.84     5.16  A    \n 3      4.00 0.796 21     2.34     5.66  A    \n 2      5.88 0.796 21     4.22     7.53  A    \n 1     20.25 0.796 21    18.59    21.91   B   \n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 8 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nUtilizando o boxcox (variável transformada:\n\nlibrary(MASS)\nb &lt;- boxcox(lm(soja$FER+0.1 ~1))\n\n\n\n\n\n\n\nlambda &lt;- b$x[which.max(b$y)]\n\n#Usando o lambda na fórmula: y(lambda) = (x^lambda -1)/lambda\nsoja$FER3 &lt;- (soja$FER ^ lambda - 1) / lambda\n\naov_FER3 &lt;- lm(FER3 ~ TRAT + BLOCO,\n         data = soja)\n\nanova(aov_FER3)\n\nAnalysis of Variance Table\n\nResponse: FER3\n          Df   Sum Sq   Mean Sq F value    Pr(&gt;F)    \nTRAT       7 0.036632 0.0052332 12.5567 3.033e-06 ***\nBLOCO      3 0.005360 0.0017865  4.2867    0.0165 *  \nResiduals 21 0.008752 0.0004168                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ncheck_normality(aov_FER3)\n\nOK: residuals appear as normally distributed (p = 0.790).\n\ncheck_heteroscedasticity(aov_FER3)\n\nOK: Error variance appears to be homoscedastic (p = 0.834).\n\nmedias_fer3 &lt;- emmeans(aov_FER3, ~ TRAT)\nmedias_fer3\n\n TRAT emmean     SE df lower.CL upper.CL\n 1     0.621 0.0102 21    0.600    0.642\n 2     0.584 0.0102 21    0.563    0.605\n 3     0.543 0.0102 21    0.522    0.564\n 4     0.519 0.0102 21    0.498    0.540\n 5     0.530 0.0102 21    0.509    0.551\n 6     0.515 0.0102 21    0.494    0.536\n 7     0.536 0.0102 21    0.515    0.557\n 8     0.540 0.0102 21    0.519    0.561\n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \n\npwpm(medias_fer3)\n\n         1        2        3        4        5        6        7       8\n1  [0.621]   0.2155   0.0005   &lt;.0001   &lt;.0001   &lt;.0001   0.0002  0.0003\n2  0.03732  [0.584]   0.1390   0.0040   0.0221   0.0021   0.0527  0.0928\n3  0.07823  0.04091  [0.543]   0.7065   0.9822   0.5351   0.9996  1.0000\n4  0.10230  0.06498  0.02407  [0.519]   0.9934   1.0000   0.9312  0.8218\n5  0.09129  0.05397  0.01306 -0.01101  [0.530]   0.9614   0.9999  0.9963\n6  0.10637  0.06905  0.02814  0.00407  0.01508  [0.515]   0.8218  0.6654\n7  0.08538  0.04805  0.00715 -0.01692 -0.00592 -0.02100  [0.536]  1.0000\n8  0.08131  0.04398  0.00308 -0.02100 -0.00999 -0.02507 -0.00407 [0.540]\n\nRow and column labels: TRAT\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\nlibrary(multcomp)\ncld(medias_fer3, Letters = LETTERS)\n\n TRAT emmean     SE df lower.CL upper.CL .group\n 6     0.515 0.0102 21    0.494    0.536  A    \n 4     0.519 0.0102 21    0.498    0.540  A    \n 5     0.530 0.0102 21    0.509    0.551  A    \n 7     0.536 0.0102 21    0.515    0.557  AB   \n 8     0.540 0.0102 21    0.519    0.561  AB   \n 3     0.543 0.0102 21    0.522    0.564  AB   \n 2     0.584 0.0102 21    0.563    0.605   BC  \n 1     0.621 0.0102 21    0.600    0.642    C  \n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 8 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same."
  },
  {
    "objectID": "Aula8.html#anova-prod",
    "href": "Aula8.html#anova-prod",
    "title": "ANOVA",
    "section": "Anova PROD",
    "text": "Anova PROD\n\naov_prod &lt;- lm(PROD ~ TRAT + BLOCO,\n              data = soja)\n\nanova(aov_prod)\n\nAnalysis of Variance Table\n\nResponse: PROD\n          Df  Sum Sq Mean Sq F value  Pr(&gt;F)  \nTRAT       7 2993906  427701  2.6367 0.04021 *\nBLOCO      3  105665   35222  0.2171 0.88340  \nResiduals 21 3406431  162211                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nEfeito de tratamento foi significativo, de blocos não foi. Vai comparar as médias entre os tratamentos. Mesmo assim, tem que deixar os blocos, porque o delineamento do experimento foi em blocos casualizados. Antes de partir para as comparações múltiplas, tem que verificar as variâncias e homogeneidade.\nChecar normalidade e variancias:\n\ncheck_normality(aov_prod)\n\nOK: residuals appear as normally distributed (p = 0.542).\n\ncheck_heteroscedasticity(aov_prod)\n\nOK: Error variance appears to be homoscedastic (p = 0.215).\n\n\nTodos os pacotes a seguir permitem a comparar as médias dos tratamentos:\n\nmedias_prod &lt;- emmeans(aov_prod, ~ TRAT)\nmedias_prod\n\n TRAT emmean  SE df lower.CL upper.CL\n 1      4219 201 21     3800     4638\n 2      4935 201 21     4516     5354\n 3      5110 201 21     4691     5529\n 4      5140 201 21     4721     5559\n 5      5122 201 21     4703     5541\n 6      5256 201 21     4837     5675\n 7      5128 201 21     4709     5546\n 8      5078 201 21     4659     5497\n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \n\npwpm(medias_prod)\n\n        1       2       3       4       5       6       7      8\n1  [4219]  0.2430  0.0792  0.0640  0.0728  0.0272  0.0700 0.0985\n2  -715.8  [4935]  0.9983  0.9953  0.9974  0.9430  0.9968 0.9995\n3  -890.8  -175.0  [5110]  1.0000  1.0000  0.9994  1.0000 1.0000\n4  -921.0  -205.3   -30.3  [5140]  1.0000  0.9999  1.0000 1.0000\n5  -902.8  -187.0   -12.0    18.3  [5122]  0.9997  1.0000 1.0000\n6 -1037.0  -321.3  -146.3  -116.0  -134.3  [5256]  0.9998 0.9981\n7  -908.3  -192.5   -17.5    12.8    -5.5   128.8  [5127] 1.0000\n8  -859.0  -143.3    31.7    62.0    43.7   178.0    49.2 [5078]\n\nRow and column labels: TRAT\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\nlibrary(multcomp)\ncld(medias_prod, Letters = LETTERS)\n\n TRAT emmean  SE df lower.CL upper.CL .group\n 1      4219 201 21     3800     4638  A    \n 2      4935 201 21     4516     5354  AB   \n 8      5078 201 21     4659     5497  AB   \n 3      5110 201 21     4691     5529  AB   \n 5      5122 201 21     4703     5541  AB   \n 7      5128 201 21     4709     5546  AB   \n 4      5140 201 21     4721     5559  AB   \n 6      5256 201 21     4837     5675   B   \n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 8 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "FIP 606",
    "section": "",
    "text": "Sou Ana Carolyne, mestranda no Programa de Pós-Graduação em Fitopatologia da Universidade Federal de Viçosa, formada em Agronomia pela Universidade Federal Rural do Rio de Janeiro. Atualmente, atuo no Laboratório de Epidemiologia.\nOlá, seja bem vindo ao meu website!! Meu nome é Ana Carolyne, concluí minha graduação em Agronomia na Universidade Federal Rural do Rio de Janeiro e atualmente sou mestranda no Programa de Pós-Graduação em Fitopatologia na Universidade Federal de Viçosa. Atuo no Laboratório de Epidemiologia e estou ansiosa para continuar explorando novas oportunidades de aprendizado e crescimento, enquanto trabalho para fazer uma diferença positiva no campo da Fitopatologia.\n\n\nEste website é dedicado à disciplina FIP 606 - Análise e Visualização de Dados em Fitopatologia, oferecida pela Universidade Federal de Viçosa e ministrada pelo professor Emerson M. Del Ponte.\nNeste site, você encontrará todo o material das aulas, com códigos comentados e organizados de acordo com o cronograma da disciplina. O objetivo é facilitar o acesso ao conhecimento e fomentar o interesse pela análise de dados fitopatológicos utilizando o RStudio.\nConvido você a explorar os conteúdos disponíveis e a aproveitar ao máximo os recursos oferecidos. Se tiver qualquer dúvida ou sugestão, sinta-se à vontade para entrar em contato. Boa aprendizagem!"
  },
  {
    "objectID": "index.html#sobre-esse-site",
    "href": "index.html#sobre-esse-site",
    "title": "FIP 606",
    "section": "",
    "text": "Este website é dedicado à disciplina FIP 606 - Análise e Visualização de Dados em Fitopatologia, oferecida pela Universidade Federal de Viçosa e ministrada pelo professor Emerson M. Del Ponte.\nNeste site, você encontrará todo o material das aulas, com códigos comentados e organizados de acordo com o cronograma da disciplina. O objetivo é facilitar o acesso ao conhecimento e fomentar o interesse pela análise de dados fitopatológicos utilizando o RStudio.\nConvido você a explorar os conteúdos disponíveis e a aproveitar ao máximo os recursos oferecidos. Se tiver qualquer dúvida ou sugestão, sinta-se à vontade para entrar em contato. Boa aprendizagem!"
  }
]