{"title":"Aula 6","markdown":{"yaml":{"title":"Aula 6","format":"html","editor":"visual","message":false,"warning":false},"headingText":"Aula 6","containsRefs":false,"markdown":"\n\n\n## Bibliotecas\n\n```{r}\nlibrary(gsheet)\nlibrary(tidyverse)\nlibrary(report)\nlibrary(emmeans)\nlibrary(estimability)\nlibrary(see)\n\n```\n\n## Inferencial\n\nNesta aula, consideramos o alfa = 0,05.\n\n### Dois grupos independentes\n\n```{r}\nmg <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=983033137\")\n```\n\n#### Visualização\n\n```{r}\nmg |> \n  ggplot(aes(trat, comp))+\n  geom_boxplot()\n```\n\nHipótese científica: a suplementação de Mg reduz o tamanho da lesão. Hipótese estatística: H0 = as médias não diferem entre os tratamentos.\n\nVisualmente: Parece que tem um efeito da suplementação de magnésio reduzindo a redução da lesão. Indica que o Mg tem um efeito de indução de resistência na planta.\n\n\\*A diferença entre as medianas dá o tamanho desse efeito.\n\nPara dois grupos independentes, com normalidade garantida, usa-se normalmente o teste T. É independente porque são dois grupos medidos individualmente (10 plantas para trat control e 10 plantas para Mg2). \\* Se tivesse avaliações em diferentes tempos na mesma planta, seria dependente, pois a resposta seria dependente da planta.\n\nO box indica normalidade, de acordo com a simetria e dá uma ideia de variancia, por isso, para conjuntos com n \\> ou = 8, o boxplot pode ser bom para viasualizar e fazer a estatística inferencial.\n\n#### Teste T\n\nFunção que roda o teste T: ***t.test***\n\nPara o t.test precisa que os dados estejam no formato largo (a função pede os dados (tratamentos) em colunas separadas).\n\nTambém precisa verificar: homogeneidade de variâncias e normalidade (Shapiro-wilk test).\n\n```{r}\nmg2 <- mg |> \n  pivot_wider(names_from = trat,\n              values_from = comp)\n\nteste1 <- t.test(mg2$control, mg2$Mg2)\n```\n\nAssummindo que o test T está ok (normalidade e variâncias homogêneas), como o p-valor foi muito menor que 0,05, pode-se rejeitar a hipótese nula (H0). Ou seja, existe um efeito de indução de resistência.\n\nSe o intervalo de confiança não inclui o 0, dá diferença.\n\n#### Teste de normalidade\n\nPode ser feito visualmente, mas existe um teste que avalia a normalidade: shapiro.test No shapiro test a H0 = normalidade. Se p-value for maior do que 0,05, não rejeita H0, ou seja, assume normalidade. Se o p-valor for menor que 0,05, rejeita H0, então assume não normalidade.\n\nComo para os dois tratamentos foi maior 0,05, assume normalidade para os tratamentos.\n\n```{r}\nshapiro.test(mg2$control)\n\nhist(mg2$control)\n\nshapiro.test(mg2$Mg2)\n\nhist(mg2$Mg2)\n```\n\n-   normalmente variáveis numéricas contínuas tendem a apresentar normalidade.\n\nOutra forma de verificar a normalidade:\n\n```{r}\nqqnorm(mg2$control)\nqqline(mg2$control)\n```\n\n#### Teste de variância\n\nH0 = as variâncias são homogêneas\n\nComo valor p é maior que 0,05, assume que são homogeneas\n\n```{r}\nvar.test(mg2$control, mg2$Mg2)\n```\n\nComo as variancias e a normalidade estão okay, pode usar o teste T normalmente (tipico caso de análise paramétrica).\n\nCaso a variancia fosse heterogênea, poderia utilizar o teste T, porém deve informar que as variancias são heterogeneas:\n\n```{r}\nt.test(mg2$control, mg2$Mg2,\n       var.equal = FALSE)\n```\n\n#### Uso da função report\n\nO report cria um \"textinnho\" sobre o teste T que pode ser utilizado para justificar a estatística.\n\n```{r}\nreport(teste1)\n```\n\n### Dois grupos dependentes\n\nDependencia: mesmo avaliador em tempos diferentes\n\n```{r}\nescala <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1729131173\")\n```\n\nComo são dois grupos (avaliação com escala e sem escala), pode usar o Teste T novamente, todavia deve indicar o argumento de que é pareado.\n\n#### Visualização\n\n```{r}\nescala |> \n  ggplot(aes(assessment, acuracia))+\n  geom_boxplot()\n```\n\n#### Teste T\n\n```{r}\nescala2 <- escala |> \n  select(assessment, rater, acuracia) |> \n  pivot_wider(names_from = assessment,\n              values_from = acuracia)\n\nt.test(escala2$Aided1, escala2$Unaided,\n       var.equal = FALSE,\n       paired = TRUE)\n\n```\n\np-value \\< 0,05, por isso, rejeita H0: ou seja há um efeito do uso da escala diagramática aumentando a acurácia dos avaliadores. Como o intervalo de confiança não inclui 0 (varia de 0,113 até 0,252), indica que há diferença significativa.\n\n#### Normalidade\n\n```{r}\nshapiro.test(escala2$Unaided)\n\nhist(escala2$Unaided)\n\nshapiro.test(escala2$Aided1)\n\nhist(escala2$Aided1)\n```\n\nH0 = apresenta normalidade Normalidade okay (p-valor \\> 0,05, ou seja, aceita H0)\n\n#### Variância\n\n```{r}\nvar.test(escala2$Unaided, escala2$Aided1)\n```\n\nH0 = variâncias são homogêneas Variâncias são heterogêneas (p-value \\< 0,05, rejeita H0)\n\n### Teste não paramétrico\n\nHouve uma modificação nos dados (Escala) para que fiquem não paramétricos.\n\n#### Visualização\n\n```{r}\nescala <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1729131173\")\n\nescala |> \n  ggplot(aes(assessment, acuracia))+\n  geom_boxplot()\n```\n\n#### Teste de normalidade\n\n```{r}\nescala2 <- escala |> \n  select(assessment, rater, acuracia) |> \n  pivot_wider(names_from = assessment,\n              values_from = acuracia)\n\n\nshapiro.test(escala2$Unaided)\n\nhist(escala2$Unaided)\n\nshapiro.test(escala2$Aided1)\n\nhist(escala2$Aided1)\n```\n\nComo o p-valor é menor que 0,05, rejeita H0, dessa forma, não apresenta normalidade. A partir daí utilizaremos outro teste, equivalente ao Teste T, mas que usa-se para dados não paramétricos.\n\n#### Teste Wilcox\n\nNão precisa verificar as variâncias.\n\n```{r}\nwilcox.test(escala2$Aided1,\n            escala2$Unaided,\n            paired = TRUE)\n```\n\nComo o p-valor é menor que 0,05, rejeita H0, dessa forma as médias são diferentes. Ou seja, há um efeito do uso da escala diagramática aumentando a acurácia dos avaliadores.\n\nSe os dados não atenderem as pressimas para análise paramétrica, pode-se usar um teste não paramétrico, ou, fazer a transformação dos dados, para que esses valores transformados possam atender as premissas. Porém, ao se usar os dados transformados, não está usando os dados originais (não está errado, é apenas uma metodologia diferente).\n\nt.test -\\> pareado (paired = \"TRUE\") -\\> não-pareado (paired = \"FALSE\" - não precisa porque já assume isso)\n\n```         \n   -> variâncias homogêneas (var.equal = TRUE - não precisa porque já assume isso)\n   -> variâncias heterogêneas (var.equal = FALSE)\n   \n```\n\nwilcox.test -\\> pareado (paired = TRUE) não-pareado (paired = FALSE) = Mann-Whitney test\n\n### Três ou mais grupos\n\nANOVA: Hipótese alternativa é que pelo menos uma média é diferente das outras. Mas não diz qual média é diferente das outras, para isso, usa o teste de comparação de médias. H0 = as médias não diferem.\n\ntcm = taxa de crescimento micelial\n\n```{r}\nmicelial <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=959387827\")\n```\n\n#### Visualização\n\n```{r}\nmicelial |> \n  ggplot(aes(especie, tcm))+\n  geom_jitter(width = 0.01)+\n  stat_summary(\n    geom = \"point\",\n    fun.y = \"mean\",\n    size = 3,\n    color = \"red\"\n  )\n```\n\nVisualmente: parece que a dispersão dos dados é muito grande, dessa forma não parece haver muita diferença entre os grupos.\n\nTeste F: é a razão da variância entre os grupos sobre a variância dentro dos grupos.\n\n#### Teste Anova\n\n```{r}\nm1 <- lm(tcm ~especie, data = micelial)\n\nanova(m1)\nsummary(m1)\n```\n\nDF = grau de liberdade Sum Sq = é a soma dos quadrados Mean SQ = média da soma dos quadrados (variância) F value (valor F) = variância da espécie/média de residuals Quanto \\> o F, \\< o p-valor\n\nComo p-valor \\> 0,05 (0,055), não descartamos H0, ou seja, não a diferença entre as médias. Ou seja, não há diferença entre o crescimento micelial das espécies.\n\nPara retirar o intercepto e dar os valores médios direto\n\n```{r}\nm1 <- lm(tcm ~especie -1, data = micelial)\n\nanova(m1)\nsummary(m1)\n```\n\nPara ter variabilidade, modificamos os dados, para ter efeito de espécie.\n\n```{r}\nmicelial <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=959387827\")\n\nmicelial |> \n  ggplot(aes(especie, tcm))+\n  geom_jitter(width = 0.01)+\n  stat_summary(\n    geom = \"point\",\n    fun.y = \"mean\",\n    size = 3,\n    color = \"red\"\n  )\n```\n\n#### Teste Anova (com dados alterados)\n\n```{r}\nm1 <- lm(tcm ~especie, data = micelial)\n\nanova(m1)\nsummary(m1) #<- visualiza a diferença entre os grupos\n```\n\nComo valor-p \\< 0,05 (2.028e-07), rejeitamos H0, dessa forma, pelo menos uma espécie difere das outras.\n\n-   o summary compara a média de todos com asiaticus (intercepto) e não de todos contra todos.\n\n## Para verificar a diferença entre as médias\n\n```{r}\nmedias1 <- emmeans(m1, ~especie)\n\nlibrary(multcomp)\nlibrary(multcompView) #para colocar as letrinhas\ncld(medias1)\n```\n\n#### Verificando as premissas\n\n```{r}\n#Para verificar normalidade:\nhist(m1$residuals)\nshapiro.test(m1$residuals)\n\n#Para verificar as variâncias:\nbartlett.test(tcm ~especie, data = micelial)\n\nlibrary(DHARMa)\nplot(simulateResiduals(m1))\n\nlibrary(performance)\ncheck_normality(m1)\ncheck_heteroscedasticity(m1) #(variâncias homogêneas = homoscedastic)\ncheck_model(m1)\n\n```\n\n# Aula 7\n\n## Importação dos dados\n\n```{r}\ninseticida <- InsectSprays\n\ninseticida |> \n  count(spray)\n```\n\n12 repetições para cada spray. tem um fator só (inseticida = spray) -\\> vai ser Anova unifatorial (um fator só com seis níveis).\n\n### Visualização\n\nVer se tem normalidade dos resíduos e homogeneidade entre as variâncias.\n\n```{r}\ninseticida |> \n  ggplot(aes(spray, count))+\n  geom_boxplot()\n```\n\nF é o que tem maior variância, o que tem menor é o C e D (tem outlier), parece que (visualmente) as variâncias não são homogêneas.\n\n1º Ajusta ANOVA 2º trabalha com resíduos da ANOVA (aplica os testes)\n\n**lm** = função que ajusta anova\n\n```{r}\nm1 <- lm(count ~ spray,\n         data = inseticida)\n\nsummary(m1)\nanova(m1)\n\nhist(m1$residuals)\nshapiro.test(m1$residuals)\nqqnorm(m1$residuals)\nqqline(m1$residuals)\n\nbartlett.test(count ~ spray,\n             data = inseticida)\n```\n\nOs resíduos parecem ter normalidade visualizando pelo histograma. AO fazer o shapiro.test, vê-se que não tem normalidade, pq o p-valor \\< 0,05, então rejeita H0 (H0 = normalidade).\n\nMais grave: variâncias não serem homogêneas, do que normalidade.\n\n```{r}\nlibrary(performance)\ncheck_normality(m1)\ncheck_heteroscedasticity(m1)\n\nlibrary(DHARMa)\nplot(simulateResiduals(m1))\n```\n\nCom ***performance*** e **DHARma**, foi possível ver que não tem normalidade e que as variâncias são heterogêneas. O DHARma faz o outro test (KS test) -- saída das variâncias com texto em vermelho indica que as variâncias são heterogêneas.\n\nTranformações mais comuns: log de x (quando tem 0, adiciona a constante + 0,5) raiz quadrada de x arc seno de x\n\n### Alternativa 1: fazer a transformação dos dados\n\nNormalmente, quando tem contagem (numérica discreta), raiz quadrada resolve.\n\nFunção **sqrt** faz a raiz quadrada.\n\n```{r}\ninseticida <- inseticida |> \n  mutate(count2 = sqrt(count))\n\ninseticida |> \n  ggplot(aes(spray, count2))+\n  geom_boxplot()\n```\n\nAgora, variancias parecem mais iguais, dessa forma, visualmente parece que a raiz quadrada está homogeneizando as variâncias.\n\n```{r}\nm2 <- lm(count2 ~ spray,\n         data = inseticida)\n\nsummary(m2)\nanova(m2)\nhist(m2$residuals)\nshapiro.test(m2$residuals)  # tem normalidade\nqqnorm(m2$residuals)\nqqline(m2$residuals)\nbartlett.test(count2 ~spray,\n             data = inseticida)  # tem homgeneidade das variâncias\n```\n\nCom a transformação alcançou a normalidade e homogeneidade de variancias. Em ***anova(m2)*** pode ver que pelo menos um grupo difere dos demais (p-valor \\< 0,05)\n\n```{r}\nlibrary(performance)\ncheck_normality(m2)\ncheck_heteroscedasticity(m2)\n\nlibrary(DHARMa)\nplot(simulateResiduals(m2)) #melhorou ainda mais a normmalidade e variância deu ñ significativo\n```\n\nQuando for avaliar, utilizar os diferentes testes para garantir confiabilidade. ANOVa é um teste mais robusto à falta de normalidade do que à heterocedasticidade.\n\n```{r}\n# Para m1 (dados não transformados)\nlibrary(emmeans)\nm1_medias <- emmeans(m1, ~ spray,)\nplot(m1_medias)\n\nlibrary(multcomp)\ncld(m1_medias)\n\n# Para m2 (dados transformados)\nlibrary(emmeans)\nm2_medias <- emmeans(m2, ~ spray,)\nplot(m2_medias)\n\nlibrary(multcomp)\ncld(m2_medias)\npwpm(m2_medias)\npwpp(m2_medias)\npairs(m2_medias)\n# quando usa os dados não transformados tá cometendo o erro do tipo 2, não estava mostrando a diferença quando existia (mostrou só 2 grupos e quando com dados transformados dividiu em 3)\n```\n\nUtilizando o pwpm mostrou a comparação entre cada um dos grupos (comparação par a par). Quando o valor (é igual ao p-valor) é \\< 0,05, diz que são de grupos diferentes (rejeita H0), enquanto valor \\> 0,05, pertencem ao mesmo grupo (não rejeita H0).\n\n#### Testando outras formas de transformação\n\nBox-Cox: y(lambda) = (x\\^lambda -1)/lambda lambda é o valor de x onde o y é máximo Sempre que o lambda = 0,5 é igual a raiz quadrado\n\n```{r}\nlibrary(MASS)\nb <- boxcox(lm(inseticida$count+0.1 ~1))\nlambda <- b$x[which.max(b$y)]\n\n# O lambda (0,42) é o que usaremos na fórmula para transformar os dados --> variável transformada\n\n#Usando o lambda (0,42) na fórmula: y(lambda) = (x^lambda -1)/lambda\ninseticida$count3 <- (inseticida$count ^ lambda - 1) / lambda\n\nm5 <- lm(count3 ~ spray,\n         data = inseticida)\n\nsummary(m5)\nanova(m5)\nhist(m5$residuals)\nshapiro.test(m5$residuals)  \nqqnorm(m5$residuals)\nqqline(m5$residuals)\nbartlett.test(count3 ~spray,\n             data = inseticida)\n\n# é uma forma de estabilizar variância também\n```\n\n### Alternativa 2: teste não paramétrico\n\nUsa saída original (sem transformar). Faz um rankeamento.\n\n```{r}\nlibrary(agricolae)\n\nkruskal.test(count ~spray,\n             data = inseticida) #kruskal.test é do R base\n\n# usando o agricolae\nm3 <- kruskal(inseticida$count,\n        inseticida$spray,\n        group = TRUE)\n```\n\nH0 = médias são iguais Como Kruskal-wallis, rejeita H0, então as médias são diferentes\n\nO não-paramétrico deu os mesmos resultados dos valores transformados.\n\nmodelo linear generalizado = glm. É o modelo menos criticado (entre os transformado e não-paramétrico). Utiliza a distribuição apropriado.\n\n### Alternativa 3: GLMs\n\nDistribuição de dados contagem (numérica discreta): poisson se ajusta também a essa distribuição (de 0 para cima)\n\n```{r}\n# glm com a familia gaussiana reduz a lm\nm4 <- glm(count ~ spray,\n          family = gaussian,\n          data = inseticida)\n\n# utilizando com a família poisson\nm4 <- glm(count ~ spray,\n          family = poisson,\n          data = inseticida)\nsummary(m4)\nanova(m4)\n\nlibrary(car)\nAnova(m4)\nplot(simulateResiduals(m4))\n\nm4_medias <- emmeans(m4, ~spray,\n                     type = \"response\")\n\ncld(m4_medias)\n```\n\nAnova: tem um que é diferente dos outros (p-valor \\<0,05). Os grupos com o GLM foram iguais às outras alternativas (dados transformados e não-paramétrico)\n\n## Anova 2 fatores = Modelo fatorial (two-way anova)\n\n#### Importa os dados\n\n```{r}\ntheme_set(theme_bw())\nli <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=2023059672\")\n\n#visualização dos dados\n\nli |> \n  ggplot(aes(factor(dose), severity, color = factor(dose)))+\n  geom_jitter(width = 0.05)+\n  facet_wrap(~~treat)\n\nli |> \n  ggplot(aes(factor(treat), severity, color = factor(dose)))+\n  geom_jitter(width = 0.05)\n```\n\n### Anova\n\n```{r}\nmf <- lm(severity ~treat*factor(dose),\n         data = li)\n\nanova(mf)\n```\n\ntreat:dose = interação Interação significativa: tem que estimar as médias de um dentro do outro (combinação dos fatores). São quatro valores médios (LI-0,5, LI-2,0, TEB-0,5 e TEB-2,0 = 4 médias). Letras maiusculas comparam as colunas e as minusculas comparam as linhas\n\n```         \n      0,5             2,0\n```\n\nLI Média Aa Média Ab TEB Média Ba Média Aa\n\n#### Testar as premissas\n\n```{r}\nplot(simulateResiduals(mf))\n```\n\nDharma: não teve problema na normalidade dos residuals, nem na heterocedasticidade\n\n```{r}\ncheck_heteroscedasticity(mf)\ncheck_homogeneity(mf)\n```\n\nUtilizando o performance, os resultados foram o contrário do DHArma, mas o Dharma é mais confiável, então vamos prosseguir.\n\n#### COMPARAR AS COLUNAS\n\n```{r}\nmf_medias <- emmeans(mf, ~ treat | dose)\ncld(mf_medias)  #para mostrar os grupos\n```\n\n```         \n         DOSES\n```\n\nTREAT 0,5 \\| 2,0 LI \\| 0,29 A \\| 0,05 A TEB \\| 0,02 B \\| 0,02 A\n\n####COMPARAR AS LINHAS\n\n```{r}\nmf_medias <- emmeans(mf, ~ dose | treat)\ncld(mf_medias)\n```\n\n```         \n         DOSES\n```\n\nTREAT\\| 0,5 \\| 2,0 LI \\| 0,29 Aa \\| 0,05 Ab TEB \\| 0,02 Ba \\| 0,02 Aa\n","srcMarkdownNoYaml":"\n\n# Aula 6\n\n## Bibliotecas\n\n```{r}\nlibrary(gsheet)\nlibrary(tidyverse)\nlibrary(report)\nlibrary(emmeans)\nlibrary(estimability)\nlibrary(see)\n\n```\n\n## Inferencial\n\nNesta aula, consideramos o alfa = 0,05.\n\n### Dois grupos independentes\n\n```{r}\nmg <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=983033137\")\n```\n\n#### Visualização\n\n```{r}\nmg |> \n  ggplot(aes(trat, comp))+\n  geom_boxplot()\n```\n\nHipótese científica: a suplementação de Mg reduz o tamanho da lesão. Hipótese estatística: H0 = as médias não diferem entre os tratamentos.\n\nVisualmente: Parece que tem um efeito da suplementação de magnésio reduzindo a redução da lesão. Indica que o Mg tem um efeito de indução de resistência na planta.\n\n\\*A diferença entre as medianas dá o tamanho desse efeito.\n\nPara dois grupos independentes, com normalidade garantida, usa-se normalmente o teste T. É independente porque são dois grupos medidos individualmente (10 plantas para trat control e 10 plantas para Mg2). \\* Se tivesse avaliações em diferentes tempos na mesma planta, seria dependente, pois a resposta seria dependente da planta.\n\nO box indica normalidade, de acordo com a simetria e dá uma ideia de variancia, por isso, para conjuntos com n \\> ou = 8, o boxplot pode ser bom para viasualizar e fazer a estatística inferencial.\n\n#### Teste T\n\nFunção que roda o teste T: ***t.test***\n\nPara o t.test precisa que os dados estejam no formato largo (a função pede os dados (tratamentos) em colunas separadas).\n\nTambém precisa verificar: homogeneidade de variâncias e normalidade (Shapiro-wilk test).\n\n```{r}\nmg2 <- mg |> \n  pivot_wider(names_from = trat,\n              values_from = comp)\n\nteste1 <- t.test(mg2$control, mg2$Mg2)\n```\n\nAssummindo que o test T está ok (normalidade e variâncias homogêneas), como o p-valor foi muito menor que 0,05, pode-se rejeitar a hipótese nula (H0). Ou seja, existe um efeito de indução de resistência.\n\nSe o intervalo de confiança não inclui o 0, dá diferença.\n\n#### Teste de normalidade\n\nPode ser feito visualmente, mas existe um teste que avalia a normalidade: shapiro.test No shapiro test a H0 = normalidade. Se p-value for maior do que 0,05, não rejeita H0, ou seja, assume normalidade. Se o p-valor for menor que 0,05, rejeita H0, então assume não normalidade.\n\nComo para os dois tratamentos foi maior 0,05, assume normalidade para os tratamentos.\n\n```{r}\nshapiro.test(mg2$control)\n\nhist(mg2$control)\n\nshapiro.test(mg2$Mg2)\n\nhist(mg2$Mg2)\n```\n\n-   normalmente variáveis numéricas contínuas tendem a apresentar normalidade.\n\nOutra forma de verificar a normalidade:\n\n```{r}\nqqnorm(mg2$control)\nqqline(mg2$control)\n```\n\n#### Teste de variância\n\nH0 = as variâncias são homogêneas\n\nComo valor p é maior que 0,05, assume que são homogeneas\n\n```{r}\nvar.test(mg2$control, mg2$Mg2)\n```\n\nComo as variancias e a normalidade estão okay, pode usar o teste T normalmente (tipico caso de análise paramétrica).\n\nCaso a variancia fosse heterogênea, poderia utilizar o teste T, porém deve informar que as variancias são heterogeneas:\n\n```{r}\nt.test(mg2$control, mg2$Mg2,\n       var.equal = FALSE)\n```\n\n#### Uso da função report\n\nO report cria um \"textinnho\" sobre o teste T que pode ser utilizado para justificar a estatística.\n\n```{r}\nreport(teste1)\n```\n\n### Dois grupos dependentes\n\nDependencia: mesmo avaliador em tempos diferentes\n\n```{r}\nescala <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1729131173\")\n```\n\nComo são dois grupos (avaliação com escala e sem escala), pode usar o Teste T novamente, todavia deve indicar o argumento de que é pareado.\n\n#### Visualização\n\n```{r}\nescala |> \n  ggplot(aes(assessment, acuracia))+\n  geom_boxplot()\n```\n\n#### Teste T\n\n```{r}\nescala2 <- escala |> \n  select(assessment, rater, acuracia) |> \n  pivot_wider(names_from = assessment,\n              values_from = acuracia)\n\nt.test(escala2$Aided1, escala2$Unaided,\n       var.equal = FALSE,\n       paired = TRUE)\n\n```\n\np-value \\< 0,05, por isso, rejeita H0: ou seja há um efeito do uso da escala diagramática aumentando a acurácia dos avaliadores. Como o intervalo de confiança não inclui 0 (varia de 0,113 até 0,252), indica que há diferença significativa.\n\n#### Normalidade\n\n```{r}\nshapiro.test(escala2$Unaided)\n\nhist(escala2$Unaided)\n\nshapiro.test(escala2$Aided1)\n\nhist(escala2$Aided1)\n```\n\nH0 = apresenta normalidade Normalidade okay (p-valor \\> 0,05, ou seja, aceita H0)\n\n#### Variância\n\n```{r}\nvar.test(escala2$Unaided, escala2$Aided1)\n```\n\nH0 = variâncias são homogêneas Variâncias são heterogêneas (p-value \\< 0,05, rejeita H0)\n\n### Teste não paramétrico\n\nHouve uma modificação nos dados (Escala) para que fiquem não paramétricos.\n\n#### Visualização\n\n```{r}\nescala <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1729131173\")\n\nescala |> \n  ggplot(aes(assessment, acuracia))+\n  geom_boxplot()\n```\n\n#### Teste de normalidade\n\n```{r}\nescala2 <- escala |> \n  select(assessment, rater, acuracia) |> \n  pivot_wider(names_from = assessment,\n              values_from = acuracia)\n\n\nshapiro.test(escala2$Unaided)\n\nhist(escala2$Unaided)\n\nshapiro.test(escala2$Aided1)\n\nhist(escala2$Aided1)\n```\n\nComo o p-valor é menor que 0,05, rejeita H0, dessa forma, não apresenta normalidade. A partir daí utilizaremos outro teste, equivalente ao Teste T, mas que usa-se para dados não paramétricos.\n\n#### Teste Wilcox\n\nNão precisa verificar as variâncias.\n\n```{r}\nwilcox.test(escala2$Aided1,\n            escala2$Unaided,\n            paired = TRUE)\n```\n\nComo o p-valor é menor que 0,05, rejeita H0, dessa forma as médias são diferentes. Ou seja, há um efeito do uso da escala diagramática aumentando a acurácia dos avaliadores.\n\nSe os dados não atenderem as pressimas para análise paramétrica, pode-se usar um teste não paramétrico, ou, fazer a transformação dos dados, para que esses valores transformados possam atender as premissas. Porém, ao se usar os dados transformados, não está usando os dados originais (não está errado, é apenas uma metodologia diferente).\n\nt.test -\\> pareado (paired = \"TRUE\") -\\> não-pareado (paired = \"FALSE\" - não precisa porque já assume isso)\n\n```         \n   -> variâncias homogêneas (var.equal = TRUE - não precisa porque já assume isso)\n   -> variâncias heterogêneas (var.equal = FALSE)\n   \n```\n\nwilcox.test -\\> pareado (paired = TRUE) não-pareado (paired = FALSE) = Mann-Whitney test\n\n### Três ou mais grupos\n\nANOVA: Hipótese alternativa é que pelo menos uma média é diferente das outras. Mas não diz qual média é diferente das outras, para isso, usa o teste de comparação de médias. H0 = as médias não diferem.\n\ntcm = taxa de crescimento micelial\n\n```{r}\nmicelial <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=959387827\")\n```\n\n#### Visualização\n\n```{r}\nmicelial |> \n  ggplot(aes(especie, tcm))+\n  geom_jitter(width = 0.01)+\n  stat_summary(\n    geom = \"point\",\n    fun.y = \"mean\",\n    size = 3,\n    color = \"red\"\n  )\n```\n\nVisualmente: parece que a dispersão dos dados é muito grande, dessa forma não parece haver muita diferença entre os grupos.\n\nTeste F: é a razão da variância entre os grupos sobre a variância dentro dos grupos.\n\n#### Teste Anova\n\n```{r}\nm1 <- lm(tcm ~especie, data = micelial)\n\nanova(m1)\nsummary(m1)\n```\n\nDF = grau de liberdade Sum Sq = é a soma dos quadrados Mean SQ = média da soma dos quadrados (variância) F value (valor F) = variância da espécie/média de residuals Quanto \\> o F, \\< o p-valor\n\nComo p-valor \\> 0,05 (0,055), não descartamos H0, ou seja, não a diferença entre as médias. Ou seja, não há diferença entre o crescimento micelial das espécies.\n\nPara retirar o intercepto e dar os valores médios direto\n\n```{r}\nm1 <- lm(tcm ~especie -1, data = micelial)\n\nanova(m1)\nsummary(m1)\n```\n\nPara ter variabilidade, modificamos os dados, para ter efeito de espécie.\n\n```{r}\nmicelial <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=959387827\")\n\nmicelial |> \n  ggplot(aes(especie, tcm))+\n  geom_jitter(width = 0.01)+\n  stat_summary(\n    geom = \"point\",\n    fun.y = \"mean\",\n    size = 3,\n    color = \"red\"\n  )\n```\n\n#### Teste Anova (com dados alterados)\n\n```{r}\nm1 <- lm(tcm ~especie, data = micelial)\n\nanova(m1)\nsummary(m1) #<- visualiza a diferença entre os grupos\n```\n\nComo valor-p \\< 0,05 (2.028e-07), rejeitamos H0, dessa forma, pelo menos uma espécie difere das outras.\n\n-   o summary compara a média de todos com asiaticus (intercepto) e não de todos contra todos.\n\n## Para verificar a diferença entre as médias\n\n```{r}\nmedias1 <- emmeans(m1, ~especie)\n\nlibrary(multcomp)\nlibrary(multcompView) #para colocar as letrinhas\ncld(medias1)\n```\n\n#### Verificando as premissas\n\n```{r}\n#Para verificar normalidade:\nhist(m1$residuals)\nshapiro.test(m1$residuals)\n\n#Para verificar as variâncias:\nbartlett.test(tcm ~especie, data = micelial)\n\nlibrary(DHARMa)\nplot(simulateResiduals(m1))\n\nlibrary(performance)\ncheck_normality(m1)\ncheck_heteroscedasticity(m1) #(variâncias homogêneas = homoscedastic)\ncheck_model(m1)\n\n```\n\n# Aula 7\n\n## Importação dos dados\n\n```{r}\ninseticida <- InsectSprays\n\ninseticida |> \n  count(spray)\n```\n\n12 repetições para cada spray. tem um fator só (inseticida = spray) -\\> vai ser Anova unifatorial (um fator só com seis níveis).\n\n### Visualização\n\nVer se tem normalidade dos resíduos e homogeneidade entre as variâncias.\n\n```{r}\ninseticida |> \n  ggplot(aes(spray, count))+\n  geom_boxplot()\n```\n\nF é o que tem maior variância, o que tem menor é o C e D (tem outlier), parece que (visualmente) as variâncias não são homogêneas.\n\n1º Ajusta ANOVA 2º trabalha com resíduos da ANOVA (aplica os testes)\n\n**lm** = função que ajusta anova\n\n```{r}\nm1 <- lm(count ~ spray,\n         data = inseticida)\n\nsummary(m1)\nanova(m1)\n\nhist(m1$residuals)\nshapiro.test(m1$residuals)\nqqnorm(m1$residuals)\nqqline(m1$residuals)\n\nbartlett.test(count ~ spray,\n             data = inseticida)\n```\n\nOs resíduos parecem ter normalidade visualizando pelo histograma. AO fazer o shapiro.test, vê-se que não tem normalidade, pq o p-valor \\< 0,05, então rejeita H0 (H0 = normalidade).\n\nMais grave: variâncias não serem homogêneas, do que normalidade.\n\n```{r}\nlibrary(performance)\ncheck_normality(m1)\ncheck_heteroscedasticity(m1)\n\nlibrary(DHARMa)\nplot(simulateResiduals(m1))\n```\n\nCom ***performance*** e **DHARma**, foi possível ver que não tem normalidade e que as variâncias são heterogêneas. O DHARma faz o outro test (KS test) -- saída das variâncias com texto em vermelho indica que as variâncias são heterogêneas.\n\nTranformações mais comuns: log de x (quando tem 0, adiciona a constante + 0,5) raiz quadrada de x arc seno de x\n\n### Alternativa 1: fazer a transformação dos dados\n\nNormalmente, quando tem contagem (numérica discreta), raiz quadrada resolve.\n\nFunção **sqrt** faz a raiz quadrada.\n\n```{r}\ninseticida <- inseticida |> \n  mutate(count2 = sqrt(count))\n\ninseticida |> \n  ggplot(aes(spray, count2))+\n  geom_boxplot()\n```\n\nAgora, variancias parecem mais iguais, dessa forma, visualmente parece que a raiz quadrada está homogeneizando as variâncias.\n\n```{r}\nm2 <- lm(count2 ~ spray,\n         data = inseticida)\n\nsummary(m2)\nanova(m2)\nhist(m2$residuals)\nshapiro.test(m2$residuals)  # tem normalidade\nqqnorm(m2$residuals)\nqqline(m2$residuals)\nbartlett.test(count2 ~spray,\n             data = inseticida)  # tem homgeneidade das variâncias\n```\n\nCom a transformação alcançou a normalidade e homogeneidade de variancias. Em ***anova(m2)*** pode ver que pelo menos um grupo difere dos demais (p-valor \\< 0,05)\n\n```{r}\nlibrary(performance)\ncheck_normality(m2)\ncheck_heteroscedasticity(m2)\n\nlibrary(DHARMa)\nplot(simulateResiduals(m2)) #melhorou ainda mais a normmalidade e variância deu ñ significativo\n```\n\nQuando for avaliar, utilizar os diferentes testes para garantir confiabilidade. ANOVa é um teste mais robusto à falta de normalidade do que à heterocedasticidade.\n\n```{r}\n# Para m1 (dados não transformados)\nlibrary(emmeans)\nm1_medias <- emmeans(m1, ~ spray,)\nplot(m1_medias)\n\nlibrary(multcomp)\ncld(m1_medias)\n\n# Para m2 (dados transformados)\nlibrary(emmeans)\nm2_medias <- emmeans(m2, ~ spray,)\nplot(m2_medias)\n\nlibrary(multcomp)\ncld(m2_medias)\npwpm(m2_medias)\npwpp(m2_medias)\npairs(m2_medias)\n# quando usa os dados não transformados tá cometendo o erro do tipo 2, não estava mostrando a diferença quando existia (mostrou só 2 grupos e quando com dados transformados dividiu em 3)\n```\n\nUtilizando o pwpm mostrou a comparação entre cada um dos grupos (comparação par a par). Quando o valor (é igual ao p-valor) é \\< 0,05, diz que são de grupos diferentes (rejeita H0), enquanto valor \\> 0,05, pertencem ao mesmo grupo (não rejeita H0).\n\n#### Testando outras formas de transformação\n\nBox-Cox: y(lambda) = (x\\^lambda -1)/lambda lambda é o valor de x onde o y é máximo Sempre que o lambda = 0,5 é igual a raiz quadrado\n\n```{r}\nlibrary(MASS)\nb <- boxcox(lm(inseticida$count+0.1 ~1))\nlambda <- b$x[which.max(b$y)]\n\n# O lambda (0,42) é o que usaremos na fórmula para transformar os dados --> variável transformada\n\n#Usando o lambda (0,42) na fórmula: y(lambda) = (x^lambda -1)/lambda\ninseticida$count3 <- (inseticida$count ^ lambda - 1) / lambda\n\nm5 <- lm(count3 ~ spray,\n         data = inseticida)\n\nsummary(m5)\nanova(m5)\nhist(m5$residuals)\nshapiro.test(m5$residuals)  \nqqnorm(m5$residuals)\nqqline(m5$residuals)\nbartlett.test(count3 ~spray,\n             data = inseticida)\n\n# é uma forma de estabilizar variância também\n```\n\n### Alternativa 2: teste não paramétrico\n\nUsa saída original (sem transformar). Faz um rankeamento.\n\n```{r}\nlibrary(agricolae)\n\nkruskal.test(count ~spray,\n             data = inseticida) #kruskal.test é do R base\n\n# usando o agricolae\nm3 <- kruskal(inseticida$count,\n        inseticida$spray,\n        group = TRUE)\n```\n\nH0 = médias são iguais Como Kruskal-wallis, rejeita H0, então as médias são diferentes\n\nO não-paramétrico deu os mesmos resultados dos valores transformados.\n\nmodelo linear generalizado = glm. É o modelo menos criticado (entre os transformado e não-paramétrico). Utiliza a distribuição apropriado.\n\n### Alternativa 3: GLMs\n\nDistribuição de dados contagem (numérica discreta): poisson se ajusta também a essa distribuição (de 0 para cima)\n\n```{r}\n# glm com a familia gaussiana reduz a lm\nm4 <- glm(count ~ spray,\n          family = gaussian,\n          data = inseticida)\n\n# utilizando com a família poisson\nm4 <- glm(count ~ spray,\n          family = poisson,\n          data = inseticida)\nsummary(m4)\nanova(m4)\n\nlibrary(car)\nAnova(m4)\nplot(simulateResiduals(m4))\n\nm4_medias <- emmeans(m4, ~spray,\n                     type = \"response\")\n\ncld(m4_medias)\n```\n\nAnova: tem um que é diferente dos outros (p-valor \\<0,05). Os grupos com o GLM foram iguais às outras alternativas (dados transformados e não-paramétrico)\n\n## Anova 2 fatores = Modelo fatorial (two-way anova)\n\n#### Importa os dados\n\n```{r}\ntheme_set(theme_bw())\nli <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=2023059672\")\n\n#visualização dos dados\n\nli |> \n  ggplot(aes(factor(dose), severity, color = factor(dose)))+\n  geom_jitter(width = 0.05)+\n  facet_wrap(~~treat)\n\nli |> \n  ggplot(aes(factor(treat), severity, color = factor(dose)))+\n  geom_jitter(width = 0.05)\n```\n\n### Anova\n\n```{r}\nmf <- lm(severity ~treat*factor(dose),\n         data = li)\n\nanova(mf)\n```\n\ntreat:dose = interação Interação significativa: tem que estimar as médias de um dentro do outro (combinação dos fatores). São quatro valores médios (LI-0,5, LI-2,0, TEB-0,5 e TEB-2,0 = 4 médias). Letras maiusculas comparam as colunas e as minusculas comparam as linhas\n\n```         \n      0,5             2,0\n```\n\nLI Média Aa Média Ab TEB Média Ba Média Aa\n\n#### Testar as premissas\n\n```{r}\nplot(simulateResiduals(mf))\n```\n\nDharma: não teve problema na normalidade dos residuals, nem na heterocedasticidade\n\n```{r}\ncheck_heteroscedasticity(mf)\ncheck_homogeneity(mf)\n```\n\nUtilizando o performance, os resultados foram o contrário do DHArma, mas o Dharma é mais confiável, então vamos prosseguir.\n\n#### COMPARAR AS COLUNAS\n\n```{r}\nmf_medias <- emmeans(mf, ~ treat | dose)\ncld(mf_medias)  #para mostrar os grupos\n```\n\n```         \n         DOSES\n```\n\nTREAT 0,5 \\| 2,0 LI \\| 0,29 A \\| 0,05 A TEB \\| 0,02 B \\| 0,02 A\n\n####COMPARAR AS LINHAS\n\n```{r}\nmf_medias <- emmeans(mf, ~ dose | treat)\ncld(mf_medias)\n```\n\n```         \n         DOSES\n```\n\nTREAT\\| 0,5 \\| 2,0 LI \\| 0,29 Aa \\| 0,05 Ab TEB \\| 0,02 Ba \\| 0,02 Aa\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":true,"freeze":"auto","echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"output-file":"Aula6.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.555","editor":"visual","theme":{"light":"Minty","dark":"superhero"},"title":"Aula 6","message":false},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}