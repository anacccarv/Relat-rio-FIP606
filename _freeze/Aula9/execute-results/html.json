{
  "hash": "fbd4749f165d7bd8e247a5e351b19800",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Análise de Modelo Misto, Correlação e Regressão Linear\"\nformat: html\neditor: visual\n---\n\n\n# Análise de Modelo Misto\n\nParcelas subdividas: dentro de cada bloco tem os hibridos aleatoriamente. Naquele bloco, subdivido, aleatorizou o método dentro dos blocos -- ou seja, o método foi aleatorizado entre os hibridos em cada bloco. \"Hibrido dentro do bloco e método dentro do híbrido\".\n\nPode utilizar um modelo misto (mistura de um fator de efeito fixo e um fator de efeito aleatório).\n\n# Bibliotecas\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(gsheet)\nlibrary(tidyverse)\nlibrary(lme4)\nlibrary(car)\nlibrary(performance)\nlibrary(DHARMa)\nlibrary(emmeans)\nlibrary(multcomp)\nlibrary(multcompView)\nlibrary(ggthemes)\nlibrary(patchwork)\n```\n:::\n\n\n# Importação dos dados\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmilho <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1345524759\")\n```\n:::\n\n\n# Visualização dos dados\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmilho |> \n  ggplot(aes(method, index))+\n  geom_jitter(width = 0.05, color = \"grey\")+\n  stat_summary(fun.data = \"mean_cl_boot\", size = 0.5,\n               alpha = 0.5, color = \"blue\")+\n  facet_wrap(~ hybrid)+\n  theme_classic()\n```\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n\n```{.r .cell-code}\nmilho |> \n  ggplot(aes(method, yield))+\n  geom_jitter(width = 0.05, color = \"grey\")+\n  stat_summary(fun.data = \"mean_cl_boot\", size = 0.5,\n               alpha = 0.5, color = \"red\")+\n  facet_wrap(~ hybrid)+\n  theme_classic()\n```\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-3-2.png){width=672}\n:::\n:::\n\n\n## INDEX: Modelo para subdividido:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmilho <- milho |> \n  mutate(block = as.factor(block))\n\nmix2 <- lmer(sqrt(index) ~hybrid*method  + block + (1|block/hybrid),\n                                  data = milho)\n\nAnova(mix2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: sqrt(index)\n                Chisq Df Pr(>Chisq)   \nhybrid        15.3159  5   0.009095 **\nmethod         3.8886  1   0.048615 * \nblock          0.0718  3   0.994997   \nhybrid:method 13.3812  5   0.020057 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n(1\\|block/hybrid) = é para indicar para a função que é o fator de efeito aleatório.\n\nResultado: deu interação significativa entre o hibrido e o metodo.\n\n### Testar as premissas\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_normality(mix2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: residuals appear as normally distributed (p = 0.440).\n```\n\n\n:::\n\n```{.r .cell-code}\ncheck_heteroscedasticity(mix2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: Error variance appears to be homoscedastic (p = 0.971).\n```\n\n\n:::\n\n```{.r .cell-code}\nplot(simulateResiduals(mix2))\n```\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n\n```{.r .cell-code}\nqqnorm(residuals(mix2))\nqqline(residuals(mix2))\n```\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-5-2.png){width=672}\n:::\n\n```{.r .cell-code}\nhist(residuals(mix2))\n```\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-5-3.png){width=672}\n:::\n\n```{.r .cell-code}\n#mesmo o Dharma dando problema, com o qqlinde e qqnorm os pontos estão próximos da linha, indicando normalidade, por isso, vamos prosseguir assumindo que as premissas foram atendidas.\n```\n:::\n\n\n### Teste de comparação de médias\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmedias_milho <- emmeans(mix2,\n                        ~ hybrid | method,\n                        type = \"response\")\n\nmedias_milho2 <- emmeans(mix2,\n                         ~ method | hybrid,\n                         type = \"response\")\n\ncld(medias_milho, Letters = LETTERS)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nmethod = pin:\n hybrid   response   SE   df lower.CL upper.CL .group\n BG7049H      19.4 10.7 6084     4.10     46.0  A    \n 30K64        20.3 10.9 6084     4.51     47.4  A    \n 30F53 YH     24.5 12.0 6084     6.61     53.7  AB   \n 30F53 HX     25.0 12.1 6084     6.84     54.4  AB   \n 30S31YH      31.7 13.7 6084    10.57     64.2  AB   \n 30S31H       37.1 14.8 6084    13.79     71.8   B   \n\nmethod = silk:\n hybrid   response   SE   df lower.CL upper.CL .group\n BG7049H      19.1 10.6 6084     3.96     45.6  A    \n 30K64        21.3 11.2 6084     5.00     48.9  A    \n 30F53 HX     24.4 12.0 6084     6.56     53.6  A    \n 30F53 YH     26.0 12.4 6084     7.42     56.0  A    \n 30S31H       26.3 12.5 6084     7.57     56.4  A    \n 30S31YH      26.4 12.5 6084     7.62     56.5  A    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n\n\n:::\n\n```{.r .cell-code}\ncld(medias_milho2, Letters = LETTERS)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nhybrid = 30F53 HX:\n method response   SE   df lower.CL upper.CL .group\n silk       24.4 12.0 6084     6.56     53.6  A    \n pin        25.0 12.1 6084     6.84     54.4  A    \n\nhybrid = 30F53 YH:\n method response   SE   df lower.CL upper.CL .group\n pin        24.5 12.0 6084     6.61     53.7  A    \n silk       26.0 12.4 6084     7.42     56.0  A    \n\nhybrid = 30K64:\n method response   SE   df lower.CL upper.CL .group\n pin        20.3 10.9 6084     4.51     47.4  A    \n silk       21.3 11.2 6084     5.00     48.9  A    \n\nhybrid = 30S31H:\n method response   SE   df lower.CL upper.CL .group\n silk       26.3 12.5 6084     7.57     56.4  A    \n pin        37.1 14.8 6084    13.79     71.8   B   \n\nhybrid = 30S31YH:\n method response   SE   df lower.CL upper.CL .group\n silk       26.4 12.5 6084     7.62     56.5  A    \n pin        31.7 13.7 6084    10.57     64.2  A    \n\nhybrid = BG7049H:\n method response   SE   df lower.CL upper.CL .group\n silk       19.1 10.6 6084     3.96     45.6  A    \n pin        19.4 10.7 6084     4.10     46.0  A    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n\n\n:::\n:::\n\n\n## YIELD: Modelo para subdividido:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmilho <- milho |> \n  mutate(block = as.factor(block))\n\nmix3 <- lmer(sqrt(yield) ~hybrid*method  + block + (1|block/hybrid),\n                                  data = milho)\n\nAnova(mix3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: sqrt(yield)\n                Chisq Df Pr(>Chisq)    \nhybrid        25.5591  5  0.0001086 ***\nmethod         0.0520  1  0.8196750    \nblock          2.3606  3  0.5010021    \nhybrid:method 24.4985  5  0.0001741 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n(1\\|block/hybrid) = é para indicar para a função que é o fator de efeito aleatório.\n\nResultado: deu interação significativa entre o hibrido e o metodo.\n\n### Testar as premissas\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_normality(mix3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: residuals appear as normally distributed (p = 0.214).\n```\n\n\n:::\n\n```{.r .cell-code}\ncheck_heteroscedasticity(mix3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: Error variance appears to be homoscedastic (p = 0.686).\n```\n\n\n:::\n\n```{.r .cell-code}\nplot(simulateResiduals(mix3))\n```\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n\n```{.r .cell-code}\nqqnorm(residuals(mix3))\nqqline(residuals(mix3))\n```\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-8-2.png){width=672}\n:::\n\n```{.r .cell-code}\nhist(residuals(mix3))\n```\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-8-3.png){width=672}\n:::\n\n```{.r .cell-code}\n#mesmo o Dharma dando problema, com o qqlinde e qqnorm os pontos estão próximos da linha, indicando normalidade, por isso, vamos prosseguir assumindo que as premissas foram atendidas.\n```\n:::\n\n\n### Teste de comparação de médias\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmedias_milho3 <- emmeans(mix3,\n                        ~ hybrid | method,\n                        type = \"response\")\n\nmedias_milho4 <- emmeans(mix3,\n                         ~ method | hybrid,\n                         type = \"response\")\n\ncld(medias_milho3, Letters = LETTERS)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nmethod = pin:\n hybrid   response  SE   df lower.CL upper.CL .group\n 30S31YH      7829 732 26.1     6398     9405  A    \n 30S31H       8081 743 26.1     6626     9681  AB   \n 30F53 YH     9314 798 26.1     7746    11027  ABC  \n 30F53 HX    11130 872 26.1     9410    12995   BC  \n 30K64       11666 893 26.1     9903    13574    C  \n BG7049H     11914 903 26.1    10131    13841    C  \n\nmethod = silk:\n hybrid   response  SE   df lower.CL upper.CL .group\n 30S31YH      8257 751 26.1     6785     9873  A    \n 30F53 YH     9079 788 26.1     7532    10770  A    \n 30S31H       9135 790 26.1     7583    10832  A    \n 30F53 HX     9932 824 26.1     8311    11698  AB   \n 30K64       10331 840 26.1     8676    12131  AB   \n BG7049H     12822 936 26.1    10970    14818   B   \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n\n\n:::\n\n```{.r .cell-code}\ncld(medias_milho4, Letters = LETTERS)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nhybrid = 30F53 HX:\n method response  SE   df lower.CL upper.CL .group\n silk       9932 824 26.1     8311    11698  A    \n pin       11130 872 26.1     9410    12995   B   \n\nhybrid = 30F53 YH:\n method response  SE   df lower.CL upper.CL .group\n silk       9079 788 26.1     7532    10770  A    \n pin        9314 798 26.1     7746    11027  A    \n\nhybrid = 30K64:\n method response  SE   df lower.CL upper.CL .group\n silk      10331 840 26.1     8676    12131  A    \n pin       11666 893 26.1     9903    13574   B   \n\nhybrid = 30S31H:\n method response  SE   df lower.CL upper.CL .group\n pin        8081 743 26.1     6626     9681  A    \n silk       9135 790 26.1     7583    10832   B   \n\nhybrid = 30S31YH:\n method response  SE   df lower.CL upper.CL .group\n pin        7829 732 26.1     6398     9405  A    \n silk       8257 751 26.1     6785     9873  A    \n\nhybrid = BG7049H:\n method response  SE   df lower.CL upper.CL .group\n pin       11914 903 26.1    10131    13841  A    \n silk      12822 936 26.1    10970    14818  A    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n\n\n:::\n:::\n\n\n# Importação dos dados\n\n\n::: {.cell}\n\n```{.r .cell-code}\nestande <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=401662555\")\n```\n:::\n\n\nQuer saber qual a tendência da porcentagem de sementes infectadas no número de plantas, ou seja, se diminui o estande de plantas emergidas, conforme aumenta a infecção no lote de sementes. Apesar de os dados serem em pontos específicos (0%, 3%, 6%...), se quer estimar qual a relação, o efeito (de 0 a 100%).\n\n# Visualização de dados\n\n\n::: {.cell}\n\n```{.r .cell-code}\nestande |> \n  ggplot(aes(trat, nplants))+\n  geom_jitter(width = 0.05, color = \"lightgrey\")+\n  stat_summary(fun.data = \"mean_cl_boot\", size = 0.5, color = \"black\",\n               alpha = 0.5)+\n  geom_smooth(method = lm,\n              se = FALSE)+\n  facet_wrap(~exp)+\n  theme_clean()\n```\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\ngeom_smooth(method = lm) = cria a linha de regressão linear\n\nTa mostrando que há efeito do *Bipolaris oryzae* causando redução na emergência de plantas no estande de plantas de arroz.\n\nColocando todos os experimentos como um todo:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nestande |> \n  ggplot(aes(trat, nplants))+\n  geom_jitter(width = 0.05, color = \"lightgrey\")+\n  stat_summary(fun.data = \"mean_cl_boot\", size = 0.5, color = \"blue\",\n               alpha = 0.5)+\n  #geom_smooth(method = lm, se = FALSE)+\n  #facet_wrap(~exp)+\n  theme_clean()\n```\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n## Regressão linear simples por experimento\n\n### Visualização para exp1\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexp1 <- estande |> \n  dplyr::filter(exp == 1)\n\nexp1 |> \nggplot(aes(trat, nplants))+\n  geom_point()+\n  ylim(0,100)+\n  geom_smooth(se = FALSE)\n```\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\nSe não colocar o method em geom_smooth ele dá a linha suavizada. O se é para tirar o fundo cinza de tras da linha (erro)\n\n### Modelo linear\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm1 <- lm(nplants ~trat,\n          data = exp1)\nsummary(lm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = nplants ~ trat, data = exp1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.500  -6.532   1.758   8.573  27.226 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  52.5000     4.2044  12.487 1.84e-11 ***\ntrat         -0.2419     0.1859  -1.301    0.207    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 15 on 22 degrees of freedom\nMultiple R-squared:  0.07148,\tAdjusted R-squared:  0.02928 \nF-statistic: 1.694 on 1 and 22 DF,  p-value: 0.2066\n```\n\n\n:::\n:::\n\n\nQUal a hipótese nula: que o coeficiente de regressão é igual a 0. Ou seja, não tem efeito. Para cada percentual de inoculo (unidade de x) reduz 0,24 de y (precisa de 4% para reduzir uma planta) Dessa forma, como valor p foi maior que 0,05 (0,207), não rejeita H0, então não tem efeito.\n\n### Visualização para exp2\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexp2 <- estande |> \n  dplyr::filter(exp == 2)\n\nexp2 |> \nggplot(aes(trat, nplants))+\n  geom_point()+\n  ylim(0,100)+\n  geom_smooth(method = lm,\n    se = FALSE)\n```\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\nSe não colocar o method em geom_smooth ele dá a linha suavizada. O se é para tirar o fundo cinza de tras da linha (erro)\n\n### Modelo linear\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm2 <- lm(nplants ~trat,\n          data = exp2)\nsummary(lm2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = nplants ~ trat, data = exp2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-25.7816  -7.7150   0.5653   8.1929  19.2184 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  60.9857     3.6304  16.798 4.93e-14 ***\ntrat         -0.7007     0.1605  -4.365 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.95 on 22 degrees of freedom\nMultiple R-squared:  0.4641,\tAdjusted R-squared:  0.4398 \nF-statistic: 19.05 on 1 and 22 DF,  p-value: 0.0002473\n```\n\n\n:::\n:::\n\n\nPara cada percentual de inoculo (unidade de x) reduz 0,70 de y (quase uma planta)\n\nTem efeito significativo: p-valor \\< 0,05\n\nAdjusted R-squared: é uma medida estatística utilizada em regressão linear para avaliar o ajuste do modelo aos dados. Ou seja, quanto maior o R2, maior a relação de y ser em função do x. Quanto maior variabilidade nos pontos (dispersão), o R2 diminui e o p-valor aumenta. Vai explicar menos, quanto mais disperso são os dados.\n\n#### Fazendo transformação dos dados: fica mais linear a linha\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexp2 |> \nggplot(aes(log(trat), nplants))+\n  geom_point()+\n  ylim(0,100)+\n  geom_smooth(se = FALSE)\n```\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\n#### Fazendo GLM\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglm2 <- glm(nplants ~trat, family = \"gaussian\",\n            data = exp2)\n\nsummary(glm2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = nplants ~ trat, family = \"gaussian\", data = exp2)\n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  60.9857     3.6304  16.798 4.93e-14 ***\ntrat         -0.7007     0.1605  -4.365 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 167.7464)\n\n    Null deviance: 6886.6  on 23  degrees of freedom\nResidual deviance: 3690.4  on 22  degrees of freedom\nAIC: 194.96\n\nNumber of Fisher Scoring iterations: 2\n```\n\n\n:::\n\n```{.r .cell-code}\nAIC(glm2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 194.9597\n```\n\n\n:::\n\n```{.r .cell-code}\nglm2b <- glm(nplants ~trat, family = \"poisson\",\n             data = exp2)\n\nsummary(glm2b)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = nplants ~ trat, family = \"poisson\", data = exp2)\n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  4.134189   0.037583 110.003  < 2e-16 ***\ntrat        -0.016270   0.002059  -7.901 2.76e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 139.783  on 23  degrees of freedom\nResidual deviance:  69.578  on 22  degrees of freedom\nAIC: 210.24\n\nNumber of Fisher Scoring iterations: 4\n```\n\n\n:::\n\n```{.r .cell-code}\nAIC(glm2b)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 210.2353\n```\n\n\n:::\n:::\n\n\n### Visualização para exp3\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexp3 <- estande |> \n  dplyr::filter(exp == 3)\n\nexp3 |> \nggplot(aes(trat, nplants))+\n  geom_point()+\n  ylim(0,100)+\n  geom_smooth(se = FALSE)\n```\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n\n```{.r .cell-code}\nglm3 <- glm(nplants ~trat, family = \"poisson\",\n             data = exp3)\n\nsummary(glm3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = nplants ~ trat, family = \"poisson\", data = exp3)\n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  4.571590   0.029539 154.762  < 2e-16 ***\ntrat        -0.009965   0.001488  -6.697 2.13e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 77.906  on 23  degrees of freedom\nResidual deviance: 29.952  on 22  degrees of freedom\nAIC: 183.93\n\nNumber of Fisher Scoring iterations: 4\n```\n\n\n:::\n\n```{.r .cell-code}\nAIC(glm3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 183.9324\n```\n\n\n:::\n:::\n\n\n### Análise global (sem ser para cada experimentos = todos os experimentos juntos)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglm3 <- glmer(nplants ~trat + (trat | exp), family = \"gaussian\",\n              data = estande)\nsummary(glm3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: nplants ~ trat + (trat | exp)\n   Data: estande\n\nREML criterion at convergence: 580.8\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.0988 -0.6091  0.1722  0.6360  1.9963 \n\nRandom effects:\n Groups   Name        Variance  Std.Dev. Corr \n exp      (Intercept) 510.68405 22.5983       \n          trat          0.05516  0.2349  -0.82\n Residual             167.91303 12.9581       \nNumber of obs: 72, groups:  exp, 3\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)  69.7452    13.2146   5.278\ntrat         -0.5687     0.1643  -3.462\n\nCorrelation of Fixed Effects:\n     (Intr)\ntrat -0.731\noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.00274249 (tol = 0.002, component 1)\n```\n\n\n:::\n\n```{.r .cell-code}\nAIC(glm3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 592.8402\n```\n\n\n:::\n\n```{.r .cell-code}\nglm3b <- glmer(nplants ~trat + (trat|exp), family = poisson(link = \"log\"),\n                                                            data = estande)\nsummary(glm3b)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: poisson  ( log )\nFormula: nplants ~ trat + (trat | exp)\n   Data: estande\n\n     AIC      BIC   logLik deviance df.resid \n   660.7    672.1   -325.4    650.7       67 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.6247 -0.8083  0.1042  0.9601  3.6511 \n\nRandom effects:\n Groups Name        Variance  Std.Dev. Corr \n exp    (Intercept) 6.425e-02 0.253478      \n        trat        1.602e-05 0.004003 -0.17\nNumber of obs: 72, groups:  exp, 3\n\nFixed effects:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  4.223397   0.147793  28.577  < 2e-16 ***\ntrat        -0.010434   0.002538  -4.111 3.93e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n     (Intr)\ntrat -0.192\n```\n\n\n:::\n\n```{.r .cell-code}\nAIC(glm3b)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 660.7282\n```\n\n\n:::\n:::\n\n\nAIC menor diz que o modelo está melhor ajustado.\n\n# Impotação\n\n\n::: {.cell}\n\n```{.r .cell-code}\nremotes::install_github(\"emdelponte/r4pde\")\n\nlibrary(r4pde)\n\nwm <- WhiteMoldSoybean\n\nwm |> \n  ggplot(aes(inc, yld, color = factor(study)))+\n  geom_point()+\n  #facet_wrap(~study)+\n  theme_minimal()+\n  geom_smooth(method = lm,\n              se = FALSE)\n```\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmofo1 <- lm(yld ~inc,\n            data = wm)\nsummary(mofo1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = yld ~ inc, data = wm)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1657.85  -594.50   -91.32   531.76  1693.15 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 3299.619     56.451  58.451  < 2e-16 ***\ninc           -9.261      2.108  -4.393 1.45e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 745.8 on 380 degrees of freedom\nMultiple R-squared:  0.04833,\tAdjusted R-squared:  0.04582 \nF-statistic:  19.3 on 1 and 380 DF,  p-value: 1.452e-05\n```\n\n\n:::\n:::\n\n\nIntercepto: produtivididade quando a incidÊncia é 0. INC: para cada percentual vc pede 9 kg (-9,261)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(broom)\nfit_all <- wm |> \n  group_by(study) |> \n  do(tidy(lm(.$yld ~.$inc),conf.int=TRUE))\nfit_all\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 70 × 8\n# Groups:   study [35]\n   study term        estimate std.error statistic  p.value conf.low conf.high\n   <dbl> <chr>          <dbl>     <dbl>     <dbl>    <dbl>    <dbl>     <dbl>\n 1     1 (Intercept)  3329.       86.8      38.3  4.60e-13   3138.    3520.  \n 2     1 .$inc         -14.2       2.08     -6.85 2.78e- 5    -18.8     -9.64\n 3     2 (Intercept)  2682.       48.6      55.2  8.55e-15   2575.    2789.  \n 4     2 .$inc          -6.93      1.49     -4.66 6.89e- 4    -10.2     -3.66\n 5     3 (Intercept)  4017.       61.6      65.2  1.37e-15   3882.    4153.  \n 6     3 .$inc         -18.6       1.71    -10.9  3.11e- 7    -22.4    -14.9 \n 7     4 (Intercept)  2814.      151.       18.6  1.15e- 9   2481.    3147.  \n 8     4 .$inc         -43.5      16.8      -2.58 2.56e- 2    -80.5     -6.38\n 9     5 (Intercept)  3317.      234.       14.2  2.07e- 8   2802.    3832.  \n10     5 .$inc         -21.2       5.69     -3.72 3.36e- 3    -33.7     -8.67\n# ℹ 60 more rows\n```\n\n\n:::\n\n```{.r .cell-code}\nmofo2 <- wm |> \n    group_by(study) |> \n      do(tidy(lm(.$yld ~.$inc),conf.int=TRUE))\n    mofo2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 70 × 8\n# Groups:   study [35]\n   study term        estimate std.error statistic  p.value conf.low conf.high\n   <dbl> <chr>          <dbl>     <dbl>     <dbl>    <dbl>    <dbl>     <dbl>\n 1     1 (Intercept)  3329.       86.8      38.3  4.60e-13   3138.    3520.  \n 2     1 .$inc         -14.2       2.08     -6.85 2.78e- 5    -18.8     -9.64\n 3     2 (Intercept)  2682.       48.6      55.2  8.55e-15   2575.    2789.  \n 4     2 .$inc          -6.93      1.49     -4.66 6.89e- 4    -10.2     -3.66\n 5     3 (Intercept)  4017.       61.6      65.2  1.37e-15   3882.    4153.  \n 6     3 .$inc         -18.6       1.71    -10.9  3.11e- 7    -22.4    -14.9 \n 7     4 (Intercept)  2814.      151.       18.6  1.15e- 9   2481.    3147.  \n 8     4 .$inc         -43.5      16.8      -2.58 2.56e- 2    -80.5     -6.38\n 9     5 (Intercept)  3317.      234.       14.2  2.07e- 8   2802.    3832.  \n10     5 .$inc         -21.2       5.69     -3.72 3.36e- 3    -33.7     -8.67\n# ℹ 60 more rows\n```\n\n\n:::\n\n```{.r .cell-code}\ndf <- mofo2 |>\n  dplyr::filter(term == \".$inc\")\n\nmean(df$estimate)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -19.52932\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(lme4)\nmofo3 <- lmer(yld ~inc + (inc | study), data = wm,\n              REML = FALSE)\nsummary(mofo3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear mixed model fit by maximum likelihood  ['lmerMod']\nFormula: yld ~ inc + (inc | study)\n   Data: wm\n\n     AIC      BIC   logLik deviance df.resid \n  5319.4   5343.1  -2653.7   5307.4      376 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.7078 -0.5991 -0.0295  0.5077  3.2364 \n\nRandom effects:\n Groups   Name        Variance  Std.Dev. Corr \n study    (Intercept) 557573.08 746.708       \n          inc             36.85   6.071  -0.29\n Residual              37228.73 192.947       \nNumber of obs: 382, groups:  study, 35\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept) 3455.432    128.063   26.98\ninc          -17.236      1.451  -11.88\n\nCorrelation of Fixed Effects:\n    (Intr)\ninc -0.300\noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.416806 (tol = 0.002, component 1)\n```\n\n\n:::\n:::\n\n\n# Correlação linear\n\n## Importação dos dados e visualização\n\nQue correlação tem entre a análise dos grupos (diferentes programas que fizeram a análise das imagens)? Definimos como padrão o Assess.\n\nCorrelação: associação entre duas variáveis. A força da associação é em função da dispersão dos dados, quanto mais diperso, mais fraca é a associação. Quanto mais próximo, menos disperso, são os dados, a associação é mais forte.\n\nObtém o r (COEFICIENTE DE CORRELAÇÃO) = força de associação entre x e y. Correlação: entre variáveis respostas diferentes.\n\nCoeficiente de Pearson: -1 \\> 0 \\> 1 (correlação negativa e positiva).\n\nPode obter a significação da correlação através do p-valor.\n\nCorrelação não quer dizer causalidade: não tem relação de causa e efeito. Exemplo: aumentou o consumo de sorvete e aumentou a temperatura do mar - uma coisa não tem causa e efeito com a outra.\n\nRegressão: R² (quanto da variação de y é explicado pelo x) = COEFICIENTE DE DETERMINAÇÃO. R² é sempre menor que o r. O R² é sempre menor que r.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nimg <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=373270992\")\n\np1 <- img |> \n  ggplot(aes(Assess, ImageJ))+\n  geom_point()+\n  geom_smooth(method = \"lm\")\n\np2 <- img |> \n  ggplot(aes(Assess, LeafDoctor))+\n  geom_point()+\n  geom_smooth(method = \"lm\")\n\nimg |> \n  pivot_longer(3:5, names_to = \"method\",\n               values_to = \"value\") |> \n  ggplot(aes(method, value))+\n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n\n```{.r .cell-code}\np1 + p2\n```\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-24-2.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nimg2 <- img |> \n  dplyr::select(Assess, LeafDoctor, ImageJ)\n\nlibrary(AgroR)\ncorgraph(img2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        Var1       Var2       cor            p\n2 LeafDoctor     Assess 0.9666367 5.972544e-42\n3     ImageJ     Assess 0.9776918 8.143613e-48\n6     ImageJ LeafDoctor 0.9797478 3.144091e-49\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n\n```{.r .cell-code}\ncor.test(img$Assess, img$LeafDoctor)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPearson's product-moment correlation\n\ndata:  img$Assess and img$LeafDoctor\nt = 31.119, df = 68, p-value < 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.9466882 0.9792005\nsample estimates:\n      cor \n0.9666367 \n```\n\n\n:::\n\n```{.r .cell-code}\ncor(img$Assess, img$LeafDoctor)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.9666367\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(corrplot)\ncor_img2 <- cor(img2)\ncorrplot(cor_img2, method = 'number', type = \"lower\")\n```\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-25-2.png){width=672}\n:::\n\n```{.r .cell-code}\ncor_img2 <- cor(img2)\ncorrplot(cor_img2, method = 'number', type = \"upper\")\n```\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-25-3.png){width=672}\n:::\n:::\n\n\ncor.test dá mais informações do que a função cor. Quanto maior o r, menor o p-valor. P-valor: hipótese alternativa é que a a ccorrelação é igual a 0 (não tem correlação significativa). p-value = \\< 2.2e-16 indica que a correlação é muito forte (p-valor altamente significativo) o r = 0,98 indica eplevada correlação entre os resultados.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncampo <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=866852711\")\n\ncampo2 <- campo |> \n  dplyr::select(DFC, FER, PROD)\n\ncorgraph(campo2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Var1 Var2        cor            p\n2  FER  DFC  0.9316978 9.864101e-15\n3 PROD  DFC -0.6928161 1.110652e-05\n6 PROD  FER -0.6258321 1.277444e-04\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-26-1.png){width=672}\n:::\n\n```{.r .cell-code}\ncor.test(campo$PROD, campo$DFC)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPearson's product-moment correlation\n\ndata:  campo$PROD and campo$DFC\nt = -5.2623, df = 30, p-value = 1.111e-05\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.8388581 -0.4537361\nsample estimates:\n       cor \n-0.6928161 \n```\n\n\n:::\n\n```{.r .cell-code}\ncor.test(campo$PROD, campo$FER)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPearson's product-moment correlation\n\ndata:  campo$PROD and campo$FER\nt = -4.3949, df = 30, p-value = 0.0001277\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.7999565 -0.3544981\nsample estimates:\n       cor \n-0.6258321 \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncampo |>\n  ggplot(aes(DFC, PROD))+\n  geom_point()\n```\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n:::\n\n\n# Regressão linear: modelo quadrático\n\no modelo quadrático é um modelo linear de ordem 2! (= modelo curvi-linear)\n\nFunção para o modelo quadrático: formula = y \\~ poly(x,2) no ggplot\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexp2 <- estande |> \n  dplyr::filter(exp == 2)\n\nexp2 |> \n  ggplot(aes(trat, nplants))+\n  geom_point()+\n # stat_summary(fun.data = \"mean_cl_boot\", size = 0.5, color = \"black\",\n #              alpha = 0.5)+\n  ylim(0,100)+\n  geom_smooth(method = \"lm\",\n              se = FALSE,\n              formula = y ~poly(x,2),\n              color = \"black\")+\n  geom_smooth(method = \"lm\",\n              se = FALSE)\n```\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-28-1.png){width=672}\n:::\n\n```{.r .cell-code}\n # facet_wrap(~exp)+\n  #theme_clean()\n```\n:::\n\n\nModelo linear:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#primeira ordem\nlm2 <- lm(nplants ~trat,\n          data = exp2)\nsummary(lm2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = nplants ~ trat, data = exp2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-25.7816  -7.7150   0.5653   8.1929  19.2184 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  60.9857     3.6304  16.798 4.93e-14 ***\ntrat         -0.7007     0.1605  -4.365 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.95 on 22 degrees of freedom\nMultiple R-squared:  0.4641,\tAdjusted R-squared:  0.4398 \nF-statistic: 19.05 on 1 and 22 DF,  p-value: 0.0002473\n```\n\n\n:::\n\n```{.r .cell-code}\nhist(residuals(lm2))\n```\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-29-1.png){width=672}\n:::\n\n```{.r .cell-code}\nAIC(lm2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 194.9597\n```\n\n\n:::\n:::\n\n\nMultiple R-squared: 0.4641 (obtido do summary(lm2))\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# segunda ordem (ou quadrática)\nexp2$trat2 <- exp2$trat^2\n\nlm3 <- lm(nplants ~trat + trat2,\n          data = exp2)\nsummary(lm3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = nplants ~ trat + trat2, data = exp2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.439  -6.019   1.789   8.016  19.561 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 66.30156    4.42097  14.997 1.08e-12 ***\ntrat        -1.77720    0.58467  -3.040  0.00623 ** \ntrat2        0.02223    0.01166   1.906  0.07036 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.24 on 21 degrees of freedom\nMultiple R-squared:  0.5432,\tAdjusted R-squared:  0.4997 \nF-statistic: 12.49 on 2 and 21 DF,  p-value: 0.0002675\n```\n\n\n:::\n\n```{.r .cell-code}\nhist(residuals(lm3))\n```\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-30-1.png){width=672}\n:::\n\n```{.r .cell-code}\nAIC(lm3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 193.1284\n```\n\n\n:::\n:::\n\n\nMultiple R-squared: 0.5432 O modelo quadrático está explicando melhor que o modelo de primeira ordem.\n\nAIC(lm3) = 93.1284 AIC(lm2) = 194.9597\n\nQuanto menor o AIC, melhor está explicando, então a quadrática realmente é melhor.\n\ny = 66,3 - 1,77xTrat + 0,02xTrat² (essa é a equação da regressão)\n\nUsando o pacote AgroR:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwith(exp2, polynomial(trat, nplants, grau = 3))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n----------------------------------------------------\nRegression Models\n----------------------------------------------------\n                Estimate  Std. Error   t value     Pr(>|t|)\n(Intercept) 70.265143802 5.300440019 13.256474 2.295186e-11\ntrat        -3.609380523 1.514625525 -2.383018 2.720299e-02\nI(trat^2)    0.140522077 0.091192577  1.540938 1.390058e-01\nI(trat^3)   -0.001712445 0.001309648 -1.307561 2.058546e-01\n\n----------------------------------------------------\nDeviations from regression\n----------------------------------------------------\n          Df       SSq       MSQ          F      p-value\nLinear     1 3196.2031 3196.2031 21.8232929 0.0001899378\nQuadratic  1  544.5029  544.5029  3.7178008 0.0697619482\nCubic      1  247.7520  247.7520  1.6916208 0.2097934169\nDeviation  2  261.9170  130.9585  0.8941691 0.4263523326\nResidual  18 2636.2500  146.4583                        \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[[1]]\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-31-1.png){width=672}\n:::\n:::\n\n\ngrau = 2 é função quadrática (R² maior que o grau = 1 então é melhor), o grau = 1 é função linear. Grau 3 (cubica) fica melhor ainda, não tem uma explicação biológica para isso. para acubica o valor-p é 0,21.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#library(agro3)\n#with(exp2, polynomial(trat,nplants, grau = 2))\n#data(\"phao\")\n#with(phao, polynomial(dose,comp, grau = 2))\n```\n:::\n\n\n## Importação dos dados e visualização dos dados\n\n\n::: {.cell}\n\n```{.r .cell-code}\npyra <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=465348652\")\n\npyra2 <- pyra |>\n  group_by(code, state, dose) |> \n  summarise(mean_germination = mean(germination))\n\npyra2|> \n  ggplot(aes(dose, mean_germination))+\n  geom_point()+\n  facet_wrap(~code)\n```\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-33-1.png){width=672}\n:::\n:::\n\n\n### Isolado 186\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(drc)\n\nisolado186 <- pyra2 |> \n   filter(code == \"186\")\n\ndrc1 <- drm(mean_germination ~ dose, data = isolado186,\n            fct = W1.3())\n\nAIC(drc1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 20.97861\n```\n\n\n:::\n\n```{.r .cell-code}\nplot(drc1) #para visualizar se o ajuste está bom\n```\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-34-1.png){width=672}\n:::\n\n```{.r .cell-code}\nED(drc1, 50, interval = \"delta\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nEstimated effective doses\n\n       Estimate Std. Error    Lower    Upper\ne:1:50 0.612064   0.015429 0.562963 0.661165\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(drc1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nModel fitted: Weibull (type 1) with lower limit at 0 (3 parms)\n\nParameter estimates:\n\n               Estimate Std. Error t-value   p-value    \nb:(Intercept)  2.832159   0.213496  13.266 0.0009257 ***\nd:(Intercept) 48.767893   0.716131  68.099 6.978e-06 ***\ne:(Intercept)  0.696626   0.018156  38.368 3.895e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error:\n\n 1.009228 (3 degrees of freedom)\n```\n\n\n:::\n:::\n\n\n### Isolado 165\n\n\n::: {.cell}\n\n```{.r .cell-code}\nisolado165 <- pyra2 |> \n  filter(code == \"165\")\n\ndrc2 <- drm(mean_germination ~ dose, data = isolado165,\n            fct = LL.3())\n\nAIC(drc2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 31.55522\n```\n\n\n:::\n\n```{.r .cell-code}\nplot(drc2) #para visualizar se o ajuste está bom\n```\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-35-1.png){width=672}\n:::\n\n```{.r .cell-code}\nED(drc1, 50, interval = \"delta\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nEstimated effective doses\n\n       Estimate Std. Error    Lower    Upper\ne:1:50 0.612064   0.015429 0.562963 0.661165\n```\n\n\n:::\n:::\n\n\n### Interpretação:\n\n***AIC***: O critério de informação de Akaike (AIC) ajuda a avaliar a qualidade do ajuste do modelo; valores menores indicam melhor ajuste.\n\n***plot(drc1)***: O gráfico permite visualizar o ajuste do modelo aos dados.\n\n***ED(drc1, 50, interval = \"delta\")***: Calcula a dose que causa 50% do efeito máximo esperado (ED50) com um intervalo de confiança delta.\n\n***summary(drc1)***: Fornece um resumo detalhado do modelo ajustado, incluindo estimativas dos parâmetros e suas significâncias.\n\n## EC50\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ec50estimator)\ndf_ec50 <- estimate_EC50(mean_germination ~ dose,\n                         data = pyra2,\n                         isolate_col = \"code\",\n                         interval = \"delta\",\n                         fct = drc::LL.3())\n\ndf_ec50 |> \n  ggplot(aes(reorder(ID, Estimate), Estimate))+\n  geom_point()+\n  geom_errorbar(aes(ymin = Lower, ymax = Upper), width = 0.1)+\n  coord_flip()\n```\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-36-1.png){width=672}\n:::\n\n```{.r .cell-code}\nprint(df_ec50)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      ID strata   Estimate  Std..Error        Lower     Upper\n1    152        0.44435629 0.077789240  0.196796213 0.6919164\n2    153        0.20379664 0.042373512  0.068945217 0.3386481\n3    164        0.50775844 0.047248266  0.357393370 0.6581235\n4    165        0.55839613 0.114195113  0.194976315 0.9218159\n5    169        0.14722311 0.009555688  0.116812646 0.1776336\n6    170        0.37503889 0.043207328  0.237533889 0.5125439\n7    186        0.57975744 0.013332268  0.537328208 0.6221867\n8    187        0.21563338 0.036639446  0.099030315 0.3322365\n9    188        0.15297172 0.004284691  0.139335920 0.1666075\n10   189        0.53106193 0.023130936  0.457448972 0.6046749\n11 FGT05        0.04483862 0.019290890 -0.016553601 0.1062308\n12 FGT06        0.54497946 0.034834602  0.434120211 0.6558387\n13 FGT07        0.88770053 0.079917704  0.633366725 1.1420343\n14 FGT28        0.22608141 0.033600742  0.119148854 0.3330140\n15 FGT29        0.23601652 0.034933881  0.124841318 0.3471917\n16 FGT33        0.10481627 0.013065221  0.063236910 0.1463956\n17 FGT34        0.14773114 0.047003373 -0.001854568 0.2973169\n18 FGT35        0.20315392 0.038984604  0.079087515 0.3272203\n19 FGT42        0.45000559 0.059685890  0.260058448 0.6399527\n20 FGT43        0.49589549 0.060850771  0.302241178 0.6895498\n```\n\n\n:::\n:::\n\n\n### Explicação dos Parâmetros:\n\n***mean_germination \\~ dose***: A fórmula que especifica a variável resposta (`mean_germination`) e a variável preditora (`dose`).\n\n***data = pyra2***: O data frame que contém os dados.\n\n***isolate_col = \"code\"***: A coluna que identifica os diferentes isolados.\n\n***interval = \"delta\"***: O método para calcular os intervalos de confiança.\n\n***fct = drc::LL.3()***: A função de ajuste logística de três parâmetros do pacote `drc`.\n\n### Atenção\n\nQuanto maior a EC50, menor a sensibilidade. Ou seja, requer uma quantidade maior de produto, para ter o efeito de redução de 50% A EC50 (concentração efetiva 50) é a concentração de um agente (exemplo, fungicida) que é necessária para obter 50% do efeito máximo desejado. Portanto, a interpretação da EC50 é:\n\n-   Maior EC50: Indica menor sensibilidade do organismo ao agente. Isso significa que é necessária uma concentração maior do agente para alcançar o efeito desejado.\n-   Menor EC50: Indica maior sensibilidade do organismo ao agente. Isso significa que uma concentração menor do agente é suficiente para alcançar o efeito desejado\n\nEssa relação é crucial para entender a eficácia e a dosagem necessária de determinado produto.",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}